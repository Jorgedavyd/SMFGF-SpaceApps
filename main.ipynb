{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocessing import *\n",
    "from data.data_utils import *\n",
    "from models.macro_architectures import *\n",
    "from models.micro_architectures import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format: YYYYMMDD\n",
    "start_time = '20201231'\n",
    "end_time = '20230803'\n",
    "scrap_date = interval_time(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(set([day[:6] for day in scrap_date]))\n",
    "import_Dst(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\data\\preprocessing.py:158: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  mg1 = pd.concat(mg1_list)\n"
     ]
    }
   ],
   "source": [
    "l1_sample, l2_sample, dst, kp = automated_preprocessing(scrap_date, sep = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 (raw) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       " 2020-12-31 00:00:00     -459.95712      20.771427     -37.828570   \n",
       " 2020-12-31 00:01:00     -458.98570      18.614286     -40.314290   \n",
       " 2020-12-31 00:02:00     -460.80002      19.028570     -37.328570   \n",
       " 2020-12-31 00:03:00     -458.98750      21.837500     -39.425000   \n",
       " 2020-12-31 00:04:00     -460.91428      21.199999     -39.257140   \n",
       " ...                            ...            ...            ...   \n",
       " 2023-08-03 23:55:00     -458.07272       8.363636     -20.463636   \n",
       " 2023-08-03 23:56:00     -457.90000      31.890000     -21.760000   \n",
       " 2023-08-03 23:57:00     -460.56366       1.745455     -13.645455   \n",
       " 2023-08-03 23:58:00     -463.80002     -14.516666      -4.116667   \n",
       " 2023-08-03 23:59:00     -439.42502       1.658333     -13.025001   \n",
       " \n",
       "                      proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       " 2020-12-31 00:00:00     -459.95712      29.357143     -31.628570   \n",
       " 2020-12-31 00:01:00     -458.98570      27.914286     -34.542860   \n",
       " 2020-12-31 00:02:00     -460.80002      27.571428     -31.542858   \n",
       " 2020-12-31 00:03:00     -458.98750      30.775002     -32.900000   \n",
       " 2020-12-31 00:04:00     -460.91428      30.085714     -32.928570   \n",
       " ...                            ...            ...            ...   \n",
       " 2023-08-03 23:55:00     -458.07272       5.927273     -21.281816   \n",
       " 2023-08-03 23:56:00     -457.90000      29.130000     -25.340000   \n",
       " 2023-08-03 23:57:00     -460.56366       0.136364     -13.754546   \n",
       " 2023-08-03 23:58:00     -463.80002     -14.891667      -2.391667   \n",
       " 2023-08-03 23:59:00     -439.42502       0.100000     -13.125000   \n",
       " \n",
       "                      proton_speed  proton_density  proton_temperature  \n",
       " 2020-12-31 00:00:00     462.02856        6.050000          154177.420  \n",
       " 2020-12-31 00:01:00     461.18573        5.697143          143959.140  \n",
       " 2020-12-31 00:02:00     462.82858        5.862857          153136.140  \n",
       " 2020-12-31 00:03:00     461.37500        5.867500          146527.750  \n",
       " 2020-12-31 00:04:00     463.17142        5.845714          141359.140  \n",
       " ...                           ...             ...                 ...  \n",
       " 2023-08-03 23:55:00     459.57272        0.124545            2000.000  \n",
       " 2023-08-03 23:56:00     462.02002        0.403000            4756.600  \n",
       " 2023-08-03 23:57:00     460.77274        0.833636           14152.454  \n",
       " 2023-08-03 23:58:00     465.94998        0.733333            9470.083  \n",
       " 2023-08-03 23:59:00     439.63333        0.785000            8913.667  \n",
       " \n",
       " [1362240 rows x 9 columns],\n",
       "                            bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       " 2020-12-31 00:00:00  3.103543 -1.372186 -1.481739 -2.347711 -49.236874   \n",
       " 2020-12-31 00:01:00  3.121529 -1.600045 -1.255240 -2.361683 -49.195217   \n",
       " 2020-12-31 00:02:00  3.229239 -1.357512 -2.009158 -1.942433 -37.763630   \n",
       " 2020-12-31 00:03:00  2.966850 -1.500373 -1.187357 -1.967772 -42.944990   \n",
       " 2020-12-31 00:04:00  2.932062 -1.586736 -1.057594 -2.214242 -49.151546   \n",
       " ...                       ...       ...       ...       ...        ...   \n",
       " 2023-08-03 23:55:00  9.148619 -7.701201  4.927823  0.234573   1.467366   \n",
       " 2023-08-03 23:56:00  9.117077 -7.746156  4.771574  0.456540   2.871917   \n",
       " 2023-08-03 23:57:00  9.129887 -7.796285  4.708487  0.402483   2.526587   \n",
       " 2023-08-03 23:58:00  9.107132 -7.686605  4.833078  0.528950   3.330908   \n",
       " 2023-08-03 23:59:00  9.114652 -7.897603  4.496427  0.588675   3.703073   \n",
       " \n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       " 2020-12-31 00:00:00  212.29163 -1.372186 -0.863934 -2.638353 -58.362057   \n",
       " 2020-12-31 00:01:00  201.94005 -1.600045 -0.641299 -2.596520 -56.349064   \n",
       " 2020-12-31 00:02:00  224.33852 -1.357512 -1.475083 -2.373543 -47.985750   \n",
       " 2020-12-31 00:03:00  200.96104 -1.500373 -0.672283 -2.197755 -48.643024   \n",
       " 2020-12-31 00:04:00  197.24292 -1.586736 -0.486791 -2.405081 -55.295593   \n",
       " ...                        ...       ...       ...       ...        ...   \n",
       " 2023-08-03 23:55:00  147.38512 -7.701201  4.921561 -0.341616  -2.142453   \n",
       " 2023-08-03 23:56:00  148.36537 -7.746156  4.792239 -0.103969  -0.652903   \n",
       " 2023-08-03 23:57:00  148.86864 -7.796285  4.723234 -0.151295  -0.951697   \n",
       " 2023-08-03 23:58:00  147.84564 -7.686605  4.861768 -0.041320  -0.259435   \n",
       " 2023-08-03 23:59:00  150.34690 -7.897603  4.534444  0.056465   0.353977   \n",
       " \n",
       "                        phi_gsm  \n",
       " 2020-12-31 00:00:00  212.29163  \n",
       " 2020-12-31 00:01:00  201.94005  \n",
       " 2020-12-31 00:02:00  224.33852  \n",
       " 2020-12-31 00:03:00  200.96104  \n",
       " 2020-12-31 00:04:00  197.24292  \n",
       " ...                        ...  \n",
       " 2023-08-03 23:55:00  147.41812  \n",
       " 2023-08-03 23:56:00  148.25417  \n",
       " 2023-08-03 23:57:00  148.78772  \n",
       " 2023-08-03 23:58:00  147.69276  \n",
       " 2023-08-03 23:59:00  150.13960  \n",
       " \n",
       " [1362240 rows x 11 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:00:00</th>\n",
       "      <td>-461.712648</td>\n",
       "      <td>23.564702</td>\n",
       "      <td>-41.086875</td>\n",
       "      <td>-461.712648</td>\n",
       "      <td>32.661459</td>\n",
       "      <td>-34.307589</td>\n",
       "      <td>464.346162</td>\n",
       "      <td>5.811333</td>\n",
       "      <td>146978.770000</td>\n",
       "      <td>3.196159</td>\n",
       "      <td>-1.654849</td>\n",
       "      <td>-1.847285</td>\n",
       "      <td>-1.694565</td>\n",
       "      <td>-33.542051</td>\n",
       "      <td>215.702141</td>\n",
       "      <td>-1.654849</td>\n",
       "      <td>-1.390457</td>\n",
       "      <td>-2.081981</td>\n",
       "      <td>-41.945192</td>\n",
       "      <td>215.702141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 01:00:00</th>\n",
       "      <td>-457.052138</td>\n",
       "      <td>17.513274</td>\n",
       "      <td>-27.782113</td>\n",
       "      <td>-457.052138</td>\n",
       "      <td>23.151429</td>\n",
       "      <td>-23.313929</td>\n",
       "      <td>458.318929</td>\n",
       "      <td>6.294155</td>\n",
       "      <td>197023.787333</td>\n",
       "      <td>2.760782</td>\n",
       "      <td>-0.405533</td>\n",
       "      <td>-2.105541</td>\n",
       "      <td>0.021299</td>\n",
       "      <td>-0.177205</td>\n",
       "      <td>258.416425</td>\n",
       "      <td>-0.405533</td>\n",
       "      <td>-2.051862</td>\n",
       "      <td>-0.433943</td>\n",
       "      <td>-11.797873</td>\n",
       "      <td>258.416425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 02:00:00</th>\n",
       "      <td>-453.349376</td>\n",
       "      <td>12.962054</td>\n",
       "      <td>-25.639137</td>\n",
       "      <td>-453.349376</td>\n",
       "      <td>17.454822</td>\n",
       "      <td>-22.815923</td>\n",
       "      <td>454.335716</td>\n",
       "      <td>6.812452</td>\n",
       "      <td>230582.338333</td>\n",
       "      <td>2.872992</td>\n",
       "      <td>0.120363</td>\n",
       "      <td>-2.265247</td>\n",
       "      <td>0.865786</td>\n",
       "      <td>20.457005</td>\n",
       "      <td>270.883119</td>\n",
       "      <td>0.120363</td>\n",
       "      <td>-2.386412</td>\n",
       "      <td>0.432359</td>\n",
       "      <td>10.488156</td>\n",
       "      <td>270.883119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 03:00:00</th>\n",
       "      <td>-457.754936</td>\n",
       "      <td>15.503958</td>\n",
       "      <td>-34.397917</td>\n",
       "      <td>-457.754936</td>\n",
       "      <td>20.284434</td>\n",
       "      <td>-31.818393</td>\n",
       "      <td>459.367022</td>\n",
       "      <td>6.874756</td>\n",
       "      <td>212633.102667</td>\n",
       "      <td>2.612051</td>\n",
       "      <td>-0.610070</td>\n",
       "      <td>-1.577324</td>\n",
       "      <td>-1.464512</td>\n",
       "      <td>-37.558328</td>\n",
       "      <td>237.178338</td>\n",
       "      <td>-0.610070</td>\n",
       "      <td>-1.357049</td>\n",
       "      <td>-1.681922</td>\n",
       "      <td>-44.019162</td>\n",
       "      <td>237.178338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 04:00:00</th>\n",
       "      <td>-441.350564</td>\n",
       "      <td>14.754673</td>\n",
       "      <td>-28.015595</td>\n",
       "      <td>-441.350564</td>\n",
       "      <td>17.365982</td>\n",
       "      <td>-26.479821</td>\n",
       "      <td>442.711253</td>\n",
       "      <td>6.524396</td>\n",
       "      <td>211812.393500</td>\n",
       "      <td>2.835215</td>\n",
       "      <td>-0.076185</td>\n",
       "      <td>-2.472715</td>\n",
       "      <td>0.753232</td>\n",
       "      <td>14.703117</td>\n",
       "      <td>268.512925</td>\n",
       "      <td>-0.076185</td>\n",
       "      <td>-2.524382</td>\n",
       "      <td>0.514577</td>\n",
       "      <td>9.325356</td>\n",
       "      <td>268.512925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 19:00:00</th>\n",
       "      <td>-336.646294</td>\n",
       "      <td>2.560524</td>\n",
       "      <td>-40.894559</td>\n",
       "      <td>-336.646294</td>\n",
       "      <td>-4.469508</td>\n",
       "      <td>-40.811081</td>\n",
       "      <td>339.976270</td>\n",
       "      <td>3.297642</td>\n",
       "      <td>10603.785207</td>\n",
       "      <td>8.881810</td>\n",
       "      <td>-8.397860</td>\n",
       "      <td>-0.315262</td>\n",
       "      <td>2.761895</td>\n",
       "      <td>18.125610</td>\n",
       "      <td>182.149904</td>\n",
       "      <td>-8.397860</td>\n",
       "      <td>0.161601</td>\n",
       "      <td>2.780559</td>\n",
       "      <td>18.254308</td>\n",
       "      <td>178.913148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 20:00:00</th>\n",
       "      <td>-332.942454</td>\n",
       "      <td>-19.543290</td>\n",
       "      <td>-8.267044</td>\n",
       "      <td>-332.942454</td>\n",
       "      <td>-20.459794</td>\n",
       "      <td>-5.348601</td>\n",
       "      <td>335.023164</td>\n",
       "      <td>1.821652</td>\n",
       "      <td>6775.375603</td>\n",
       "      <td>9.278263</td>\n",
       "      <td>-8.971080</td>\n",
       "      <td>-0.909717</td>\n",
       "      <td>1.199496</td>\n",
       "      <td>7.538724</td>\n",
       "      <td>185.612646</td>\n",
       "      <td>-8.971080</td>\n",
       "      <td>-0.730964</td>\n",
       "      <td>1.308748</td>\n",
       "      <td>8.197190</td>\n",
       "      <td>184.480378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 21:00:00</th>\n",
       "      <td>-325.770046</td>\n",
       "      <td>5.254784</td>\n",
       "      <td>-28.044986</td>\n",
       "      <td>-325.770046</td>\n",
       "      <td>1.841405</td>\n",
       "      <td>-28.512537</td>\n",
       "      <td>328.366749</td>\n",
       "      <td>2.553373</td>\n",
       "      <td>7479.847265</td>\n",
       "      <td>9.491237</td>\n",
       "      <td>-9.264703</td>\n",
       "      <td>-0.280312</td>\n",
       "      <td>1.955153</td>\n",
       "      <td>11.896596</td>\n",
       "      <td>181.740103</td>\n",
       "      <td>-9.264703</td>\n",
       "      <td>-0.044151</td>\n",
       "      <td>1.975867</td>\n",
       "      <td>12.025461</td>\n",
       "      <td>180.281581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 22:00:00</th>\n",
       "      <td>-357.435846</td>\n",
       "      <td>15.239832</td>\n",
       "      <td>-27.647399</td>\n",
       "      <td>-357.435846</td>\n",
       "      <td>12.085765</td>\n",
       "      <td>-29.165588</td>\n",
       "      <td>359.615137</td>\n",
       "      <td>3.209151</td>\n",
       "      <td>65709.495525</td>\n",
       "      <td>9.317494</td>\n",
       "      <td>-9.089208</td>\n",
       "      <td>0.564847</td>\n",
       "      <td>1.426778</td>\n",
       "      <td>8.788789</td>\n",
       "      <td>176.384023</td>\n",
       "      <td>-9.089208</td>\n",
       "      <td>0.719256</td>\n",
       "      <td>1.356400</td>\n",
       "      <td>8.346369</td>\n",
       "      <td>175.425802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:00:00</th>\n",
       "      <td>-471.629934</td>\n",
       "      <td>2.330469</td>\n",
       "      <td>-14.573993</td>\n",
       "      <td>-471.629934</td>\n",
       "      <td>0.667548</td>\n",
       "      <td>-14.742996</td>\n",
       "      <td>472.017339</td>\n",
       "      <td>3.669411</td>\n",
       "      <td>208994.500400</td>\n",
       "      <td>9.134143</td>\n",
       "      <td>-8.516804</td>\n",
       "      <td>2.958169</td>\n",
       "      <td>0.946576</td>\n",
       "      <td>5.953639</td>\n",
       "      <td>160.870878</td>\n",
       "      <td>-8.516804</td>\n",
       "      <td>3.045140</td>\n",
       "      <td>0.605140</td>\n",
       "      <td>3.804584</td>\n",
       "      <td>160.345478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22704 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2020-12-31 00:00:00    -461.712648      23.564702     -41.086875   \n",
       "2020-12-31 01:00:00    -457.052138      17.513274     -27.782113   \n",
       "2020-12-31 02:00:00    -453.349376      12.962054     -25.639137   \n",
       "2020-12-31 03:00:00    -457.754936      15.503958     -34.397917   \n",
       "2020-12-31 04:00:00    -441.350564      14.754673     -28.015595   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 19:00:00    -336.646294       2.560524     -40.894559   \n",
       "2023-08-03 20:00:00    -332.942454     -19.543290      -8.267044   \n",
       "2023-08-03 21:00:00    -325.770046       5.254784     -28.044986   \n",
       "2023-08-03 22:00:00    -357.435846      15.239832     -27.647399   \n",
       "2023-08-03 23:00:00    -471.629934       2.330469     -14.573993   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2020-12-31 00:00:00    -461.712648      32.661459     -34.307589   \n",
       "2020-12-31 01:00:00    -457.052138      23.151429     -23.313929   \n",
       "2020-12-31 02:00:00    -453.349376      17.454822     -22.815923   \n",
       "2020-12-31 03:00:00    -457.754936      20.284434     -31.818393   \n",
       "2020-12-31 04:00:00    -441.350564      17.365982     -26.479821   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 19:00:00    -336.646294      -4.469508     -40.811081   \n",
       "2023-08-03 20:00:00    -332.942454     -20.459794      -5.348601   \n",
       "2023-08-03 21:00:00    -325.770046       1.841405     -28.512537   \n",
       "2023-08-03 22:00:00    -357.435846      12.085765     -29.165588   \n",
       "2023-08-03 23:00:00    -471.629934       0.667548     -14.742996   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2020-12-31 00:00:00    464.346162        5.811333       146978.770000   \n",
       "2020-12-31 01:00:00    458.318929        6.294155       197023.787333   \n",
       "2020-12-31 02:00:00    454.335716        6.812452       230582.338333   \n",
       "2020-12-31 03:00:00    459.367022        6.874756       212633.102667   \n",
       "2020-12-31 04:00:00    442.711253        6.524396       211812.393500   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-03 19:00:00    339.976270        3.297642        10603.785207   \n",
       "2023-08-03 20:00:00    335.023164        1.821652         6775.375603   \n",
       "2023-08-03 21:00:00    328.366749        2.553373         7479.847265   \n",
       "2023-08-03 22:00:00    359.615137        3.209151        65709.495525   \n",
       "2023-08-03 23:00:00    472.017339        3.669411       208994.500400   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2020-12-31 00:00:00  3.196159 -1.654849 -1.847285 -1.694565 -33.542051   \n",
       "2020-12-31 01:00:00  2.760782 -0.405533 -2.105541  0.021299  -0.177205   \n",
       "2020-12-31 02:00:00  2.872992  0.120363 -2.265247  0.865786  20.457005   \n",
       "2020-12-31 03:00:00  2.612051 -0.610070 -1.577324 -1.464512 -37.558328   \n",
       "2020-12-31 04:00:00  2.835215 -0.076185 -2.472715  0.753232  14.703117   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-03 19:00:00  8.881810 -8.397860 -0.315262  2.761895  18.125610   \n",
       "2023-08-03 20:00:00  9.278263 -8.971080 -0.909717  1.199496   7.538724   \n",
       "2023-08-03 21:00:00  9.491237 -9.264703 -0.280312  1.955153  11.896596   \n",
       "2023-08-03 22:00:00  9.317494 -9.089208  0.564847  1.426778   8.788789   \n",
       "2023-08-03 23:00:00  9.134143 -8.516804  2.958169  0.946576   5.953639   \n",
       "\n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2020-12-31 00:00:00  215.702141 -1.654849 -1.390457 -2.081981 -41.945192   \n",
       "2020-12-31 01:00:00  258.416425 -0.405533 -2.051862 -0.433943 -11.797873   \n",
       "2020-12-31 02:00:00  270.883119  0.120363 -2.386412  0.432359  10.488156   \n",
       "2020-12-31 03:00:00  237.178338 -0.610070 -1.357049 -1.681922 -44.019162   \n",
       "2020-12-31 04:00:00  268.512925 -0.076185 -2.524382  0.514577   9.325356   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "2023-08-03 19:00:00  182.149904 -8.397860  0.161601  2.780559  18.254308   \n",
       "2023-08-03 20:00:00  185.612646 -8.971080 -0.730964  1.308748   8.197190   \n",
       "2023-08-03 21:00:00  181.740103 -9.264703 -0.044151  1.975867  12.025461   \n",
       "2023-08-03 22:00:00  176.384023 -9.089208  0.719256  1.356400   8.346369   \n",
       "2023-08-03 23:00:00  160.870878 -8.516804  3.045140  0.605140   3.804584   \n",
       "\n",
       "                        phi_gsm  \n",
       "2020-12-31 00:00:00  215.702141  \n",
       "2020-12-31 01:00:00  258.416425  \n",
       "2020-12-31 02:00:00  270.883119  \n",
       "2020-12-31 03:00:00  237.178338  \n",
       "2020-12-31 04:00:00  268.512925  \n",
       "...                         ...  \n",
       "2023-08-03 19:00:00  178.913148  \n",
       "2023-08-03 20:00:00  184.480378  \n",
       "2023-08-03 21:00:00  180.281581  \n",
       "2023-08-03 22:00:00  175.425802  \n",
       "2023-08-03 23:00:00  160.345478  \n",
       "\n",
       "[22704 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_sample_hour = l1_sample.resample('60min').mean()\n",
    "#l1_sample_hour = (l1_sample[0].resample('60min').mean(), l1_sample[1].resample('60min').mean())\n",
    "l1_sample_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 (cleaned) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       " 2020-12-31 00:00:00         -461.0           20.6          -37.7   \n",
       " 2020-12-31 00:01:00         -459.2           17.7          -39.2   \n",
       " 2020-12-31 00:02:00         -461.8           18.1          -39.2   \n",
       " 2020-12-31 00:03:00         -459.5           22.5          -38.1   \n",
       " 2020-12-31 00:04:00         -461.5           21.1          -38.5   \n",
       " ...                            ...            ...            ...   \n",
       " 2023-08-03 23:55:00         -458.3            1.8          -13.6   \n",
       " 2023-08-03 23:56:00         -457.8            1.7          -13.6   \n",
       " 2023-08-03 23:57:00         -460.4            1.7          -13.6   \n",
       " 2023-08-03 23:58:00         -463.8            1.8          -13.7   \n",
       " 2023-08-03 23:59:00         -461.3            1.7          -13.7   \n",
       " \n",
       "                      proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       " 2020-12-31 00:00:00         -461.0           29.2          -31.5   \n",
       " 2020-12-31 00:01:00         -459.2           26.7          -33.7   \n",
       " 2020-12-31 00:02:00         -461.8           27.1          -33.6   \n",
       " 2020-12-31 00:03:00         -459.5           31.1          -31.5   \n",
       " 2020-12-31 00:04:00         -461.5           29.9          -32.2   \n",
       " ...                            ...            ...            ...   \n",
       " 2023-08-03 23:55:00         -458.3            0.2          -13.7   \n",
       " 2023-08-03 23:56:00         -457.8            0.1          -13.7   \n",
       " 2023-08-03 23:57:00         -460.4            0.1          -13.7   \n",
       " 2023-08-03 23:58:00         -463.8            0.2          -13.8   \n",
       " 2023-08-03 23:59:00         -461.3            0.1          -13.8   \n",
       " \n",
       "                      proton_speed  proton_density  proton_temperature  \n",
       " 2020-12-31 00:00:00         463.0            6.32            156370.0  \n",
       " 2020-12-31 00:01:00         461.2            6.03            145922.0  \n",
       " 2020-12-31 00:02:00         463.8            6.12            152728.0  \n",
       " 2020-12-31 00:03:00         461.6            6.33            144651.0  \n",
       " 2020-12-31 00:04:00         463.6            6.04            141876.0  \n",
       " ...                           ...             ...                 ...  \n",
       " 2023-08-03 23:55:00         458.5            0.12              2000.0  \n",
       " 2023-08-03 23:56:00         458.0            0.37              2000.0  \n",
       " 2023-08-03 23:57:00         460.6            0.81             12657.0  \n",
       " 2023-08-03 23:58:00         464.0            0.72              9024.0  \n",
       " 2023-08-03 23:59:00         461.5            0.79              9548.0  \n",
       " \n",
       " [1362240 rows x 9 columns],\n",
       "                        bt  bx_gse  by_gse  bz_gse  theta_gse  phi_gse  bx_gsm  \\\n",
       " 2020-12-31 00:00:00  3.10   -1.37   -1.48   -2.35     -49.29   227.20   -1.37   \n",
       " 2020-12-31 00:01:00  3.12   -1.59   -1.25   -2.36     -49.37   218.17   -1.59   \n",
       " 2020-12-31 00:02:00  3.23   -1.40   -1.97   -2.02     -39.75   234.57   -1.40   \n",
       " 2020-12-31 00:03:00  2.96   -1.60   -0.97   -2.16     -49.14   211.31   -1.60   \n",
       " 2020-12-31 00:04:00  2.93   -1.58   -1.07   -2.21     -49.18   214.07   -1.58   \n",
       " ...                   ...     ...     ...     ...        ...      ...     ...   \n",
       " 2023-08-03 23:55:00  9.15   -7.70    4.92    0.23       1.46   147.41   -7.70   \n",
       " 2023-08-03 23:56:00  9.12   -7.75    4.78    0.45       2.83   148.35   -7.75   \n",
       " 2023-08-03 23:57:00  9.13   -7.81    4.69    0.39       2.43   149.01   -7.81   \n",
       " 2023-08-03 23:58:00  9.11   -7.70    4.83    0.51       3.24   147.90   -7.70   \n",
       " 2023-08-03 23:59:00  9.11   -7.90    4.50    0.59       3.73   150.31   -7.90   \n",
       " \n",
       "                      by_gsm  bz_gsm  theta_gsm  phi_gsm  \n",
       " 2020-12-31 00:00:00   -0.86   -2.64     -58.42   212.19  \n",
       " 2020-12-31 00:01:00   -0.64   -2.60     -56.53   201.83  \n",
       " 2020-12-31 00:02:00   -1.42   -2.44     -50.62   225.38  \n",
       " 2020-12-31 00:03:00   -0.42   -2.33     -54.72   194.58  \n",
       " 2020-12-31 00:04:00   -0.50   -2.41     -55.40   197.52  \n",
       " ...                     ...     ...        ...      ...  \n",
       " 2023-08-03 23:55:00    4.92   -0.34      -2.14   147.44  \n",
       " 2023-08-03 23:56:00    4.80   -0.11      -0.69   148.24  \n",
       " 2023-08-03 23:57:00    4.70   -0.16      -1.03   148.94  \n",
       " 2023-08-03 23:58:00    4.86   -0.05      -0.35   147.75  \n",
       " 2023-08-03 23:59:00    4.54    0.06       0.37   150.10  \n",
       " \n",
       " [1362240 rows x 11 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:00:00</th>\n",
       "      <td>-462.145000</td>\n",
       "      <td>22.706667</td>\n",
       "      <td>-40.606667</td>\n",
       "      <td>-462.145000</td>\n",
       "      <td>31.723333</td>\n",
       "      <td>-34.036667</td>\n",
       "      <td>464.526667</td>\n",
       "      <td>6.024000</td>\n",
       "      <td>147974.900000</td>\n",
       "      <td>3.196333</td>\n",
       "      <td>-1.657667</td>\n",
       "      <td>-1.849500</td>\n",
       "      <td>-1.700000</td>\n",
       "      <td>-33.725000</td>\n",
       "      <td>225.520000</td>\n",
       "      <td>-1.657667</td>\n",
       "      <td>-1.390833</td>\n",
       "      <td>-2.088833</td>\n",
       "      <td>-42.233667</td>\n",
       "      <td>215.938167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 01:00:00</th>\n",
       "      <td>-457.590000</td>\n",
       "      <td>17.478333</td>\n",
       "      <td>-27.850000</td>\n",
       "      <td>-457.590000</td>\n",
       "      <td>23.135000</td>\n",
       "      <td>-23.376667</td>\n",
       "      <td>458.808333</td>\n",
       "      <td>6.346000</td>\n",
       "      <td>197041.233333</td>\n",
       "      <td>2.764000</td>\n",
       "      <td>-0.405833</td>\n",
       "      <td>-2.111667</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>-0.183000</td>\n",
       "      <td>261.027000</td>\n",
       "      <td>-0.405833</td>\n",
       "      <td>-2.058167</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>-11.922167</td>\n",
       "      <td>259.814167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 02:00:00</th>\n",
       "      <td>-453.828333</td>\n",
       "      <td>13.290000</td>\n",
       "      <td>-25.736667</td>\n",
       "      <td>-453.828333</td>\n",
       "      <td>17.811667</td>\n",
       "      <td>-22.845000</td>\n",
       "      <td>454.766667</td>\n",
       "      <td>6.834000</td>\n",
       "      <td>233766.700000</td>\n",
       "      <td>2.872333</td>\n",
       "      <td>0.114333</td>\n",
       "      <td>-2.272667</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>20.795500</td>\n",
       "      <td>269.079667</td>\n",
       "      <td>0.114333</td>\n",
       "      <td>-2.395333</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>10.766000</td>\n",
       "      <td>271.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 03:00:00</th>\n",
       "      <td>-458.330000</td>\n",
       "      <td>15.601667</td>\n",
       "      <td>-34.370000</td>\n",
       "      <td>-458.330000</td>\n",
       "      <td>20.390000</td>\n",
       "      <td>-31.761667</td>\n",
       "      <td>459.913333</td>\n",
       "      <td>6.911000</td>\n",
       "      <td>213284.966667</td>\n",
       "      <td>2.611667</td>\n",
       "      <td>-0.609000</td>\n",
       "      <td>-1.573833</td>\n",
       "      <td>-1.474833</td>\n",
       "      <td>-38.339667</td>\n",
       "      <td>252.523333</td>\n",
       "      <td>-0.609000</td>\n",
       "      <td>-1.351500</td>\n",
       "      <td>-1.691833</td>\n",
       "      <td>-44.940667</td>\n",
       "      <td>239.751500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 04:00:00</th>\n",
       "      <td>-441.168333</td>\n",
       "      <td>14.753333</td>\n",
       "      <td>-27.376667</td>\n",
       "      <td>-441.168333</td>\n",
       "      <td>17.310000</td>\n",
       "      <td>-25.830000</td>\n",
       "      <td>442.366667</td>\n",
       "      <td>6.511333</td>\n",
       "      <td>211253.916667</td>\n",
       "      <td>2.838000</td>\n",
       "      <td>-0.072167</td>\n",
       "      <td>-2.477667</td>\n",
       "      <td>0.751000</td>\n",
       "      <td>14.600500</td>\n",
       "      <td>268.564667</td>\n",
       "      <td>-0.072167</td>\n",
       "      <td>-2.529833</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>9.170167</td>\n",
       "      <td>268.554667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 19:00:00</th>\n",
       "      <td>-336.648333</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>-41.610000</td>\n",
       "      <td>-336.648333</td>\n",
       "      <td>-2.953333</td>\n",
       "      <td>-41.776667</td>\n",
       "      <td>339.760000</td>\n",
       "      <td>3.311167</td>\n",
       "      <td>10654.400000</td>\n",
       "      <td>8.882167</td>\n",
       "      <td>-8.398167</td>\n",
       "      <td>-0.316333</td>\n",
       "      <td>2.763167</td>\n",
       "      <td>18.135000</td>\n",
       "      <td>182.157833</td>\n",
       "      <td>-8.398167</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>2.781667</td>\n",
       "      <td>18.264833</td>\n",
       "      <td>178.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 20:00:00</th>\n",
       "      <td>-331.586667</td>\n",
       "      <td>-20.721667</td>\n",
       "      <td>-8.181667</td>\n",
       "      <td>-331.586667</td>\n",
       "      <td>-21.613333</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>333.200000</td>\n",
       "      <td>1.798500</td>\n",
       "      <td>6084.233333</td>\n",
       "      <td>9.278833</td>\n",
       "      <td>-8.971667</td>\n",
       "      <td>-0.909500</td>\n",
       "      <td>1.197667</td>\n",
       "      <td>7.533833</td>\n",
       "      <td>185.614333</td>\n",
       "      <td>-8.971667</td>\n",
       "      <td>-0.730333</td>\n",
       "      <td>1.307333</td>\n",
       "      <td>8.195333</td>\n",
       "      <td>184.482500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 21:00:00</th>\n",
       "      <td>-325.763333</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>-28.608333</td>\n",
       "      <td>-325.763333</td>\n",
       "      <td>3.903333</td>\n",
       "      <td>-29.333333</td>\n",
       "      <td>327.763333</td>\n",
       "      <td>2.565167</td>\n",
       "      <td>7487.116667</td>\n",
       "      <td>9.491667</td>\n",
       "      <td>-9.265500</td>\n",
       "      <td>-0.279167</td>\n",
       "      <td>1.955333</td>\n",
       "      <td>11.903167</td>\n",
       "      <td>181.734500</td>\n",
       "      <td>-9.265500</td>\n",
       "      <td>-0.042833</td>\n",
       "      <td>1.977167</td>\n",
       "      <td>12.030000</td>\n",
       "      <td>180.273833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 22:00:00</th>\n",
       "      <td>-357.271667</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>-27.151667</td>\n",
       "      <td>-357.271667</td>\n",
       "      <td>12.301667</td>\n",
       "      <td>-28.686667</td>\n",
       "      <td>359.123333</td>\n",
       "      <td>3.185167</td>\n",
       "      <td>63931.000000</td>\n",
       "      <td>9.318167</td>\n",
       "      <td>-9.089667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.428333</td>\n",
       "      <td>8.796833</td>\n",
       "      <td>176.370833</td>\n",
       "      <td>-9.089667</td>\n",
       "      <td>0.721667</td>\n",
       "      <td>1.356833</td>\n",
       "      <td>8.353333</td>\n",
       "      <td>175.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:00:00</th>\n",
       "      <td>-474.641667</td>\n",
       "      <td>1.821667</td>\n",
       "      <td>-14.065000</td>\n",
       "      <td>-474.641667</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>-14.176667</td>\n",
       "      <td>474.856667</td>\n",
       "      <td>3.598000</td>\n",
       "      <td>205072.333333</td>\n",
       "      <td>9.134333</td>\n",
       "      <td>-8.518167</td>\n",
       "      <td>2.959333</td>\n",
       "      <td>0.948667</td>\n",
       "      <td>5.970333</td>\n",
       "      <td>160.867000</td>\n",
       "      <td>-8.518167</td>\n",
       "      <td>3.046167</td>\n",
       "      <td>0.607667</td>\n",
       "      <td>3.821167</td>\n",
       "      <td>160.341500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22704 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2020-12-31 00:00:00    -462.145000      22.706667     -40.606667   \n",
       "2020-12-31 01:00:00    -457.590000      17.478333     -27.850000   \n",
       "2020-12-31 02:00:00    -453.828333      13.290000     -25.736667   \n",
       "2020-12-31 03:00:00    -458.330000      15.601667     -34.370000   \n",
       "2020-12-31 04:00:00    -441.168333      14.753333     -27.376667   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 19:00:00    -336.648333       4.220000     -41.610000   \n",
       "2023-08-03 20:00:00    -331.586667     -20.721667      -8.181667   \n",
       "2023-08-03 21:00:00    -325.763333       7.400000     -28.608333   \n",
       "2023-08-03 22:00:00    -357.271667      15.400000     -27.151667   \n",
       "2023-08-03 23:00:00    -474.641667       1.821667     -14.065000   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2020-12-31 00:00:00    -462.145000      31.723333     -34.036667   \n",
       "2020-12-31 01:00:00    -457.590000      23.135000     -23.376667   \n",
       "2020-12-31 02:00:00    -453.828333      17.811667     -22.845000   \n",
       "2020-12-31 03:00:00    -458.330000      20.390000     -31.761667   \n",
       "2020-12-31 04:00:00    -441.168333      17.310000     -25.830000   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 19:00:00    -336.648333      -2.953333     -41.776667   \n",
       "2023-08-03 20:00:00    -331.586667     -21.613333      -5.080000   \n",
       "2023-08-03 21:00:00    -325.763333       3.903333     -29.333333   \n",
       "2023-08-03 22:00:00    -357.271667      12.301667     -28.686667   \n",
       "2023-08-03 23:00:00    -474.641667       0.216667     -14.176667   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2020-12-31 00:00:00    464.526667        6.024000       147974.900000   \n",
       "2020-12-31 01:00:00    458.808333        6.346000       197041.233333   \n",
       "2020-12-31 02:00:00    454.766667        6.834000       233766.700000   \n",
       "2020-12-31 03:00:00    459.913333        6.911000       213284.966667   \n",
       "2020-12-31 04:00:00    442.366667        6.511333       211253.916667   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-03 19:00:00    339.760000        3.311167        10654.400000   \n",
       "2023-08-03 20:00:00    333.200000        1.798500         6084.233333   \n",
       "2023-08-03 21:00:00    327.763333        2.565167         7487.116667   \n",
       "2023-08-03 22:00:00    359.123333        3.185167        63931.000000   \n",
       "2023-08-03 23:00:00    474.856667        3.598000       205072.333333   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2020-12-31 00:00:00  3.196333 -1.657667 -1.849500 -1.700000 -33.725000   \n",
       "2020-12-31 01:00:00  2.764000 -0.405833 -2.111667  0.024667  -0.183000   \n",
       "2020-12-31 02:00:00  2.872333  0.114333 -2.272667  0.877333  20.795500   \n",
       "2020-12-31 03:00:00  2.611667 -0.609000 -1.573833 -1.474833 -38.339667   \n",
       "2020-12-31 04:00:00  2.838000 -0.072167 -2.477667  0.751000  14.600500   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-03 19:00:00  8.882167 -8.398167 -0.316333  2.763167  18.135000   \n",
       "2023-08-03 20:00:00  9.278833 -8.971667 -0.909500  1.197667   7.533833   \n",
       "2023-08-03 21:00:00  9.491667 -9.265500 -0.279167  1.955333  11.903167   \n",
       "2023-08-03 22:00:00  9.318167 -9.089667  0.566667  1.428333   8.796833   \n",
       "2023-08-03 23:00:00  9.134333 -8.518167  2.959333  0.948667   5.970333   \n",
       "\n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2020-12-31 00:00:00  225.520000 -1.657667 -1.390833 -2.088833 -42.233667   \n",
       "2020-12-31 01:00:00  261.027000 -0.405833 -2.058167 -0.433333 -11.922167   \n",
       "2020-12-31 02:00:00  269.079667  0.114333 -2.395333  0.441500  10.766000   \n",
       "2020-12-31 03:00:00  252.523333 -0.609000 -1.351500 -1.691833 -44.940667   \n",
       "2020-12-31 04:00:00  268.564667 -0.072167 -2.529833  0.510500   9.170167   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "2023-08-03 19:00:00  182.157833 -8.398167  0.161500  2.781667  18.264833   \n",
       "2023-08-03 20:00:00  185.614333 -8.971667 -0.730333  1.307333   8.195333   \n",
       "2023-08-03 21:00:00  181.734500 -9.265500 -0.042833  1.977167  12.030000   \n",
       "2023-08-03 22:00:00  176.370833 -9.089667  0.721667  1.356833   8.353333   \n",
       "2023-08-03 23:00:00  160.867000 -8.518167  3.046167  0.607667   3.821167   \n",
       "\n",
       "                        phi_gsm  \n",
       "2020-12-31 00:00:00  215.938167  \n",
       "2020-12-31 01:00:00  259.814167  \n",
       "2020-12-31 02:00:00  271.607000  \n",
       "2020-12-31 03:00:00  239.751500  \n",
       "2020-12-31 04:00:00  268.554667  \n",
       "...                         ...  \n",
       "2023-08-03 19:00:00  178.913500  \n",
       "2023-08-03 20:00:00  184.482500  \n",
       "2023-08-03 21:00:00  180.273833  \n",
       "2023-08-03 22:00:00  175.412000  \n",
       "2023-08-03 23:00:00  160.341500  \n",
       "\n",
       "[22704 rows x 20 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_sample_hour = l2_sample.resample('60min').mean()\n",
    "#l2_sample_hour = (l2_sample[0].resample('60min').mean(), l2_sample[1].resample('60min').mean())\n",
    "l2_sample_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dst data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -3\n",
       "1       -1\n",
       "2       -1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "22699    1\n",
       "22700   -2\n",
       "22701   -3\n",
       "22702   -6\n",
       "22703   -6\n",
       "Name: Dst, Length: 22704, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1+\n",
       "1        1\n",
       "2       0+\n",
       "3        1\n",
       "4       1-\n",
       "        ..\n",
       "7563     2\n",
       "7564    2-\n",
       "7565    1+\n",
       "7566    0+\n",
       "7567    0+\n",
       "Name: Kp, Length: 7568, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "### Descriptions:\n",
    "**hn_dl**: hour normal dataloader\n",
    "\n",
    "**mn_dl**: minute normal dataloader\n",
    "\n",
    "**hr_dl**: minute normal dataloader\n",
    "\n",
    "**mr_dl**: minute normal dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_hour = 10  #hour\n",
    "sequence_length_minute = 600 #minute\n",
    "pred_length = 9 #hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normal\n",
    "hour_Normal_dataset = NormalTrainingDataset(l1_sample_hour, dst, kp, sequence_length_hour, pred_length, hour = True)\n",
    "minute_Normal_dataset = NormalTrainingDataset(l1_sample, dst, kp, sequence_length_minute, pred_length, hour = False)\n",
    "##Refined(new method)\n",
    "hour_Refined_dataset = RefinedTrainingDataset(l1_sample_hour, l2_sample_hour, dst,kp,sequence_length_hour, pred_length, hour = True)\n",
    "minute_Refined_dataset = RefinedTrainingDataset(l1_sample, l2_sample, dst,kp,sequence_length_minute, pred_length, hour = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Extra dataset\n",
    "hour_kp_dataset = MainToSingleTarget(l1_sample, kp, sequence_length_hour, pred_length, hour = True, sep = True, target_mode='kp_gfz')\n",
    "minute_kp_dataset = MainToSingleTarget(l1_sample, kp, sequence_length_minute, pred_length, hour = False, sep = True, target_mode='kp_gfz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(hour_kp_dataset))\n",
    "\n",
    "train_hour_kp, test_hour_kp = random_split(hour_kp_dataset , [len(hour_kp_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hour_kp_dl = DataLoader(train_hour_kp, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hour_kp_dl = DeviceDataLoader(train_hour_kp_dl, device)\n",
    "test_hour_kp_dl = DataLoader(test_hour_kp, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hour_kp_dl = DeviceDataLoader(test_hour_kp_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(minute_kp_dataset))\n",
    "\n",
    "train_minute_kp, test_minute_kp = random_split(minute_kp_dataset , [len(minute_kp_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_minute_kp_dl = DataLoader(train_minute_kp, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_minute_kp_dl = DeviceDataLoader(train_minute_kp_dl, device)\n",
    "test_minute_kp_dl = DataLoader(test_minute_kp, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_minute_kp_dl = DeviceDataLoader(test_minute_kp_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(hour_Normal_dataset))\n",
    "\n",
    "train_hn_ds, test_hn_ds = random_split(hour_Normal_dataset , [len(hour_Normal_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hn_dl = DataLoader(train_hn_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hn_dl = DeviceDataLoader(train_hn_dl, device)\n",
    "test_hn_dl = DataLoader(test_hn_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hn_dl = DeviceDataLoader(test_hn_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(minute_Normal_dataset))\n",
    "\n",
    "train_mn_ds, test_mn_ds = random_split(minute_Normal_dataset , [len(minute_Normal_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_mn_dl = DataLoader(train_mn_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_mn_dl = DeviceDataLoader(train_mn_dl, device)\n",
    "test_mn_dl = DataLoader(test_mn_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_mn_dl = DeviceDataLoader(test_mn_dl, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(hour_Refined_dataset))\n",
    "\n",
    "train_hr_ds, test_hr_ds = random_split(hour_Refined_dataset , [len(hour_Refined_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hr_dl = DataLoader(train_hr_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hr_dl = DeviceDataLoader(train_hr_dl, device)\n",
    "test_hr_dl = DataLoader(test_hr_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hr_dl = DeviceDataLoader(test_hr_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(minute_Refined_dataset))\n",
    "\n",
    "train_mr_ds, test_mr_ds = random_split(minute_Refined_dataset , [len(minute_Refined_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_mr_dl = DataLoader(train_mr_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_mr_dl = DeviceDataLoader(train_mr_dl, device)\n",
    "test_mr_dl = DataLoader(test_mr_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_mr_dl = DeviceDataLoader(test_mr_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined models with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Convolutional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "cnn_encoder_min = Simple1DCNN(architecture, sequence_length_minute, hidden_size)\n",
    "cnn_encoder_hour = Simple1DCNN(architecture, sequence_length_hour, hidden_size)\n",
    "#fc layer\n",
    "cnn_fc_dst_min = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_min = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "cnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_min = to_device(RefinedArchitecture(cnn_encoder_min, cnn_fc_dst_min, cnn_fc_kp_min), device)\n",
    "RefinedCNN_hour = to_device(RefinedArchitecture(cnn_encoder_hour, cnn_fc_dst_hour, cnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 20\n",
    "max_lr = 1e-2\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 1e-1\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 1.2622\n",
      "\ttrain_main_loss: 1.2621\n",
      "\ttrain_output_loss: 0.0028\n",
      "\ttrain_encoder_loss: 0.0038\n",
      "\tval_overall_loss: 1.1528\n",
      "\tval_main_loss: 1.1527\n",
      "\tval_output_loss: 0.0040\n",
      "\tval_encoder_loss: 0.0065\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_overall_loss: 1.1290\n",
      "\ttrain_main_loss: 1.1288\n",
      "\ttrain_output_loss: 0.0039\n",
      "\ttrain_encoder_loss: 0.0233\n",
      "\tval_overall_loss: 1.1327\n",
      "\tval_main_loss: 1.1319\n",
      "\tval_output_loss: 0.0054\n",
      "\tval_encoder_loss: 0.0798\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00026\n",
      "\ttrain_overall_loss: 1.1277\n",
      "\ttrain_main_loss: 1.1256\n",
      "\ttrain_output_loss: 0.0042\n",
      "\ttrain_encoder_loss: 0.2093\n",
      "\tval_overall_loss: 1.1478\n",
      "\tval_main_loss: 1.1448\n",
      "\tval_output_loss: 0.0051\n",
      "\tval_encoder_loss: 0.2883\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedCNN_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedCNN_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:231\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    229\u001b[0m main_losses\u001b[39m.\u001b[39mappend(main_loss)\n\u001b[0;32m    230\u001b[0m \u001b[39m#Calcular las derivadas parciales\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    233\u001b[0m \u001b[39m# Gradient clipping, para que no ocurra el exploding gradient\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m grad_clip:\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedCNN_min_history += RefinedCNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00104\n",
      "\ttrain_overall_loss: 1.2932\n",
      "\ttrain_main_loss: 1.2931\n",
      "\ttrain_output_loss: 0.0021\n",
      "\ttrain_encoder_loss: 0.0009\n",
      "\tval_overall_loss: 1.2866\n",
      "\tval_main_loss: 1.2865\n",
      "\tval_output_loss: 0.0017\n",
      "\tval_encoder_loss: 0.0008\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00280\n",
      "\ttrain_overall_loss: 1.2405\n",
      "\ttrain_main_loss: 1.2405\n",
      "\ttrain_output_loss: 0.0030\n",
      "\ttrain_encoder_loss: 0.0011\n",
      "\tval_overall_loss: 1.2383\n",
      "\tval_main_loss: 1.2383\n",
      "\tval_output_loss: 0.0020\n",
      "\tval_encoder_loss: 0.0010\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00520\n",
      "\ttrain_overall_loss: 1.2127\n",
      "\ttrain_main_loss: 1.2127\n",
      "\ttrain_output_loss: 0.0034\n",
      "\ttrain_encoder_loss: 0.0014\n",
      "\tval_overall_loss: 1.2170\n",
      "\tval_main_loss: 1.2169\n",
      "\tval_output_loss: 0.0024\n",
      "\tval_encoder_loss: 0.0014\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00760\n",
      "\ttrain_overall_loss: 1.2079\n",
      "\ttrain_main_loss: 1.2078\n",
      "\ttrain_output_loss: 0.0032\n",
      "\ttrain_encoder_loss: 0.0019\n",
      "\tval_overall_loss: 1.2843\n",
      "\tval_main_loss: 1.2843\n",
      "\tval_output_loss: 0.0035\n",
      "\tval_encoder_loss: 0.0024\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00936\n",
      "\ttrain_overall_loss: 1.1980\n",
      "\ttrain_main_loss: 1.1979\n",
      "\ttrain_output_loss: 0.0035\n",
      "\ttrain_encoder_loss: 0.0042\n",
      "\tval_overall_loss: 1.1917\n",
      "\tval_main_loss: 1.1916\n",
      "\tval_output_loss: 0.0023\n",
      "\tval_encoder_loss: 0.0040\n",
      "Epoch [5]\n",
      "\tlast_lr: 0.01000\n",
      "\ttrain_overall_loss: 1.1926\n",
      "\ttrain_main_loss: 1.1926\n",
      "\ttrain_output_loss: 0.0030\n",
      "\ttrain_encoder_loss: 0.0060\n",
      "\tval_overall_loss: 1.2241\n",
      "\tval_main_loss: 1.2240\n",
      "\tval_output_loss: 0.0023\n",
      "\tval_encoder_loss: 0.0057\n",
      "Epoch [6]\n",
      "\tlast_lr: 0.00987\n",
      "\ttrain_overall_loss: 1.1823\n",
      "\ttrain_main_loss: 1.1822\n",
      "\ttrain_output_loss: 0.0032\n",
      "\ttrain_encoder_loss: 0.0077\n",
      "\tval_overall_loss: 1.2172\n",
      "\tval_main_loss: 1.2171\n",
      "\tval_output_loss: 0.0029\n",
      "\tval_encoder_loss: 0.0069\n",
      "Epoch [7]\n",
      "\tlast_lr: 0.00950\n",
      "\ttrain_overall_loss: 1.1761\n",
      "\ttrain_main_loss: 1.1760\n",
      "\ttrain_output_loss: 0.0029\n",
      "\ttrain_encoder_loss: 0.0083\n",
      "\tval_overall_loss: 1.2423\n",
      "\tval_main_loss: 1.2422\n",
      "\tval_output_loss: 0.0014\n",
      "\tval_encoder_loss: 0.0054\n",
      "Epoch [8]\n",
      "\tlast_lr: 0.00891\n",
      "\ttrain_overall_loss: 1.1643\n",
      "\ttrain_main_loss: 1.1642\n",
      "\ttrain_output_loss: 0.0029\n",
      "\ttrain_encoder_loss: 0.0101\n",
      "\tval_overall_loss: 1.2023\n",
      "\tval_main_loss: 1.2022\n",
      "\tval_output_loss: 0.0013\n",
      "\tval_encoder_loss: 0.0064\n",
      "Epoch [9]\n",
      "\tlast_lr: 0.00812\n",
      "\ttrain_overall_loss: 1.1574\n",
      "\ttrain_main_loss: 1.1572\n",
      "\ttrain_output_loss: 0.0029\n",
      "\ttrain_encoder_loss: 0.0115\n",
      "\tval_overall_loss: 1.1473\n",
      "\tval_main_loss: 1.1472\n",
      "\tval_output_loss: 0.0022\n",
      "\tval_encoder_loss: 0.0097\n",
      "Epoch [10]\n",
      "\tlast_lr: 0.00717\n",
      "\ttrain_overall_loss: 1.1444\n",
      "\ttrain_main_loss: 1.1442\n",
      "\ttrain_output_loss: 0.0028\n",
      "\ttrain_encoder_loss: 0.0123\n",
      "\tval_overall_loss: 1.1509\n",
      "\tval_main_loss: 1.1508\n",
      "\tval_output_loss: 0.0017\n",
      "\tval_encoder_loss: 0.0098\n",
      "Epoch [11]\n",
      "\tlast_lr: 0.00611\n",
      "\ttrain_overall_loss: 1.1362\n",
      "\ttrain_main_loss: 1.1360\n",
      "\ttrain_output_loss: 0.0030\n",
      "\ttrain_encoder_loss: 0.0133\n",
      "\tval_overall_loss: 1.1583\n",
      "\tval_main_loss: 1.1582\n",
      "\tval_output_loss: 0.0013\n",
      "\tval_encoder_loss: 0.0086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedCNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedCNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:247\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    244\u001b[0m     sched\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    246\u001b[0m \u001b[39m# Fase de validación\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(val_loader)\n\u001b[0;32m    248\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mtrain_overall_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(train_losses)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem() \n\u001b[0;32m    249\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mtrain_main_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(main_losses)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem() \n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:200\u001b[0m, in \u001b[0;36mRefinedArchitecture.evaluate\u001b[1;34m(self, val_loader)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, val_loader):\n\u001b[0;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 200\u001b[0m     outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, val_loader):\n\u001b[0;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 200\u001b[0m     outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\utils.py:66\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     67\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1317\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1315\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[1;32m-> 1317\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[0;32m   1318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \n\u001b[0;32m   1322\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1438\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[0;32m   1439\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[0;32m   1441\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[0;32m   1443\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[0;32m   1444\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:108\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     msecs \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m))\n\u001b[1;32m--> 108\u001b[0m res \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForSingleObject(\u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle), msecs)\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m _winapi\u001b[39m.\u001b[39mWAIT_OBJECT_0:\n\u001b[0;32m    110\u001b[0m     code \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39mGetExitCodeProcess(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedCNN_hour_history += RefinedCNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute based models\n",
    "deep_lstm_encoder_min_forward = DeepLSTM(hidden_size, input_size, architecture, attention = True).to(device)\n",
    "deep_lstm_encoder_min_backward = DeepLSTM(hidden_size, input_size, architecture, attention = True).to(device)\n",
    "bidirectional_deeplstm_encoder_min = BidirectionalRNN(deep_lstm_encoder_min_forward, deep_lstm_encoder_min_backward).to(device)\n",
    "##Bidirectional hour based models\n",
    "deep_lstm_encoder_hour_forward = DeepLSTM(hidden_size, input_size, architecture, attention = True).to(device)\n",
    "deep_lstm_encoder_hour_backward = DeepLSTM(hidden_size, input_size, architecture, attention = True).to(device)\n",
    "bidirectional_deeplstm_encoder_hour = BidirectionalRNN(deep_lstm_encoder_hour_forward, deep_lstm_encoder_hour_backward).to(device)\n",
    "#fc layer\n",
    "deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture).to(device) #the multiplying factor because concatenating hidden_states on bidirectional arch\n",
    "deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture).to(device)\n",
    "\n",
    "deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture).to(device)\n",
    "deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_min = to_device(RefinedArchitecture(bidirectional_deeplstm_encoder_min, deep_lstm_fc_dst_min, deep_lstm_fc_kp_min), device)\n",
    "RefinedLSTM_hour = to_device(RefinedArchitecture(bidirectional_deeplstm_encoder_hour, deep_lstm_fc_dst_hour, deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 10\n",
    "max_lr = 1e-2\n",
    "weigth_decay = 1e-3\n",
    "grad_clip = 1e-1\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 47\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#Z1132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedLSTM_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedLSTM_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:224\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    223\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m    225\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:116\u001b[0m, in \u001b[0;36mRefinedArchitecture.training_step\u001b[1;34m(self, batch, weigths)\u001b[0m\n\u001b[0;32m    114\u001b[0m l1_sample, l2_sample, dst, kp \u001b[39m=\u001b[39m batch\n\u001b[0;32m    115\u001b[0m \u001b[39m#encoder loss\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m h_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(l1_sample)\n\u001b[0;32m    117\u001b[0m h_t_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(l2_sample)\n\u001b[0;32m    118\u001b[0m encoder_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(h_t, h_t_hat)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:274\u001b[0m, in \u001b[0;36mBidirectionalRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    273\u001b[0m     \u001b[39m# Forward pass through the first RNN\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     hidden1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn1(x)\n\u001b[0;32m    275\u001b[0m     \u001b[39m# Reverse the input sequence for the second RNN\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     x_backward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflip(x, [\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:132\u001b[0m, in \u001b[0;36mDeepLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    130\u001b[0m xt \u001b[39m=\u001b[39m x[:, t, :]\n\u001b[0;32m    131\u001b[0m \u001b[39m#forward\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m a_F \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mF_h(hn) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mF_x(xt)\n\u001b[0;32m    133\u001b[0m F \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(a_F) \u001b[39m#forget gate\u001b[39;00m\n\u001b[0;32m    134\u001b[0m a_I \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI_h(hn) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI_x(xt)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:29\u001b[0m, in \u001b[0;36mDeepNeuralNetwork.forward\u001b[1;34m(self, xb)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xb):\n\u001b[0;32m     28\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_structure(xb)\n\u001b[1;32m---> 29\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_layer(out)\n\u001b[0;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "RefinedLSTM_min_history += RefinedLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 52\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#Z1516sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:224\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    223\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m    225\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:116\u001b[0m, in \u001b[0;36mRefinedArchitecture.training_step\u001b[1;34m(self, batch, weigths)\u001b[0m\n\u001b[0;32m    114\u001b[0m l1_sample, l2_sample, dst, kp \u001b[39m=\u001b[39m batch\n\u001b[0;32m    115\u001b[0m \u001b[39m#encoder loss\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m h_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(l1_sample)\n\u001b[0;32m    117\u001b[0m h_t_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(l2_sample)\n\u001b[0;32m    118\u001b[0m encoder_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(h_t, h_t_hat)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:274\u001b[0m, in \u001b[0;36mBidirectionalRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    273\u001b[0m     \u001b[39m# Forward pass through the first RNN\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     hidden1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn1(x)\n\u001b[0;32m    275\u001b[0m     \u001b[39m# Reverse the input sequence for the second RNN\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     x_backward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflip(x, [\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:132\u001b[0m, in \u001b[0;36mDeepLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    130\u001b[0m xt \u001b[39m=\u001b[39m x[:, t, :]\n\u001b[0;32m    131\u001b[0m \u001b[39m#forward\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m a_F \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mF_h(hn) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mF_x(xt)\n\u001b[0;32m    133\u001b[0m F \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(a_F) \u001b[39m#forget gate\u001b[39;00m\n\u001b[0;32m    134\u001b[0m a_I \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI_h(hn) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI_x(xt)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:29\u001b[0m, in \u001b[0;36mDeepNeuralNetwork.forward\u001b[1;34m(self, xb)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xb):\n\u001b[0;32m     28\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_structure(xb)\n\u001b[1;32m---> 29\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_layer(out)\n\u001b[0;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "RefinedLSTM_hour_history += RefinedLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute based models\n",
    "deep_gru_encoder_min_forward= DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min_backward= DeepGRU(hidden_size, input_size, architecture)\n",
    "bidirectional_deepgru_encoder_min = BidirectionalRNN(deep_gru_encoder_min_forward, deep_gru_encoder_min_backward)\n",
    "##Bidirectional hour based models\n",
    "deep_gru_encoder_hour_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "bidirectional_deepgru_encoder_hour = BidirectionalRNN(deep_gru_encoder_hour_forward, deep_gru_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min = to_device(RefinedArchitecture(bidirectional_deepgru_encoder_min, deep_gru_fc_dst_min, deep_gru_fc_kp_min), device)\n",
    "RefinedGRU_hour = to_device(RefinedArchitecture(bidirectional_deepgru_encoder_hour, deep_gru_fc_dst_hour, deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-2\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 5e-1\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min_history += RefinedGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RefinedGRU_hour_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 58\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedGRU_hour\u001b[39m.\u001b[39mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RefinedGRU_hour_history' is not defined"
     ]
    }
   ],
   "source": [
    "RefinedGRU_hour_history += RefinedGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep Vanilla RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute encoders\n",
    "deep_rnn_encoder_min_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "bidirectional_deeprnn_encoder_min = BidirectionalRNN(deep_rnn_encoder_min_forward,deep_rnn_encoder_min_backward)\n",
    "##Bidirectional hour encoders\n",
    "deep_rnn_encoder_hour_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "bidirectional_deeprnn_encoder_hour = BidirectionalRNN(deep_rnn_encoder_hour_forward,deep_rnn_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min = to_device(RefinedArchitecture(bidirectional_deeprnn_encoder_min, deep_rnn_fc_dst_min, deep_rnn_fc_kp_min), device)\n",
    "RefinedVanillaRNN_hour = to_device(RefinedArchitecture(bidirectional_deeprnn_encoder_hour, deep_rnn_fc_dst_hour, deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min_history += RefinedVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3494\n",
      "\ttrain_main_loss: 1.3494\n",
      "\ttrain_output_loss: 0.0001\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.2106\n",
      "\tval_main_loss: 1.2106\n",
      "\tval_output_loss: 0.0002\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 1.0410\n",
      "\ttrain_main_loss: 1.0410\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.0773\n",
      "\tval_main_loss: 1.0773\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 71\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:248\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    245\u001b[0m     sched\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    247\u001b[0m \u001b[39m# Fase de validación\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(val_loader)\n\u001b[0;32m    249\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mtrain_overall_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(train_losses)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem() \n\u001b[0;32m    250\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mtrain_main_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(main_losses)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem() \n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:201\u001b[0m, in \u001b[0;36mRefinedArchitecture.evaluate\u001b[1;34m(self, val_loader)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, val_loader):\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 201\u001b[0m     outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m    202\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:201\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, val_loader):\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 201\u001b[0m     outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m    202\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedVanillaRNN_hour_history += RefinedVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional non deep architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_lstm_forward_min = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_min = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_min = BidirectionalRNNWithAttention(non_deep_lstm_forward_min, non_deep_lstm_backward_min)\n",
    "\n",
    "non_deep_lstm_forward_hour = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_hour = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_hour = BidirectionalRNNWithAttention(non_deep_lstm_forward_hour, non_deep_lstm_backward_hour)\n",
    "#fc layer\n",
    "non_deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min = to_device(RefinedArchitecture(bidirectional_lstm_encoder_min, non_deep_lstm_fc_dst_min, non_deep_lstm_fc_kp_min), device)\n",
    "RefinedNonDeepLSTM_hour = to_device(RefinedArchitecture(bidirectional_lstm_encoder_hour, non_deep_lstm_fc_dst_hour, non_deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min_history += RefinedNonDeepLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3338\n",
      "\ttrain_main_loss: 1.3338\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.1319\n",
      "\tval_main_loss: 1.1319\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 0.9605\n",
      "\ttrain_main_loss: 0.9605\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.9760\n",
      "\tval_main_loss: 0.9760\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.8491\n",
      "\ttrain_main_loss: 0.8491\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.8663\n",
      "\tval_main_loss: 0.8663\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_overall_loss: 0.7699\n",
      "\ttrain_main_loss: 0.7698\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.7792\n",
      "\tval_main_loss: 0.7792\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_overall_loss: 0.7140\n",
      "\ttrain_main_loss: 0.7140\n",
      "\ttrain_output_loss: 0.0012\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.7207\n",
      "\tval_main_loss: 0.7206\n",
      "\tval_output_loss: 0.0008\n",
      "\tval_encoder_loss: 0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 79\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y314sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepLSTM_hour_history += RefinedNonDeepLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_gru_forward_min = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_min = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_min = BidirectionalRNNWithAttention(non_deep_gru_forward_min, non_deep_gru_backward_min)\n",
    "\n",
    "non_deep_gru_forward_hour = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_hour = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_hour = BidirectionalRNNWithAttention(non_deep_gru_forward_hour, non_deep_gru_backward_hour)\n",
    "#fc layer\n",
    "non_deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min = to_device(RefinedArchitecture(bidirectional_gru_encoder_min, non_deep_gru_fc_dst_min, non_deep_gru_fc_kp_min), device)\n",
    "RefinedNonDeepGRU_hour = to_device(RefinedArchitecture(bidirectional_gru_encoder_hour, non_deep_gru_fc_dst_hour, non_deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min_history += RefinedNonDeepGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3516\n",
      "\ttrain_main_loss: 1.3516\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.1860\n",
      "\tval_main_loss: 1.1860\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 0.9823\n",
      "\ttrain_main_loss: 0.9823\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.0192\n",
      "\tval_main_loss: 1.0192\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.8637\n",
      "\ttrain_main_loss: 0.8637\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.9084\n",
      "\tval_main_loss: 0.9084\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_overall_loss: 0.7905\n",
      "\ttrain_main_loss: 0.7905\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.8263\n",
      "\tval_main_loss: 0.8263\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_overall_loss: 0.7357\n",
      "\ttrain_main_loss: 0.7357\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7559\n",
      "\tval_main_loss: 0.7559\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 86\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepGRU_hour_history += RefinedNonDeepGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_rnn_forward_min = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_min = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_min = BidirectionalRNNWithAttention(non_deep_rnn_forward_min, non_deep_rnn_backward_min)\n",
    "\n",
    "non_deep_rnn_forward_hour = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_hour = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_hour = BidirectionalRNNWithAttention(non_deep_rnn_forward_hour, non_deep_rnn_backward_hour)\n",
    "#fc layer\n",
    "non_deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min = to_device(RefinedArchitecture(bidirectional_rnn_encoder_min, non_deep_rnn_fc_dst_min, non_deep_rnn_fc_kp_min), device)\n",
    "RefinedNonDeepVanillaRNN_hour = to_device(RefinedArchitecture(bidirectional_rnn_encoder_hour, non_deep_rnn_fc_dst_hour, non_deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history += RefinedNonDeepVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.2946\n",
      "\ttrain_main_loss: 1.2946\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.1871\n",
      "\tval_main_loss: 1.1871\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 1.0257\n",
      "\ttrain_main_loss: 1.0257\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.0831\n",
      "\tval_main_loss: 1.0830\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.9554\n",
      "\ttrain_main_loss: 0.9554\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.0201\n",
      "\tval_main_loss: 1.0201\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 93\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y161sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepVanillaRNN_hour_history += RefinedNonDeepVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal models with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Convolutional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "cnn_encoder_min = Simple1DCNN(architecture, input_size, hidden_size)\n",
    "cnn_encoder_hour = Simple1DCNN(architecture, input_size, hidden_size)\n",
    "#fc layer\n",
    "cnn_fc_dst_min = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_min = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "cnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min = to_device(NormalArchitecture(cnn_encoder_min, cnn_fc_dst_min, cnn_fc_kp_min), device)\n",
    "NormalCNN_hour = to_device(NormalArchitecture(cnn_encoder_hour, cnn_fc_dst_hour, cnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min_history += NormalCNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [10, 20, 3], expected input[32, 10, 20] to have 20 channels, but got 10 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 103\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y204sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalCNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalCNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:72\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:23\u001b[0m, in \u001b[0;36mNormalArchitecture.training_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     21\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m#initialize loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m feature, dst, kp \u001b[39m=\u001b[39m batch \u001b[39m#decompose batch\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m dst_out, kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(feature)        \n\u001b[0;32m     24\u001b[0m \u001b[39m#dst index cost-1st head\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(dst_out, dst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:16\u001b[0m, in \u001b[0;36mNormalArchitecture.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     17\u001b[0m     dst_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_dst(out)\n\u001b[0;32m     18\u001b[0m     kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_kp(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:55\u001b[0m, in \u001b[0;36mSimple1DCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 55\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1d(x)\n\u001b[0;32m     56\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     57\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 20, 3], expected input[32, 10, 20] to have 20 channels, but got 10 channels instead"
     ]
    }
   ],
   "source": [
    "NormalCNN_hour_history += NormalCNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_lstm_encoder_min_forward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_min_backward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_min = BidirectionalRNNWithAttention(deep_lstm_encoder_min_forward,deep_lstm_encoder_min_backward)\n",
    "\n",
    "deep_lstm_encoder_hour_forward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_hour_backward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_hour = BidirectionalRNNWithAttention(deep_lstm_encoder_hour_forward,deep_lstm_encoder_hour_backward)\n",
    "\n",
    "#fc layer\n",
    "deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min = to_device(NormalArchitecture(deep_lstm_encoder_min, deep_lstm_fc_dst_min, deep_lstm_fc_kp_min), device)\n",
    "NormalLSTM_hour = to_device(NormalArchitecture(deep_lstm_encoder_hour, deep_lstm_fc_dst_hour, deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min_history += NormalLSTM_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 1.3096\n",
      "\tval_loss: 0.9849\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 0.9692\n",
      "\tval_loss: 0.8660\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_loss: 0.8529\n",
      "\tval_loss: 0.7863\n",
      "Epoch [3]:\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_loss: 0.7619\n",
      "\tval_loss: 0.7326\n",
      "Epoch [4]:\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_loss: 0.7028\n",
      "\tval_loss: 0.6870\n",
      "Epoch [5]:\n",
      "\tlast_lr: 0.00013\n",
      "\ttrain_loss: 0.6619\n",
      "\tval_loss: 0.6704\n",
      "Epoch [6]:\n",
      "\tlast_lr: 0.00016\n",
      "\ttrain_loss: 0.6341\n",
      "\tval_loss: 0.6449\n",
      "Epoch [7]:\n",
      "\tlast_lr: 0.00020\n",
      "\ttrain_loss: 0.6039\n",
      "\tval_loss: 0.6322\n",
      "Epoch [8]:\n",
      "\tlast_lr: 0.00024\n",
      "\ttrain_loss: 0.5860\n",
      "\tval_loss: 0.6194\n",
      "Epoch [9]:\n",
      "\tlast_lr: 0.00028\n",
      "\ttrain_loss: 0.5695\n",
      "\tval_loss: 0.5994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 112\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y216sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:76\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     74\u001b[0m train_losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m     75\u001b[0m \u001b[39m#Calcular las derivadas parciales\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     78\u001b[0m \u001b[39m# Gradient clipping, para que no ocurra el exploding gradient\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m grad_clip:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalLSTM_hour_history += NormalLSTM_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "\n",
    "deep_gru_encoder_min_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min = BidirectionalRNNWithAttention(deep_gru_encoder_min_forward,deep_gru_encoder_min_backward)\n",
    "\n",
    "deep_gru_encoder_hour_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour = BidirectionalRNNWithAttention(deep_gru_encoder_hour_forward,deep_gru_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size,hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min = to_device(NormalArchitecture(deep_gru_encoder_min, deep_gru_fc_dst_min, deep_gru_fc_kp_min), device)\n",
    "NormalGRU_hour = to_device(NormalArchitecture(deep_gru_encoder_hour, deep_gru_fc_dst_hour, deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 119\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y226sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalGRU_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalGRU_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:72\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:23\u001b[0m, in \u001b[0;36mNormalArchitecture.training_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     21\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m#initialize loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m feature, dst, kp \u001b[39m=\u001b[39m batch \u001b[39m#decompose batch\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m dst_out, kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(feature)        \n\u001b[0;32m     24\u001b[0m \u001b[39m#dst index cost-1st head\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(dst_out, dst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:16\u001b[0m, in \u001b[0;36mNormalArchitecture.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     17\u001b[0m     dst_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_dst(out)\n\u001b[0;32m     18\u001b[0m     kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_kp(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:241\u001b[0m, in \u001b[0;36mBidirectionalRNNWithAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    240\u001b[0m     \u001b[39m# Forward pass through the first RNN\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     hidden1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn1(x)\n\u001b[0;32m    242\u001b[0m     \u001b[39m# Reverse the input sequence for the second RNN\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     x_backward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflip(x, [\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:153\u001b[0m, in \u001b[0;36mDeepGRU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    151\u001b[0m xt \u001b[39m=\u001b[39m x[:, t, :]\n\u001b[0;32m    152\u001b[0m Z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ_h(hn)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ_x(xt))\n\u001b[1;32m--> 153\u001b[0m R \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mR_h(hn)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mR_x(xt))\n\u001b[0;32m    154\u001b[0m H_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_hat_h(hn\u001b[39m*\u001b[39mR)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_hat_x(xt))\n\u001b[0;32m    155\u001b[0m hn \u001b[39m=\u001b[39m hn\u001b[39m*\u001b[39mZ \u001b[39m+\u001b[39m (torch\u001b[39m.\u001b[39mones_like(Z)\u001b[39m-\u001b[39mZ)\u001b[39m*\u001b[39mH_hat\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:42\u001b[0m, in \u001b[0;36mDeepNeuralNetwork.forward\u001b[1;34m(self, xb)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xb):\n\u001b[0;32m     41\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_structure(xb)\n\u001b[1;32m---> 42\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_layer(out)\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "NormalGRU_min_history += NormalGRU_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 0.9408\n",
      "\tval_loss: 0.8459\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 121\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y231sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:83\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     80\u001b[0m     nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_value_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters(), grad_clip)\n\u001b[0;32m     82\u001b[0m \u001b[39m#Efectuar el descensod e gradiente y borrar el historial\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     84\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     86\u001b[0m \u001b[39m# Guardar el learning rate utilizado en el cycle.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:269\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[0;32m    268\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m    270\u001b[0m     \u001b[39m# call optimizer step pre hooks\u001b[39;00m\n\u001b[0;32m    271\u001b[0m     \u001b[39mfor\u001b[39;00m pre_hook \u001b[39min\u001b[39;00m chain(_global_optimizer_pre_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_pre_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    272\u001b[0m         result \u001b[39m=\u001b[39m pre_hook(\u001b[39mself\u001b[39m, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n\u001b[0;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs \u001b[39mor\u001b[39;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalGRU_hour_history += NormalGRU_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep Vanilla RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_rnn_encoder_min_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min = BidirectionalRNNWithAttention(deep_rnn_encoder_min_forward, deep_rnn_encoder_min_backward)\n",
    "\n",
    "deep_rnn_encoder_hour_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour = BidirectionalRNNWithAttention(deep_rnn_encoder_hour_forward,deep_rnn_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min = to_device(NormalArchitecture(deep_rnn_encoder_min, deep_rnn_fc_dst_min, deep_rnn_fc_kp_min), device)\n",
    "NormalVanillaRNN_hour = to_device(NormalArchitecture(deep_rnn_encoder_hour, deep_rnn_fc_dst_hour, deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min_history += NormalVanillaRNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 1.3040\n",
      "\tval_loss: 1.0009\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 1.0306\n",
      "\tval_loss: 0.9201\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_loss: 0.9532\n",
      "\tval_loss: 0.8801\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 130\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y243sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalVanillaRNN_hour_history += NormalVanillaRNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non deep bidirectional architectures with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_lstm_forward_min = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_min = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_min = BidirectionalRNNWithAttention(non_deep_lstm_forward_min, non_deep_lstm_backward_min)\n",
    "\n",
    "non_deep_lstm_forward_hour = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_hour = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_hour = BidirectionalRNNWithAttention(non_deep_lstm_forward_hour, non_deep_lstm_backward_hour)\n",
    "#fc layer\n",
    "non_deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min = to_device(NormalArchitecture(bidirectional_lstm_encoder_min, non_deep_lstm_fc_dst_min, non_deep_lstm_fc_kp_min), device)\n",
    "NormalNonDeepLSTM_hour = to_device(NormalArchitecture(bidirectional_lstm_encoder_hour, non_deep_lstm_fc_dst_hour, non_deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min_history += NormalNonDeepLSTM_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.0350\n",
      "\tval_loss: 2.0597\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_loss: 2.0237\n",
      "\tval_loss: 2.0414\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00026\n",
      "\ttrain_loss: 1.9437\n",
      "\tval_loss: 1.7768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 138\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y254sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepLSTM_hour_history += NormalNonDeepLSTM_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_gru_forward_min = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_min = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_min = BidirectionalRNNWithAttention(non_deep_gru_forward_min, non_deep_gru_backward_min)\n",
    "\n",
    "non_deep_gru_forward_hour = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_hour = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_hour = BidirectionalRNNWithAttention(non_deep_gru_forward_hour, non_deep_gru_backward_hour)\n",
    "#fc layer\n",
    "non_deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min = to_device(NormalArchitecture(bidirectional_gru_encoder_min, non_deep_gru_fc_dst_min, non_deep_gru_fc_kp_min), device)\n",
    "NormalNonDeepGRU_hour = to_device(NormalArchitecture(bidirectional_gru_encoder_hour, non_deep_gru_fc_dst_hour, non_deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min_history += NormalNonDeepGRU_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.1161\n",
      "\tval_loss: 2.1215\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_loss: 2.0831\n",
      "\tval_loss: 2.0747\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 145\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y264sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepGRU_hour_history += NormalNonDeepGRU_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_rnn_forward_min = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_min = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_min = BidirectionalRNNWithAttention(non_deep_rnn_forward_min, non_deep_rnn_backward_min)\n",
    "\n",
    "non_deep_rnn_forward_hour = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_hour = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_hour = BidirectionalRNNWithAttention(non_deep_rnn_forward_hour, non_deep_rnn_backward_hour)\n",
    "#fc layer\n",
    "non_deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_min = to_device(NormalArchitecture(bidirectional_rnn_encoder_min, non_deep_rnn_fc_dst_min, non_deep_rnn_fc_kp_min), device)\n",
    "NormalNonDeepVanillaRNN_hour = to_device(NormalArchitecture(bidirectional_rnn_encoder_hour, non_deep_rnn_fc_dst_hour, non_deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history += NormalNonDeepVanillaRNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.0527\n",
      "\tval_loss: 2.0624\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 152\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y304sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepVanillaRNN_hour_history += NormalNonDeepVanillaRNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq MultiHead2MultiHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 10\n",
    "max_lr = 1e-2\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 1e-1\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_fc = EncoderMultiheadAttentionGRU(9, hidden_size, 3, architecture)\n",
    "encoder_mg = EncoderMultiheadAttentionGRU(11, hidden_size, 1, architecture)\n",
    "fc = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length))\n",
    "model = MultiHead2SingleOUT(encoder_fc, encoder_mg, fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_fc = EncoderMultiheadAttentionGRU(9, hidden_size, 3, architecture)\n",
    "encoder_mg = EncoderMultiheadAttentionGRU(11, hidden_size, 1, architecture)\n",
    "model = MultiHeaded2MultiheadAttentionGRU(encoder_fc, encoder_mg, 2, architecture, hour_to_3_hour(pred_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [0] at entry 0 and [3] at entry 27\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 162\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#Z2033sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m new_model\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hour_kp_dl, test_hour_kp_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:36\u001b[0m, in \u001b[0;36mDefaultBase.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     34\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     37\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     39\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\utils.py:66\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     67\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    692\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [0] at entry 0 and [3] at entry 27\n"
     ]
    }
   ],
   "source": [
    "new_model+=model.fit(epochs, max_lr, train_hour_kp_dl, test_hour_kp_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
