{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocessing import *\n",
    "from data.data_utils import *\n",
    "from models.macro_architectures import *\n",
    "from models.micro_architectures import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format: YYYYMMDD\n",
    "start_time = '20220801'\n",
    "end_time = '20230801'\n",
    "scrap_date = interval_time(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(set([day[:6] for day in scrap_date]))\n",
    "import_Dst(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_sample, l2_sample, dst, kp = automated_preprocessing(scrap_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving missing values with interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_ = f'{start_time[:4]}-{start_time[4:6]}-{start_time[-2:]} 00:00:00'\n",
    "end_time_ = f'{end_time[:4]}-{end_time[4:6]}-{end_time[-2:]} 23:59:00' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = '1T'\n",
    "\n",
    "full_time_index = pd.date_range(start=start_time_, end=end_time_, freq=freq)\n",
    "\n",
    "l1_sample = l1_sample.reindex(full_time_index)\n",
    "\n",
    "l1_sample = l1_sample.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_sample = l2_sample.reindex(full_time_index)\n",
    "\n",
    "l2_sample = l2_sample.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 (raw) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>-478.65714</td>\n",
       "      <td>43.071430</td>\n",
       "      <td>-18.400000</td>\n",
       "      <td>-478.65714</td>\n",
       "      <td>40.957146</td>\n",
       "      <td>-22.714285</td>\n",
       "      <td>480.95712</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>173441.860</td>\n",
       "      <td>8.791893</td>\n",
       "      <td>7.086200</td>\n",
       "      <td>-4.019755</td>\n",
       "      <td>3.270043</td>\n",
       "      <td>21.840690</td>\n",
       "      <td>330.44970</td>\n",
       "      <td>7.086200</td>\n",
       "      <td>-3.664647</td>\n",
       "      <td>3.663627</td>\n",
       "      <td>24.632782</td>\n",
       "      <td>332.67020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:01:00</th>\n",
       "      <td>-480.98570</td>\n",
       "      <td>42.057140</td>\n",
       "      <td>-22.585714</td>\n",
       "      <td>-480.98570</td>\n",
       "      <td>39.514286</td>\n",
       "      <td>-26.742857</td>\n",
       "      <td>483.37143</td>\n",
       "      <td>8.464286</td>\n",
       "      <td>185467.140</td>\n",
       "      <td>8.582591</td>\n",
       "      <td>6.739781</td>\n",
       "      <td>-4.466785</td>\n",
       "      <td>2.769711</td>\n",
       "      <td>18.872953</td>\n",
       "      <td>326.47080</td>\n",
       "      <td>6.739781</td>\n",
       "      <td>-4.159703</td>\n",
       "      <td>3.212529</td>\n",
       "      <td>22.036581</td>\n",
       "      <td>328.33280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:02:00</th>\n",
       "      <td>-491.07144</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>-22.014284</td>\n",
       "      <td>-491.07144</td>\n",
       "      <td>53.642857</td>\n",
       "      <td>-27.642857</td>\n",
       "      <td>495.05713</td>\n",
       "      <td>9.305715</td>\n",
       "      <td>218374.280</td>\n",
       "      <td>7.703689</td>\n",
       "      <td>5.968021</td>\n",
       "      <td>-2.387868</td>\n",
       "      <td>3.884053</td>\n",
       "      <td>30.909138</td>\n",
       "      <td>339.15740</td>\n",
       "      <td>5.968021</td>\n",
       "      <td>-1.976642</td>\n",
       "      <td>4.108515</td>\n",
       "      <td>32.785530</td>\n",
       "      <td>314.55447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:03:00</th>\n",
       "      <td>-493.52856</td>\n",
       "      <td>68.014290</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>-493.52856</td>\n",
       "      <td>65.214290</td>\n",
       "      <td>-30.857143</td>\n",
       "      <td>498.91428</td>\n",
       "      <td>9.671428</td>\n",
       "      <td>228698.580</td>\n",
       "      <td>7.239092</td>\n",
       "      <td>5.971862</td>\n",
       "      <td>-0.815659</td>\n",
       "      <td>3.879902</td>\n",
       "      <td>32.538246</td>\n",
       "      <td>309.05472</td>\n",
       "      <td>5.971862</td>\n",
       "      <td>-0.412276</td>\n",
       "      <td>3.943251</td>\n",
       "      <td>33.105440</td>\n",
       "      <td>263.87167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:04:00</th>\n",
       "      <td>-484.83334</td>\n",
       "      <td>53.383330</td>\n",
       "      <td>-15.783334</td>\n",
       "      <td>-484.83334</td>\n",
       "      <td>51.483334</td>\n",
       "      <td>-21.199999</td>\n",
       "      <td>488.08334</td>\n",
       "      <td>9.080000</td>\n",
       "      <td>204210.000</td>\n",
       "      <td>7.844100</td>\n",
       "      <td>6.698265</td>\n",
       "      <td>-1.942467</td>\n",
       "      <td>3.496836</td>\n",
       "      <td>26.688057</td>\n",
       "      <td>343.98862</td>\n",
       "      <td>6.698265</td>\n",
       "      <td>-1.571605</td>\n",
       "      <td>3.678486</td>\n",
       "      <td>28.167646</td>\n",
       "      <td>346.98236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:55:00</th>\n",
       "      <td>-390.41000</td>\n",
       "      <td>20.689999</td>\n",
       "      <td>-2.420000</td>\n",
       "      <td>-390.41000</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>-4.620000</td>\n",
       "      <td>390.99000</td>\n",
       "      <td>8.613000</td>\n",
       "      <td>79090.400</td>\n",
       "      <td>8.708879</td>\n",
       "      <td>3.890249</td>\n",
       "      <td>-7.049568</td>\n",
       "      <td>3.313216</td>\n",
       "      <td>22.363012</td>\n",
       "      <td>298.89180</td>\n",
       "      <td>3.890249</td>\n",
       "      <td>-6.658564</td>\n",
       "      <td>4.041955</td>\n",
       "      <td>27.656048</td>\n",
       "      <td>300.29570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:56:00</th>\n",
       "      <td>-393.74445</td>\n",
       "      <td>17.411110</td>\n",
       "      <td>-2.655556</td>\n",
       "      <td>-393.74445</td>\n",
       "      <td>17.011112</td>\n",
       "      <td>-4.477778</td>\n",
       "      <td>394.14444</td>\n",
       "      <td>9.308888</td>\n",
       "      <td>104618.664</td>\n",
       "      <td>8.466495</td>\n",
       "      <td>3.683012</td>\n",
       "      <td>-7.056999</td>\n",
       "      <td>2.848440</td>\n",
       "      <td>19.695435</td>\n",
       "      <td>297.55127</td>\n",
       "      <td>3.683012</td>\n",
       "      <td>-6.714469</td>\n",
       "      <td>3.581986</td>\n",
       "      <td>25.071960</td>\n",
       "      <td>298.73755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:57:00</th>\n",
       "      <td>-390.28183</td>\n",
       "      <td>17.427273</td>\n",
       "      <td>-3.790909</td>\n",
       "      <td>-390.28183</td>\n",
       "      <td>16.936363</td>\n",
       "      <td>-5.627273</td>\n",
       "      <td>390.70908</td>\n",
       "      <td>8.784545</td>\n",
       "      <td>78793.630</td>\n",
       "      <td>8.379578</td>\n",
       "      <td>3.853854</td>\n",
       "      <td>-6.783406</td>\n",
       "      <td>3.052517</td>\n",
       "      <td>21.368494</td>\n",
       "      <td>299.60187</td>\n",
       "      <td>3.853854</td>\n",
       "      <td>-6.419947</td>\n",
       "      <td>3.757228</td>\n",
       "      <td>26.645920</td>\n",
       "      <td>300.97607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:58:00</th>\n",
       "      <td>-391.43634</td>\n",
       "      <td>20.827272</td>\n",
       "      <td>2.209091</td>\n",
       "      <td>-391.43634</td>\n",
       "      <td>20.954546</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>392.16360</td>\n",
       "      <td>9.211819</td>\n",
       "      <td>100566.910</td>\n",
       "      <td>8.261917</td>\n",
       "      <td>4.074574</td>\n",
       "      <td>-4.820900</td>\n",
       "      <td>4.966876</td>\n",
       "      <td>37.815850</td>\n",
       "      <td>311.42163</td>\n",
       "      <td>4.074574</td>\n",
       "      <td>-4.263566</td>\n",
       "      <td>5.452666</td>\n",
       "      <td>42.207394</td>\n",
       "      <td>315.36426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:59:00</th>\n",
       "      <td>-389.10000</td>\n",
       "      <td>25.187500</td>\n",
       "      <td>9.925000</td>\n",
       "      <td>-389.10000</td>\n",
       "      <td>26.125000</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>390.10000</td>\n",
       "      <td>8.717500</td>\n",
       "      <td>76896.375</td>\n",
       "      <td>8.233093</td>\n",
       "      <td>4.010084</td>\n",
       "      <td>-4.380499</td>\n",
       "      <td>5.672841</td>\n",
       "      <td>43.632923</td>\n",
       "      <td>312.56330</td>\n",
       "      <td>4.010084</td>\n",
       "      <td>-3.749102</td>\n",
       "      <td>6.108538</td>\n",
       "      <td>47.981370</td>\n",
       "      <td>317.04538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527040 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2022-08-01 00:00:00     -478.65714      43.071430     -18.400000   \n",
       "2022-08-01 00:01:00     -480.98570      42.057140     -22.585714   \n",
       "2022-08-01 00:02:00     -491.07144      56.200000     -22.014284   \n",
       "2022-08-01 00:03:00     -493.52856      68.014290     -24.000000   \n",
       "2022-08-01 00:04:00     -484.83334      53.383330     -15.783334   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 23:55:00     -390.41000      20.689999      -2.420000   \n",
       "2023-08-01 23:56:00     -393.74445      17.411110      -2.655556   \n",
       "2023-08-01 23:57:00     -390.28183      17.427273      -3.790909   \n",
       "2023-08-01 23:58:00     -391.43634      20.827272       2.209091   \n",
       "2023-08-01 23:59:00     -389.10000      25.187500       9.925000   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2022-08-01 00:00:00     -478.65714      40.957146     -22.714285   \n",
       "2022-08-01 00:01:00     -480.98570      39.514286     -26.742857   \n",
       "2022-08-01 00:02:00     -491.07144      53.642857     -27.642857   \n",
       "2022-08-01 00:03:00     -493.52856      65.214290     -30.857143   \n",
       "2022-08-01 00:04:00     -484.83334      51.483334     -21.199999   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 23:55:00     -390.41000      20.330000      -4.620000   \n",
       "2023-08-01 23:56:00     -393.74445      17.011112      -4.477778   \n",
       "2023-08-01 23:57:00     -390.28183      16.936363      -5.627273   \n",
       "2023-08-01 23:58:00     -391.43634      20.954546      -0.027273   \n",
       "2023-08-01 23:59:00     -389.10000      26.125000       7.187500   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2022-08-01 00:00:00     480.95712        8.510000          173441.860   \n",
       "2022-08-01 00:01:00     483.37143        8.464286          185467.140   \n",
       "2022-08-01 00:02:00     495.05713        9.305715          218374.280   \n",
       "2022-08-01 00:03:00     498.91428        9.671428          228698.580   \n",
       "2022-08-01 00:04:00     488.08334        9.080000          204210.000   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-01 23:55:00     390.99000        8.613000           79090.400   \n",
       "2023-08-01 23:56:00     394.14444        9.308888          104618.664   \n",
       "2023-08-01 23:57:00     390.70908        8.784545           78793.630   \n",
       "2023-08-01 23:58:00     392.16360        9.211819          100566.910   \n",
       "2023-08-01 23:59:00     390.10000        8.717500           76896.375   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2022-08-01 00:00:00  8.791893  7.086200 -4.019755  3.270043  21.840690   \n",
       "2022-08-01 00:01:00  8.582591  6.739781 -4.466785  2.769711  18.872953   \n",
       "2022-08-01 00:02:00  7.703689  5.968021 -2.387868  3.884053  30.909138   \n",
       "2022-08-01 00:03:00  7.239092  5.971862 -0.815659  3.879902  32.538246   \n",
       "2022-08-01 00:04:00  7.844100  6.698265 -1.942467  3.496836  26.688057   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-01 23:55:00  8.708879  3.890249 -7.049568  3.313216  22.363012   \n",
       "2023-08-01 23:56:00  8.466495  3.683012 -7.056999  2.848440  19.695435   \n",
       "2023-08-01 23:57:00  8.379578  3.853854 -6.783406  3.052517  21.368494   \n",
       "2023-08-01 23:58:00  8.261917  4.074574 -4.820900  4.966876  37.815850   \n",
       "2023-08-01 23:59:00  8.233093  4.010084 -4.380499  5.672841  43.632923   \n",
       "\n",
       "                       phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2022-08-01 00:00:00  330.44970  7.086200 -3.664647  3.663627  24.632782   \n",
       "2022-08-01 00:01:00  326.47080  6.739781 -4.159703  3.212529  22.036581   \n",
       "2022-08-01 00:02:00  339.15740  5.968021 -1.976642  4.108515  32.785530   \n",
       "2022-08-01 00:03:00  309.05472  5.971862 -0.412276  3.943251  33.105440   \n",
       "2022-08-01 00:04:00  343.98862  6.698265 -1.571605  3.678486  28.167646   \n",
       "...                        ...       ...       ...       ...        ...   \n",
       "2023-08-01 23:55:00  298.89180  3.890249 -6.658564  4.041955  27.656048   \n",
       "2023-08-01 23:56:00  297.55127  3.683012 -6.714469  3.581986  25.071960   \n",
       "2023-08-01 23:57:00  299.60187  3.853854 -6.419947  3.757228  26.645920   \n",
       "2023-08-01 23:58:00  311.42163  4.074574 -4.263566  5.452666  42.207394   \n",
       "2023-08-01 23:59:00  312.56330  4.010084 -3.749102  6.108538  47.981370   \n",
       "\n",
       "                       phi_gsm  \n",
       "2022-08-01 00:00:00  332.67020  \n",
       "2022-08-01 00:01:00  328.33280  \n",
       "2022-08-01 00:02:00  314.55447  \n",
       "2022-08-01 00:03:00  263.87167  \n",
       "2022-08-01 00:04:00  346.98236  \n",
       "...                        ...  \n",
       "2023-08-01 23:55:00  300.29570  \n",
       "2023-08-01 23:56:00  298.73755  \n",
       "2023-08-01 23:57:00  300.97607  \n",
       "2023-08-01 23:58:00  315.36426  \n",
       "2023-08-01 23:59:00  317.04538  \n",
       "\n",
       "[527040 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>-489.302281</td>\n",
       "      <td>57.179857</td>\n",
       "      <td>-21.269801</td>\n",
       "      <td>-489.302281</td>\n",
       "      <td>54.485076</td>\n",
       "      <td>-27.490186</td>\n",
       "      <td>493.251960</td>\n",
       "      <td>9.247633</td>\n",
       "      <td>198485.987167</td>\n",
       "      <td>7.543399</td>\n",
       "      <td>6.291421</td>\n",
       "      <td>-1.856414</td>\n",
       "      <td>2.859877</td>\n",
       "      <td>22.954698</td>\n",
       "      <td>300.997411</td>\n",
       "      <td>6.291421</td>\n",
       "      <td>-1.527907</td>\n",
       "      <td>3.041643</td>\n",
       "      <td>24.361645</td>\n",
       "      <td>297.380635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 01:00:00</th>\n",
       "      <td>-508.790815</td>\n",
       "      <td>51.889845</td>\n",
       "      <td>-27.850028</td>\n",
       "      <td>-508.790815</td>\n",
       "      <td>47.635167</td>\n",
       "      <td>-34.453706</td>\n",
       "      <td>512.453934</td>\n",
       "      <td>9.912636</td>\n",
       "      <td>234197.626667</td>\n",
       "      <td>6.141733</td>\n",
       "      <td>4.452409</td>\n",
       "      <td>-2.402331</td>\n",
       "      <td>1.739807</td>\n",
       "      <td>16.432656</td>\n",
       "      <td>265.105190</td>\n",
       "      <td>4.452409</td>\n",
       "      <td>-2.157465</td>\n",
       "      <td>2.061328</td>\n",
       "      <td>19.703389</td>\n",
       "      <td>240.259886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 02:00:00</th>\n",
       "      <td>-522.989989</td>\n",
       "      <td>46.409234</td>\n",
       "      <td>-34.373814</td>\n",
       "      <td>-522.989989</td>\n",
       "      <td>40.170385</td>\n",
       "      <td>-41.611131</td>\n",
       "      <td>526.401869</td>\n",
       "      <td>9.133113</td>\n",
       "      <td>218915.152667</td>\n",
       "      <td>5.931544</td>\n",
       "      <td>0.184564</td>\n",
       "      <td>-2.469814</td>\n",
       "      <td>-0.172089</td>\n",
       "      <td>-2.568171</td>\n",
       "      <td>204.232442</td>\n",
       "      <td>0.184564</td>\n",
       "      <td>-2.453588</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>1.573937</td>\n",
       "      <td>197.414516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 03:00:00</th>\n",
       "      <td>-498.359199</td>\n",
       "      <td>43.835917</td>\n",
       "      <td>-35.477302</td>\n",
       "      <td>-498.359199</td>\n",
       "      <td>35.712523</td>\n",
       "      <td>-43.524897</td>\n",
       "      <td>501.855898</td>\n",
       "      <td>7.695283</td>\n",
       "      <td>193808.512500</td>\n",
       "      <td>6.292952</td>\n",
       "      <td>5.306359</td>\n",
       "      <td>-1.672818</td>\n",
       "      <td>1.302133</td>\n",
       "      <td>11.992297</td>\n",
       "      <td>274.047466</td>\n",
       "      <td>5.306359</td>\n",
       "      <td>-1.384970</td>\n",
       "      <td>1.622839</td>\n",
       "      <td>15.157878</td>\n",
       "      <td>257.554610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 04:00:00</th>\n",
       "      <td>-525.964391</td>\n",
       "      <td>31.554381</td>\n",
       "      <td>-37.966738</td>\n",
       "      <td>-525.964391</td>\n",
       "      <td>21.319488</td>\n",
       "      <td>-44.454766</td>\n",
       "      <td>528.562193</td>\n",
       "      <td>8.653108</td>\n",
       "      <td>209614.043500</td>\n",
       "      <td>5.501450</td>\n",
       "      <td>0.355088</td>\n",
       "      <td>-3.930183</td>\n",
       "      <td>-0.112578</td>\n",
       "      <td>-1.028107</td>\n",
       "      <td>266.247303</td>\n",
       "      <td>0.355088</td>\n",
       "      <td>-3.853669</td>\n",
       "      <td>0.840545</td>\n",
       "      <td>10.024766</td>\n",
       "      <td>266.188024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 19:00:00</th>\n",
       "      <td>-382.680769</td>\n",
       "      <td>0.217665</td>\n",
       "      <td>-15.192104</td>\n",
       "      <td>-382.680769</td>\n",
       "      <td>-2.215317</td>\n",
       "      <td>-15.036393</td>\n",
       "      <td>383.136132</td>\n",
       "      <td>9.807184</td>\n",
       "      <td>66666.911150</td>\n",
       "      <td>9.816390</td>\n",
       "      <td>6.217887</td>\n",
       "      <td>-7.306248</td>\n",
       "      <td>-0.344754</td>\n",
       "      <td>-2.062787</td>\n",
       "      <td>310.312771</td>\n",
       "      <td>6.217887</td>\n",
       "      <td>-7.258762</td>\n",
       "      <td>0.820913</td>\n",
       "      <td>4.873037</td>\n",
       "      <td>310.610893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 20:00:00</th>\n",
       "      <td>-382.508196</td>\n",
       "      <td>-0.425859</td>\n",
       "      <td>-19.921152</td>\n",
       "      <td>-382.508196</td>\n",
       "      <td>-2.982734</td>\n",
       "      <td>-19.695648</td>\n",
       "      <td>383.090436</td>\n",
       "      <td>10.251275</td>\n",
       "      <td>56155.322900</td>\n",
       "      <td>9.312197</td>\n",
       "      <td>5.133512</td>\n",
       "      <td>-7.576634</td>\n",
       "      <td>-1.271946</td>\n",
       "      <td>-7.821866</td>\n",
       "      <td>304.145239</td>\n",
       "      <td>5.133512</td>\n",
       "      <td>-7.679039</td>\n",
       "      <td>-0.282955</td>\n",
       "      <td>-1.693841</td>\n",
       "      <td>303.807800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 21:00:00</th>\n",
       "      <td>-378.749960</td>\n",
       "      <td>-7.459660</td>\n",
       "      <td>-28.139573</td>\n",
       "      <td>-378.749960</td>\n",
       "      <td>-10.480231</td>\n",
       "      <td>-27.167887</td>\n",
       "      <td>380.014618</td>\n",
       "      <td>9.695502</td>\n",
       "      <td>58283.928467</td>\n",
       "      <td>8.919270</td>\n",
       "      <td>5.942875</td>\n",
       "      <td>-6.403760</td>\n",
       "      <td>-0.588859</td>\n",
       "      <td>-3.800311</td>\n",
       "      <td>312.912670</td>\n",
       "      <td>5.942875</td>\n",
       "      <td>-6.430948</td>\n",
       "      <td>0.113013</td>\n",
       "      <td>0.756934</td>\n",
       "      <td>312.845110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 22:00:00</th>\n",
       "      <td>-388.897926</td>\n",
       "      <td>9.909498</td>\n",
       "      <td>-4.975384</td>\n",
       "      <td>-388.897926</td>\n",
       "      <td>9.369652</td>\n",
       "      <td>-5.926781</td>\n",
       "      <td>389.483691</td>\n",
       "      <td>9.748028</td>\n",
       "      <td>103017.672383</td>\n",
       "      <td>8.472186</td>\n",
       "      <td>5.815027</td>\n",
       "      <td>-5.407756</td>\n",
       "      <td>2.184644</td>\n",
       "      <td>14.794651</td>\n",
       "      <td>316.942325</td>\n",
       "      <td>5.815027</td>\n",
       "      <td>-5.162399</td>\n",
       "      <td>2.712489</td>\n",
       "      <td>18.609071</td>\n",
       "      <td>318.306821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:00:00</th>\n",
       "      <td>-390.817842</td>\n",
       "      <td>18.406591</td>\n",
       "      <td>-1.972806</td>\n",
       "      <td>-390.817842</td>\n",
       "      <td>18.118264</td>\n",
       "      <td>-3.852759</td>\n",
       "      <td>391.421486</td>\n",
       "      <td>8.746741</td>\n",
       "      <td>91400.260000</td>\n",
       "      <td>8.147829</td>\n",
       "      <td>4.140885</td>\n",
       "      <td>-5.553662</td>\n",
       "      <td>3.373441</td>\n",
       "      <td>24.279417</td>\n",
       "      <td>306.572643</td>\n",
       "      <td>4.140885</td>\n",
       "      <td>-5.176985</td>\n",
       "      <td>3.923564</td>\n",
       "      <td>28.809884</td>\n",
       "      <td>307.551947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8784 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2022-08-01 00:00:00    -489.302281      57.179857     -21.269801   \n",
       "2022-08-01 01:00:00    -508.790815      51.889845     -27.850028   \n",
       "2022-08-01 02:00:00    -522.989989      46.409234     -34.373814   \n",
       "2022-08-01 03:00:00    -498.359199      43.835917     -35.477302   \n",
       "2022-08-01 04:00:00    -525.964391      31.554381     -37.966738   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 19:00:00    -382.680769       0.217665     -15.192104   \n",
       "2023-08-01 20:00:00    -382.508196      -0.425859     -19.921152   \n",
       "2023-08-01 21:00:00    -378.749960      -7.459660     -28.139573   \n",
       "2023-08-01 22:00:00    -388.897926       9.909498      -4.975384   \n",
       "2023-08-01 23:00:00    -390.817842      18.406591      -1.972806   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2022-08-01 00:00:00    -489.302281      54.485076     -27.490186   \n",
       "2022-08-01 01:00:00    -508.790815      47.635167     -34.453706   \n",
       "2022-08-01 02:00:00    -522.989989      40.170385     -41.611131   \n",
       "2022-08-01 03:00:00    -498.359199      35.712523     -43.524897   \n",
       "2022-08-01 04:00:00    -525.964391      21.319488     -44.454766   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 19:00:00    -382.680769      -2.215317     -15.036393   \n",
       "2023-08-01 20:00:00    -382.508196      -2.982734     -19.695648   \n",
       "2023-08-01 21:00:00    -378.749960     -10.480231     -27.167887   \n",
       "2023-08-01 22:00:00    -388.897926       9.369652      -5.926781   \n",
       "2023-08-01 23:00:00    -390.817842      18.118264      -3.852759   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2022-08-01 00:00:00    493.251960        9.247633       198485.987167   \n",
       "2022-08-01 01:00:00    512.453934        9.912636       234197.626667   \n",
       "2022-08-01 02:00:00    526.401869        9.133113       218915.152667   \n",
       "2022-08-01 03:00:00    501.855898        7.695283       193808.512500   \n",
       "2022-08-01 04:00:00    528.562193        8.653108       209614.043500   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-01 19:00:00    383.136132        9.807184        66666.911150   \n",
       "2023-08-01 20:00:00    383.090436       10.251275        56155.322900   \n",
       "2023-08-01 21:00:00    380.014618        9.695502        58283.928467   \n",
       "2023-08-01 22:00:00    389.483691        9.748028       103017.672383   \n",
       "2023-08-01 23:00:00    391.421486        8.746741        91400.260000   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2022-08-01 00:00:00  7.543399  6.291421 -1.856414  2.859877  22.954698   \n",
       "2022-08-01 01:00:00  6.141733  4.452409 -2.402331  1.739807  16.432656   \n",
       "2022-08-01 02:00:00  5.931544  0.184564 -2.469814 -0.172089  -2.568171   \n",
       "2022-08-01 03:00:00  6.292952  5.306359 -1.672818  1.302133  11.992297   \n",
       "2022-08-01 04:00:00  5.501450  0.355088 -3.930183 -0.112578  -1.028107   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-01 19:00:00  9.816390  6.217887 -7.306248 -0.344754  -2.062787   \n",
       "2023-08-01 20:00:00  9.312197  5.133512 -7.576634 -1.271946  -7.821866   \n",
       "2023-08-01 21:00:00  8.919270  5.942875 -6.403760 -0.588859  -3.800311   \n",
       "2023-08-01 22:00:00  8.472186  5.815027 -5.407756  2.184644  14.794651   \n",
       "2023-08-01 23:00:00  8.147829  4.140885 -5.553662  3.373441  24.279417   \n",
       "\n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2022-08-01 00:00:00  300.997411  6.291421 -1.527907  3.041643  24.361645   \n",
       "2022-08-01 01:00:00  265.105190  4.452409 -2.157465  2.061328  19.703389   \n",
       "2022-08-01 02:00:00  204.232442  0.184564 -2.453588  0.207707   1.573937   \n",
       "2022-08-01 03:00:00  274.047466  5.306359 -1.384970  1.622839  15.157878   \n",
       "2022-08-01 04:00:00  266.247303  0.355088 -3.853669  0.840545  10.024766   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "2023-08-01 19:00:00  310.312771  6.217887 -7.258762  0.820913   4.873037   \n",
       "2023-08-01 20:00:00  304.145239  5.133512 -7.679039 -0.282955  -1.693841   \n",
       "2023-08-01 21:00:00  312.912670  5.942875 -6.430948  0.113013   0.756934   \n",
       "2023-08-01 22:00:00  316.942325  5.815027 -5.162399  2.712489  18.609071   \n",
       "2023-08-01 23:00:00  306.572643  4.140885 -5.176985  3.923564  28.809884   \n",
       "\n",
       "                        phi_gsm  \n",
       "2022-08-01 00:00:00  297.380635  \n",
       "2022-08-01 01:00:00  240.259886  \n",
       "2022-08-01 02:00:00  197.414516  \n",
       "2022-08-01 03:00:00  257.554610  \n",
       "2022-08-01 04:00:00  266.188024  \n",
       "...                         ...  \n",
       "2023-08-01 19:00:00  310.610893  \n",
       "2023-08-01 20:00:00  303.807800  \n",
       "2023-08-01 21:00:00  312.845110  \n",
       "2023-08-01 22:00:00  318.306821  \n",
       "2023-08-01 23:00:00  307.551947  \n",
       "\n",
       "[8784 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_sample_hour = l1_sample.resample('60min').mean()\n",
    "l1_sample_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 (cleaned) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>-478.8</td>\n",
       "      <td>42.3</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>-478.8</td>\n",
       "      <td>40.3</td>\n",
       "      <td>-22.5</td>\n",
       "      <td>481.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>173700.0</td>\n",
       "      <td>8.79</td>\n",
       "      <td>7.08</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>3.28</td>\n",
       "      <td>21.91</td>\n",
       "      <td>330.34</td>\n",
       "      <td>7.08</td>\n",
       "      <td>-3.68</td>\n",
       "      <td>3.67</td>\n",
       "      <td>24.72</td>\n",
       "      <td>332.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:01:00</th>\n",
       "      <td>-480.9</td>\n",
       "      <td>42.2</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-480.9</td>\n",
       "      <td>39.6</td>\n",
       "      <td>-27.5</td>\n",
       "      <td>483.3</td>\n",
       "      <td>8.40</td>\n",
       "      <td>180724.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>6.74</td>\n",
       "      <td>-4.48</td>\n",
       "      <td>2.76</td>\n",
       "      <td>18.81</td>\n",
       "      <td>326.42</td>\n",
       "      <td>6.74</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>3.20</td>\n",
       "      <td>21.98</td>\n",
       "      <td>328.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:02:00</th>\n",
       "      <td>-491.4</td>\n",
       "      <td>56.1</td>\n",
       "      <td>-22.1</td>\n",
       "      <td>-491.4</td>\n",
       "      <td>53.6</td>\n",
       "      <td>-27.7</td>\n",
       "      <td>495.1</td>\n",
       "      <td>9.23</td>\n",
       "      <td>209072.0</td>\n",
       "      <td>7.69</td>\n",
       "      <td>6.04</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>3.86</td>\n",
       "      <td>30.63</td>\n",
       "      <td>337.82</td>\n",
       "      <td>6.04</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>32.69</td>\n",
       "      <td>341.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:03:00</th>\n",
       "      <td>-493.5</td>\n",
       "      <td>67.6</td>\n",
       "      <td>-25.9</td>\n",
       "      <td>-493.5</td>\n",
       "      <td>64.6</td>\n",
       "      <td>-32.7</td>\n",
       "      <td>498.8</td>\n",
       "      <td>9.64</td>\n",
       "      <td>225575.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5.99</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>3.86</td>\n",
       "      <td>32.52</td>\n",
       "      <td>351.67</td>\n",
       "      <td>5.99</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>3.93</td>\n",
       "      <td>33.18</td>\n",
       "      <td>355.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:04:00</th>\n",
       "      <td>-483.7</td>\n",
       "      <td>52.9</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>-483.7</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>486.9</td>\n",
       "      <td>9.06</td>\n",
       "      <td>200746.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>6.75</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>3.51</td>\n",
       "      <td>26.62</td>\n",
       "      <td>344.43</td>\n",
       "      <td>6.75</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>3.69</td>\n",
       "      <td>28.06</td>\n",
       "      <td>347.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:55:00</th>\n",
       "      <td>-390.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-390.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>390.9</td>\n",
       "      <td>8.57</td>\n",
       "      <td>79088.0</td>\n",
       "      <td>8.71</td>\n",
       "      <td>3.90</td>\n",
       "      <td>-7.05</td>\n",
       "      <td>3.33</td>\n",
       "      <td>22.46</td>\n",
       "      <td>298.92</td>\n",
       "      <td>3.90</td>\n",
       "      <td>-6.66</td>\n",
       "      <td>4.06</td>\n",
       "      <td>27.75</td>\n",
       "      <td>300.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:56:00</th>\n",
       "      <td>-394.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-394.4</td>\n",
       "      <td>17.3</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>394.8</td>\n",
       "      <td>9.41</td>\n",
       "      <td>110712.0</td>\n",
       "      <td>8.46</td>\n",
       "      <td>3.67</td>\n",
       "      <td>-7.05</td>\n",
       "      <td>2.86</td>\n",
       "      <td>19.79</td>\n",
       "      <td>297.53</td>\n",
       "      <td>3.67</td>\n",
       "      <td>-6.71</td>\n",
       "      <td>3.59</td>\n",
       "      <td>25.17</td>\n",
       "      <td>298.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:57:00</th>\n",
       "      <td>-389.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-389.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>389.9</td>\n",
       "      <td>8.63</td>\n",
       "      <td>58271.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>3.05</td>\n",
       "      <td>21.38</td>\n",
       "      <td>299.62</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-6.42</td>\n",
       "      <td>3.76</td>\n",
       "      <td>26.65</td>\n",
       "      <td>300.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:58:00</th>\n",
       "      <td>-391.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-391.6</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>392.2</td>\n",
       "      <td>9.19</td>\n",
       "      <td>108681.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>4.07</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>4.69</td>\n",
       "      <td>35.80</td>\n",
       "      <td>308.73</td>\n",
       "      <td>4.07</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>5.21</td>\n",
       "      <td>40.47</td>\n",
       "      <td>311.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:59:00</th>\n",
       "      <td>-388.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-388.7</td>\n",
       "      <td>25.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>389.6</td>\n",
       "      <td>8.79</td>\n",
       "      <td>71505.0</td>\n",
       "      <td>8.23</td>\n",
       "      <td>4.02</td>\n",
       "      <td>-4.39</td>\n",
       "      <td>5.68</td>\n",
       "      <td>43.63</td>\n",
       "      <td>312.43</td>\n",
       "      <td>4.02</td>\n",
       "      <td>-3.76</td>\n",
       "      <td>6.11</td>\n",
       "      <td>47.99</td>\n",
       "      <td>316.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527040 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2022-08-01 00:00:00         -478.8           42.3          -18.2   \n",
       "2022-08-01 00:01:00         -480.9           42.2          -23.3   \n",
       "2022-08-01 00:02:00         -491.4           56.1          -22.1   \n",
       "2022-08-01 00:03:00         -493.5           67.6          -25.9   \n",
       "2022-08-01 00:04:00         -483.7           52.9          -15.9   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 23:55:00         -390.4           19.9           -3.1   \n",
       "2023-08-01 23:56:00         -394.4           17.7           -2.6   \n",
       "2023-08-01 23:57:00         -389.5           17.7           -4.3   \n",
       "2023-08-01 23:58:00         -391.6           20.7            2.4   \n",
       "2023-08-01 23:59:00         -388.7           24.7            9.7   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2022-08-01 00:00:00         -478.8           40.3          -22.5   \n",
       "2022-08-01 00:01:00         -480.9           39.6          -27.5   \n",
       "2022-08-01 00:02:00         -491.4           53.6          -27.7   \n",
       "2022-08-01 00:03:00         -493.5           64.6          -32.7   \n",
       "2022-08-01 00:04:00         -483.7           51.0          -21.2   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 23:55:00         -390.4           19.5           -5.2   \n",
       "2023-08-01 23:56:00         -394.4           17.3           -4.5   \n",
       "2023-08-01 23:57:00         -389.5           17.1           -6.2   \n",
       "2023-08-01 23:58:00         -391.6           20.8            0.2   \n",
       "2023-08-01 23:59:00         -388.7           25.6            7.0   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature    bt  \\\n",
       "2022-08-01 00:00:00         481.0            8.43            173700.0  8.79   \n",
       "2022-08-01 00:01:00         483.3            8.40            180724.0  8.59   \n",
       "2022-08-01 00:02:00         495.1            9.23            209072.0  7.69   \n",
       "2022-08-01 00:03:00         498.8            9.64            225575.0  7.24   \n",
       "2022-08-01 00:04:00         486.9            9.06            200746.0  7.87   \n",
       "...                           ...             ...                 ...   ...   \n",
       "2023-08-01 23:55:00         390.9            8.57             79088.0  8.71   \n",
       "2023-08-01 23:56:00         394.8            9.41            110712.0  8.46   \n",
       "2023-08-01 23:57:00         389.9            8.63             58271.0  8.38   \n",
       "2023-08-01 23:58:00         392.2            9.19            108681.0  8.26   \n",
       "2023-08-01 23:59:00         389.6            8.79             71505.0  8.23   \n",
       "\n",
       "                     bx_gse  by_gse  bz_gse  theta_gse  phi_gse  bx_gsm  \\\n",
       "2022-08-01 00:00:00    7.08   -4.03    3.28      21.91   330.34    7.08   \n",
       "2022-08-01 00:01:00    6.74   -4.48    2.76      18.81   326.42    6.74   \n",
       "2022-08-01 00:02:00    6.04   -2.46    3.86      30.63   337.82    6.04   \n",
       "2022-08-01 00:03:00    5.99   -0.88    3.86      32.52   351.67    5.99   \n",
       "2022-08-01 00:04:00    6.75   -1.88    3.51      26.62   344.43    6.75   \n",
       "...                     ...     ...     ...        ...      ...     ...   \n",
       "2023-08-01 23:55:00    3.90   -7.05    3.33      22.46   298.92    3.90   \n",
       "2023-08-01 23:56:00    3.67   -7.05    2.86      19.79   297.53    3.67   \n",
       "2023-08-01 23:57:00    3.85   -6.78    3.05      21.38   299.62    3.85   \n",
       "2023-08-01 23:58:00    4.07   -5.07    4.69      35.80   308.73    4.07   \n",
       "2023-08-01 23:59:00    4.02   -4.39    5.68      43.63   312.43    4.02   \n",
       "\n",
       "                     by_gsm  bz_gsm  theta_gsm  phi_gsm  \n",
       "2022-08-01 00:00:00   -3.68    3.67      24.72   332.56  \n",
       "2022-08-01 00:01:00   -4.17    3.20      21.98   328.26  \n",
       "2022-08-01 00:02:00   -2.05    4.10      32.69   341.22  \n",
       "2022-08-01 00:03:00   -0.48    3.93      33.18   355.46  \n",
       "2022-08-01 00:04:00   -1.51    3.69      28.06   347.39  \n",
       "...                     ...     ...        ...      ...  \n",
       "2023-08-01 23:55:00   -6.66    4.06      27.75   300.33  \n",
       "2023-08-01 23:56:00   -6.71    3.59      25.17   298.72  \n",
       "2023-08-01 23:57:00   -6.42    3.76      26.65   300.99  \n",
       "2023-08-01 23:58:00   -4.55    5.21      40.47   311.84  \n",
       "2023-08-01 23:59:00   -3.76    6.11      47.99   316.87  \n",
       "\n",
       "[527040 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>-489.208333</td>\n",
       "      <td>57.145000</td>\n",
       "      <td>-21.240000</td>\n",
       "      <td>-489.208333</td>\n",
       "      <td>54.460000</td>\n",
       "      <td>-27.443333</td>\n",
       "      <td>493.095000</td>\n",
       "      <td>9.246667</td>\n",
       "      <td>197578.583333</td>\n",
       "      <td>7.543333</td>\n",
       "      <td>6.303667</td>\n",
       "      <td>-1.872000</td>\n",
       "      <td>2.862500</td>\n",
       "      <td>23.042667</td>\n",
       "      <td>303.207333</td>\n",
       "      <td>6.303667</td>\n",
       "      <td>-1.544167</td>\n",
       "      <td>3.046000</td>\n",
       "      <td>24.468000</td>\n",
       "      <td>305.825500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 01:00:00</th>\n",
       "      <td>-508.771667</td>\n",
       "      <td>51.758333</td>\n",
       "      <td>-27.611667</td>\n",
       "      <td>-508.771667</td>\n",
       "      <td>47.553333</td>\n",
       "      <td>-34.195000</td>\n",
       "      <td>512.376667</td>\n",
       "      <td>9.911833</td>\n",
       "      <td>234221.300000</td>\n",
       "      <td>6.146833</td>\n",
       "      <td>4.458000</td>\n",
       "      <td>-2.411000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>16.625167</td>\n",
       "      <td>259.985167</td>\n",
       "      <td>4.458000</td>\n",
       "      <td>-2.165167</td>\n",
       "      <td>2.072333</td>\n",
       "      <td>19.910000</td>\n",
       "      <td>244.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 02:00:00</th>\n",
       "      <td>-522.971667</td>\n",
       "      <td>46.445000</td>\n",
       "      <td>-34.198333</td>\n",
       "      <td>-522.971667</td>\n",
       "      <td>40.241667</td>\n",
       "      <td>-41.433333</td>\n",
       "      <td>526.340000</td>\n",
       "      <td>9.119667</td>\n",
       "      <td>217786.800000</td>\n",
       "      <td>5.940000</td>\n",
       "      <td>0.200833</td>\n",
       "      <td>-2.490000</td>\n",
       "      <td>-0.181167</td>\n",
       "      <td>-2.719167</td>\n",
       "      <td>202.435000</td>\n",
       "      <td>0.200833</td>\n",
       "      <td>-2.474333</td>\n",
       "      <td>0.201833</td>\n",
       "      <td>1.558500</td>\n",
       "      <td>193.670667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 03:00:00</th>\n",
       "      <td>-498.388333</td>\n",
       "      <td>43.578333</td>\n",
       "      <td>-35.293333</td>\n",
       "      <td>-498.388333</td>\n",
       "      <td>35.510000</td>\n",
       "      <td>-43.275000</td>\n",
       "      <td>501.780000</td>\n",
       "      <td>7.701000</td>\n",
       "      <td>193128.650000</td>\n",
       "      <td>6.293667</td>\n",
       "      <td>5.318833</td>\n",
       "      <td>-1.675667</td>\n",
       "      <td>1.297167</td>\n",
       "      <td>12.009167</td>\n",
       "      <td>270.250167</td>\n",
       "      <td>5.318833</td>\n",
       "      <td>-1.389833</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>15.186333</td>\n",
       "      <td>242.839500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 04:00:00</th>\n",
       "      <td>-526.130000</td>\n",
       "      <td>31.710000</td>\n",
       "      <td>-37.916667</td>\n",
       "      <td>-526.130000</td>\n",
       "      <td>21.496667</td>\n",
       "      <td>-44.436667</td>\n",
       "      <td>528.681667</td>\n",
       "      <td>8.655500</td>\n",
       "      <td>209349.483333</td>\n",
       "      <td>5.515833</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>-3.937167</td>\n",
       "      <td>-0.106500</td>\n",
       "      <td>-1.025167</td>\n",
       "      <td>267.512000</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>-3.859000</td>\n",
       "      <td>0.846833</td>\n",
       "      <td>10.312333</td>\n",
       "      <td>267.249167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 19:00:00</th>\n",
       "      <td>-382.586667</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>-15.218333</td>\n",
       "      <td>-382.586667</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>-15.053333</td>\n",
       "      <td>382.978333</td>\n",
       "      <td>9.779667</td>\n",
       "      <td>65301.266667</td>\n",
       "      <td>9.817000</td>\n",
       "      <td>6.212000</td>\n",
       "      <td>-7.315667</td>\n",
       "      <td>-0.357333</td>\n",
       "      <td>-2.134333</td>\n",
       "      <td>310.247500</td>\n",
       "      <td>6.212000</td>\n",
       "      <td>-7.269500</td>\n",
       "      <td>0.811833</td>\n",
       "      <td>4.826333</td>\n",
       "      <td>310.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 20:00:00</th>\n",
       "      <td>-382.468333</td>\n",
       "      <td>-0.383333</td>\n",
       "      <td>-19.765000</td>\n",
       "      <td>-382.468333</td>\n",
       "      <td>-2.926667</td>\n",
       "      <td>-19.533333</td>\n",
       "      <td>383.011667</td>\n",
       "      <td>10.239167</td>\n",
       "      <td>55382.900000</td>\n",
       "      <td>9.318000</td>\n",
       "      <td>5.136667</td>\n",
       "      <td>-7.581167</td>\n",
       "      <td>-1.270667</td>\n",
       "      <td>-7.814667</td>\n",
       "      <td>304.145667</td>\n",
       "      <td>5.136667</td>\n",
       "      <td>-7.683833</td>\n",
       "      <td>-0.279333</td>\n",
       "      <td>-1.674333</td>\n",
       "      <td>303.811667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 21:00:00</th>\n",
       "      <td>-378.730000</td>\n",
       "      <td>-7.340000</td>\n",
       "      <td>-28.055000</td>\n",
       "      <td>-378.730000</td>\n",
       "      <td>-10.360000</td>\n",
       "      <td>-27.098333</td>\n",
       "      <td>379.943333</td>\n",
       "      <td>9.687167</td>\n",
       "      <td>57833.183333</td>\n",
       "      <td>8.919167</td>\n",
       "      <td>5.942833</td>\n",
       "      <td>-6.407333</td>\n",
       "      <td>-0.580333</td>\n",
       "      <td>-3.743667</td>\n",
       "      <td>312.893000</td>\n",
       "      <td>5.942833</td>\n",
       "      <td>-6.433500</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>312.825667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 22:00:00</th>\n",
       "      <td>-388.971667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-4.993333</td>\n",
       "      <td>-388.971667</td>\n",
       "      <td>9.453333</td>\n",
       "      <td>-5.953333</td>\n",
       "      <td>389.476667</td>\n",
       "      <td>9.755667</td>\n",
       "      <td>102499.000000</td>\n",
       "      <td>8.478000</td>\n",
       "      <td>5.823167</td>\n",
       "      <td>-5.413333</td>\n",
       "      <td>2.193833</td>\n",
       "      <td>14.888167</td>\n",
       "      <td>316.923833</td>\n",
       "      <td>5.823167</td>\n",
       "      <td>-5.166667</td>\n",
       "      <td>2.723000</td>\n",
       "      <td>18.712333</td>\n",
       "      <td>318.278333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:00:00</th>\n",
       "      <td>-390.960000</td>\n",
       "      <td>18.510000</td>\n",
       "      <td>-2.025000</td>\n",
       "      <td>-390.960000</td>\n",
       "      <td>18.225000</td>\n",
       "      <td>-3.918333</td>\n",
       "      <td>391.515000</td>\n",
       "      <td>8.735167</td>\n",
       "      <td>91170.183333</td>\n",
       "      <td>8.154833</td>\n",
       "      <td>4.148500</td>\n",
       "      <td>-5.562667</td>\n",
       "      <td>3.372500</td>\n",
       "      <td>24.301333</td>\n",
       "      <td>306.792833</td>\n",
       "      <td>4.148500</td>\n",
       "      <td>-5.187167</td>\n",
       "      <td>3.922500</td>\n",
       "      <td>28.849833</td>\n",
       "      <td>308.562333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8784 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2022-08-01 00:00:00    -489.208333      57.145000     -21.240000   \n",
       "2022-08-01 01:00:00    -508.771667      51.758333     -27.611667   \n",
       "2022-08-01 02:00:00    -522.971667      46.445000     -34.198333   \n",
       "2022-08-01 03:00:00    -498.388333      43.578333     -35.293333   \n",
       "2022-08-01 04:00:00    -526.130000      31.710000     -37.916667   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 19:00:00    -382.586667       0.195000     -15.218333   \n",
       "2023-08-01 20:00:00    -382.468333      -0.383333     -19.765000   \n",
       "2023-08-01 21:00:00    -378.730000      -7.340000     -28.055000   \n",
       "2023-08-01 22:00:00    -388.971667      10.000000      -4.993333   \n",
       "2023-08-01 23:00:00    -390.960000      18.510000      -2.025000   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2022-08-01 00:00:00    -489.208333      54.460000     -27.443333   \n",
       "2022-08-01 01:00:00    -508.771667      47.553333     -34.195000   \n",
       "2022-08-01 02:00:00    -522.971667      40.241667     -41.433333   \n",
       "2022-08-01 03:00:00    -498.388333      35.510000     -43.275000   \n",
       "2022-08-01 04:00:00    -526.130000      21.496667     -44.436667   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 19:00:00    -382.586667      -2.250000     -15.053333   \n",
       "2023-08-01 20:00:00    -382.468333      -2.926667     -19.533333   \n",
       "2023-08-01 21:00:00    -378.730000     -10.360000     -27.098333   \n",
       "2023-08-01 22:00:00    -388.971667       9.453333      -5.953333   \n",
       "2023-08-01 23:00:00    -390.960000      18.225000      -3.918333   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2022-08-01 00:00:00    493.095000        9.246667       197578.583333   \n",
       "2022-08-01 01:00:00    512.376667        9.911833       234221.300000   \n",
       "2022-08-01 02:00:00    526.340000        9.119667       217786.800000   \n",
       "2022-08-01 03:00:00    501.780000        7.701000       193128.650000   \n",
       "2022-08-01 04:00:00    528.681667        8.655500       209349.483333   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-01 19:00:00    382.978333        9.779667        65301.266667   \n",
       "2023-08-01 20:00:00    383.011667       10.239167        55382.900000   \n",
       "2023-08-01 21:00:00    379.943333        9.687167        57833.183333   \n",
       "2023-08-01 22:00:00    389.476667        9.755667       102499.000000   \n",
       "2023-08-01 23:00:00    391.515000        8.735167        91170.183333   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2022-08-01 00:00:00  7.543333  6.303667 -1.872000  2.862500  23.042667   \n",
       "2022-08-01 01:00:00  6.146833  4.458000 -2.411000  1.750000  16.625167   \n",
       "2022-08-01 02:00:00  5.940000  0.200833 -2.490000 -0.181167  -2.719167   \n",
       "2022-08-01 03:00:00  6.293667  5.318833 -1.675667  1.297167  12.009167   \n",
       "2022-08-01 04:00:00  5.515833  0.348000 -3.937167 -0.106500  -1.025167   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-01 19:00:00  9.817000  6.212000 -7.315667 -0.357333  -2.134333   \n",
       "2023-08-01 20:00:00  9.318000  5.136667 -7.581167 -1.270667  -7.814667   \n",
       "2023-08-01 21:00:00  8.919167  5.942833 -6.407333 -0.580333  -3.743667   \n",
       "2023-08-01 22:00:00  8.478000  5.823167 -5.413333  2.193833  14.888167   \n",
       "2023-08-01 23:00:00  8.154833  4.148500 -5.562667  3.372500  24.301333   \n",
       "\n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2022-08-01 00:00:00  303.207333  6.303667 -1.544167  3.046000  24.468000   \n",
       "2022-08-01 01:00:00  259.985167  4.458000 -2.165167  2.072333  19.910000   \n",
       "2022-08-01 02:00:00  202.435000  0.200833 -2.474333  0.201833   1.558500   \n",
       "2022-08-01 03:00:00  270.250167  5.318833 -1.389833  1.618000  15.186333   \n",
       "2022-08-01 04:00:00  267.512000  0.348000 -3.859000  0.846833  10.312333   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "2023-08-01 19:00:00  310.247500  6.212000 -7.269500  0.811833   4.826333   \n",
       "2023-08-01 20:00:00  304.145667  5.136667 -7.683833 -0.279333  -1.674333   \n",
       "2023-08-01 21:00:00  312.893000  5.942833 -6.433500  0.122500   0.823333   \n",
       "2023-08-01 22:00:00  316.923833  5.823167 -5.166667  2.723000  18.712333   \n",
       "2023-08-01 23:00:00  306.792833  4.148500 -5.187167  3.922500  28.849833   \n",
       "\n",
       "                        phi_gsm  \n",
       "2022-08-01 00:00:00  305.825500  \n",
       "2022-08-01 01:00:00  244.457500  \n",
       "2022-08-01 02:00:00  193.670667  \n",
       "2022-08-01 03:00:00  242.839500  \n",
       "2022-08-01 04:00:00  267.249167  \n",
       "...                         ...  \n",
       "2023-08-01 19:00:00  310.531000  \n",
       "2023-08-01 20:00:00  303.811667  \n",
       "2023-08-01 21:00:00  312.825667  \n",
       "2023-08-01 22:00:00  318.278333  \n",
       "2023-08-01 23:00:00  308.562333  \n",
       "\n",
       "[8784 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_sample_hour = l2_sample.resample('60min').mean()\n",
    "l2_sample_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dst data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        8\n",
       "2       10\n",
       "3        3\n",
       "4       -1\n",
       "        ..\n",
       "8779    14\n",
       "8780    13\n",
       "8781    11\n",
       "8782     6\n",
       "8783     5\n",
       "Name: Dst, Length: 8784, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3-\n",
       "1       2+\n",
       "2       2-\n",
       "3       2-\n",
       "4        2\n",
       "        ..\n",
       "2923    1+\n",
       "2924     3\n",
       "2925    3-\n",
       "2926    2+\n",
       "2927     2\n",
       "Name: Kp, Length: 2928, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "### Descriptions:\n",
    "**hn_dl**: hour normal dataloader\n",
    "\n",
    "**mn_dl**: minute normal dataloader\n",
    "\n",
    "**hr_dl**: minute normal dataloader\n",
    "\n",
    "**mr_dl**: minute normal dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_hour = 10  #hour\n",
    "sequence_length_minute = 600 #minute\n",
    "pred_length = 6 #hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normal\n",
    "hour_Normal_dataset = NormalTrainingDataset(l1_sample_hour, dst, kp, sequence_length_hour, pred_length, hour = True)\n",
    "minute_Normal_dataset = NormalTrainingDataset(l1_sample, dst, kp, sequence_length_minute, pred_length, hour = False)\n",
    "##Refined(new method)\n",
    "hour_Refined_dataset = RefinedTrainingDataset(l1_sample_hour, l2_sample_hour, dst,kp,sequence_length_hour, pred_length, hour = True)\n",
    "minute_Refined_dataset = RefinedTrainingDataset(l1_sample, l2_sample, dst,kp,sequence_length_minute, pred_length, hour = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(hour_Normal_dataset))\n",
    "\n",
    "train_hn_ds, test_hn_ds = random_split(hour_Normal_dataset , [len(hour_Normal_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hn_dl = DataLoader(train_hn_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hn_dl = DeviceDataLoader(train_hn_dl, device)\n",
    "test_hn_dl = DataLoader(test_hn_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hn_dl = DeviceDataLoader(test_hn_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(minute_Normal_dataset))\n",
    "\n",
    "train_mn_ds, test_mn_ds = random_split(minute_Normal_dataset , [len(minute_Normal_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_mn_dl = DataLoader(train_mn_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_mn_dl = DeviceDataLoader(train_mn_dl, device)\n",
    "test_mn_dl = DataLoader(test_mn_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_mn_dl = DeviceDataLoader(test_mn_dl, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(hour_Refined_dataset))\n",
    "\n",
    "train_hr_ds, test_hr_ds = random_split(hour_Refined_dataset , [len(hour_Refined_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hr_dl = DataLoader(train_hr_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hr_dl = DeviceDataLoader(train_hr_dl, device)\n",
    "test_hr_dl = DataLoader(test_hr_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hr_dl = DeviceDataLoader(test_hr_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(minute_Refined_dataset))\n",
    "\n",
    "train_mr_ds, test_mr_ds = random_split(minute_Refined_dataset , [len(minute_Refined_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_mr_dl = DataLoader(train_mr_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_mr_dl = DeviceDataLoader(train_mr_dl, device)\n",
    "test_mr_dl = DataLoader(test_mr_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_mr_dl = DeviceDataLoader(test_mr_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined models with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Convolutional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "cnn_encoder_min = Simple1DCNN(architecture, sequence_length_minute, hidden_size)\n",
    "cnn_encoder_hour = Simple1DCNN(architecture, sequence_length_hour, hidden_size)\n",
    "#fc layer\n",
    "cnn_fc_dst_min = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_min = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "cnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_min = to_device(RefinedArchitecture(cnn_encoder_min, cnn_fc_dst_min, cnn_fc_kp_min), device)\n",
    "RefinedCNN_hour = to_device(RefinedArchitecture(cnn_encoder_hour, cnn_fc_dst_hour, cnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 20\n",
    "max_lr = 5e-4\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 1e-1\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedCNN_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedCNN_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedCNN_min_history += RefinedCNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 2.0356\n",
      "\ttrain_main_loss: 2.0356\n",
      "\ttrain_output_loss: 0.0000\n",
      "\ttrain_encoder_loss: 0.0000\n",
      "\tval_overall_loss: 2.2384\n",
      "\tval_main_loss: 2.2384\n",
      "\tval_output_loss: 0.0000\n",
      "\tval_encoder_loss: 0.0000\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_overall_loss: 2.0138\n",
      "\ttrain_main_loss: 2.0138\n",
      "\ttrain_output_loss: 0.0000\n",
      "\ttrain_encoder_loss: 0.0000\n",
      "\tval_overall_loss: 2.2065\n",
      "\tval_main_loss: 2.2065\n",
      "\tval_output_loss: 0.0000\n",
      "\tval_encoder_loss: 0.0000\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00026\n",
      "\ttrain_overall_loss: 1.9698\n",
      "\ttrain_main_loss: 1.9698\n",
      "\ttrain_output_loss: 0.0000\n",
      "\ttrain_encoder_loss: 0.0000\n",
      "\tval_overall_loss: 2.0833\n",
      "\tval_main_loss: 2.0833\n",
      "\tval_output_loss: 0.0000\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00038\n",
      "\ttrain_overall_loss: 1.5331\n",
      "\ttrain_main_loss: 1.5331\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0016\n",
      "\tval_overall_loss: 1.5814\n",
      "\tval_main_loss: 1.5814\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0013\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00047\n",
      "\ttrain_overall_loss: 1.3133\n",
      "\ttrain_main_loss: 1.3133\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0012\n",
      "\tval_overall_loss: 1.4151\n",
      "\tval_main_loss: 1.4151\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0010\n",
      "Epoch [5]\n",
      "\tlast_lr: 0.00050\n",
      "\ttrain_overall_loss: 1.1618\n",
      "\ttrain_main_loss: 1.1618\n",
      "\ttrain_output_loss: 0.0007\n",
      "\ttrain_encoder_loss: 0.0017\n",
      "\tval_overall_loss: 1.3432\n",
      "\tval_main_loss: 1.3432\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0014\n",
      "Epoch [6]\n",
      "\tlast_lr: 0.00049\n",
      "\ttrain_overall_loss: 1.0855\n",
      "\ttrain_main_loss: 1.0855\n",
      "\ttrain_output_loss: 0.0010\n",
      "\ttrain_encoder_loss: 0.0020\n",
      "\tval_overall_loss: 1.2663\n",
      "\tval_main_loss: 1.2663\n",
      "\tval_output_loss: 0.0012\n",
      "\tval_encoder_loss: 0.0022\n",
      "Epoch [7]\n",
      "\tlast_lr: 0.00048\n",
      "\ttrain_overall_loss: 1.0450\n",
      "\ttrain_main_loss: 1.0450\n",
      "\ttrain_output_loss: 0.0012\n",
      "\ttrain_encoder_loss: 0.0024\n",
      "\tval_overall_loss: 1.2354\n",
      "\tval_main_loss: 1.2353\n",
      "\tval_output_loss: 0.0013\n",
      "\tval_encoder_loss: 0.0024\n",
      "Epoch [8]\n",
      "\tlast_lr: 0.00045\n",
      "\ttrain_overall_loss: 1.0173\n",
      "\ttrain_main_loss: 1.0172\n",
      "\ttrain_output_loss: 0.0013\n",
      "\ttrain_encoder_loss: 0.0024\n",
      "\tval_overall_loss: 1.2091\n",
      "\tval_main_loss: 1.2090\n",
      "\tval_output_loss: 0.0018\n",
      "\tval_encoder_loss: 0.0028\n",
      "Epoch [9]\n",
      "\tlast_lr: 0.00041\n",
      "\ttrain_overall_loss: 0.9909\n",
      "\ttrain_main_loss: 0.9909\n",
      "\ttrain_output_loss: 0.0014\n",
      "\ttrain_encoder_loss: 0.0023\n",
      "\tval_overall_loss: 1.1945\n",
      "\tval_main_loss: 1.1945\n",
      "\tval_output_loss: 0.0016\n",
      "\tval_encoder_loss: 0.0027\n",
      "Epoch [10]\n",
      "\tlast_lr: 0.00036\n",
      "\ttrain_overall_loss: 0.9764\n",
      "\ttrain_main_loss: 0.9764\n",
      "\ttrain_output_loss: 0.0013\n",
      "\ttrain_encoder_loss: 0.0022\n",
      "\tval_overall_loss: 1.1829\n",
      "\tval_main_loss: 1.1829\n",
      "\tval_output_loss: 0.0015\n",
      "\tval_encoder_loss: 0.0026\n",
      "Epoch [11]\n",
      "\tlast_lr: 0.00031\n",
      "\ttrain_overall_loss: 0.9636\n",
      "\ttrain_main_loss: 0.9636\n",
      "\ttrain_output_loss: 0.0013\n",
      "\ttrain_encoder_loss: 0.0022\n",
      "\tval_overall_loss: 1.1620\n",
      "\tval_main_loss: 1.1619\n",
      "\tval_output_loss: 0.0017\n",
      "\tval_encoder_loss: 0.0027\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedCNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedCNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedCNN_hour_history += RefinedCNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute based models\n",
    "deep_lstm_encoder_min_forward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_min_backward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "bidirectional_deeplstm_encoder_min = BidirectionalRNNWithAttention(deep_lstm_encoder_min_forward, deep_lstm_encoder_min_backward)\n",
    "##Bidirectional hour based models\n",
    "deep_lstm_encoder_hour_forward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_hour_backward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "bidirectional_deeplstm_encoder_hour = BidirectionalRNNWithAttention(deep_lstm_encoder_hour_forward, deep_lstm_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture) #the multiplying factor because concatenating hidden_states on bidirectional arch\n",
    "deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_min = to_device(RefinedArchitecture(bidirectional_deeplstm_encoder_min, deep_lstm_fc_dst_min, deep_lstm_fc_kp_min), device)\n",
    "RefinedLSTM_hour = to_device(RefinedArchitecture(bidirectional_deeplstm_encoder_hour, deep_lstm_fc_dst_hour, deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedLSTM_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedLSTM_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:232\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    230\u001b[0m main_losses\u001b[39m.\u001b[39mappend(main_loss)\n\u001b[0;32m    231\u001b[0m \u001b[39m#Calcular las derivadas parciales\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    234\u001b[0m \u001b[39m# Gradient clipping, para que no ocurra el exploding gradient\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[39mif\u001b[39;00m grad_clip:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedLSTM_min_history += RefinedLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3423\n",
      "\ttrain_main_loss: 1.3423\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0000\n",
      "\tval_overall_loss: 0.9733\n",
      "\tval_main_loss: 0.9733\n",
      "\tval_output_loss: 0.0002\n",
      "\tval_encoder_loss: 0.0000\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 0.9529\n",
      "\ttrain_main_loss: 0.9529\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.8512\n",
      "\tval_main_loss: 0.8512\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.8301\n",
      "\ttrain_main_loss: 0.8301\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7807\n",
      "\tval_main_loss: 0.7807\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_overall_loss: 0.7586\n",
      "\ttrain_main_loss: 0.7586\n",
      "\ttrain_output_loss: 0.0007\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7456\n",
      "\tval_main_loss: 0.7456\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_overall_loss: 0.7159\n",
      "\ttrain_main_loss: 0.7159\n",
      "\ttrain_output_loss: 0.0006\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7054\n",
      "\tval_main_loss: 0.7054\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [5]\n",
      "\tlast_lr: 0.00013\n",
      "\ttrain_overall_loss: 0.6785\n",
      "\ttrain_main_loss: 0.6785\n",
      "\ttrain_output_loss: 0.0007\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.6804\n",
      "\tval_main_loss: 0.6804\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [6]\n",
      "\tlast_lr: 0.00016\n",
      "\ttrain_overall_loss: 0.6493\n",
      "\ttrain_main_loss: 0.6493\n",
      "\ttrain_output_loss: 0.0006\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.6488\n",
      "\tval_main_loss: 0.6488\n",
      "\tval_output_loss: 0.0007\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [7]\n",
      "\tlast_lr: 0.00020\n",
      "\ttrain_overall_loss: 0.6195\n",
      "\ttrain_main_loss: 0.6195\n",
      "\ttrain_output_loss: 0.0007\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.6199\n",
      "\tval_main_loss: 0.6199\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [8]\n",
      "\tlast_lr: 0.00024\n",
      "\ttrain_overall_loss: 0.6007\n",
      "\ttrain_main_loss: 0.6007\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.6158\n",
      "\tval_main_loss: 0.6158\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [9]\n",
      "\tlast_lr: 0.00028\n",
      "\ttrain_overall_loss: 0.5827\n",
      "\ttrain_main_loss: 0.5826\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5948\n",
      "\tval_main_loss: 0.5948\n",
      "\tval_output_loss: 0.0007\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [10]\n",
      "\tlast_lr: 0.00032\n",
      "\ttrain_overall_loss: 0.5660\n",
      "\ttrain_main_loss: 0.5660\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5816\n",
      "\tval_main_loss: 0.5816\n",
      "\tval_output_loss: 0.0007\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [11]\n",
      "\tlast_lr: 0.00037\n",
      "\ttrain_overall_loss: 0.5504\n",
      "\ttrain_main_loss: 0.5504\n",
      "\ttrain_output_loss: 0.0009\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5542\n",
      "\tval_main_loss: 0.5542\n",
      "\tval_output_loss: 0.0008\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [12]\n",
      "\tlast_lr: 0.00042\n",
      "\ttrain_overall_loss: 0.5379\n",
      "\ttrain_main_loss: 0.5379\n",
      "\ttrain_output_loss: 0.0010\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5567\n",
      "\tval_main_loss: 0.5567\n",
      "\tval_output_loss: 0.0008\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [13]\n",
      "\tlast_lr: 0.00047\n",
      "\ttrain_overall_loss: 0.5284\n",
      "\ttrain_main_loss: 0.5284\n",
      "\ttrain_output_loss: 0.0012\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5555\n",
      "\tval_main_loss: 0.5555\n",
      "\tval_output_loss: 0.0009\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [14]\n",
      "\tlast_lr: 0.00052\n",
      "\ttrain_overall_loss: 0.5186\n",
      "\ttrain_main_loss: 0.5186\n",
      "\ttrain_output_loss: 0.0013\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5363\n",
      "\tval_main_loss: 0.5363\n",
      "\tval_output_loss: 0.0010\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [15]\n",
      "\tlast_lr: 0.00057\n",
      "\ttrain_overall_loss: 0.5140\n",
      "\ttrain_main_loss: 0.5140\n",
      "\ttrain_output_loss: 0.0014\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5398\n",
      "\tval_main_loss: 0.5398\n",
      "\tval_output_loss: 0.0011\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 53\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedLSTM_hour_history += RefinedLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute based models\n",
    "deep_gru_encoder_min_forward= DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min_backward= DeepGRU(hidden_size, input_size, architecture)\n",
    "bidirectional_deepgru_encoder_min = BidirectionalRNNWithAttention(deep_gru_encoder_min_forward, deep_gru_encoder_min_backward)\n",
    "##Bidirectional hour based models\n",
    "deep_gru_encoder_hour_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "bidirectional_deepgru_encoder_hour = BidirectionalRNNWithAttention(deep_gru_encoder_hour_forward, deep_gru_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min = to_device(RefinedArchitecture(bidirectional_deepgru_encoder_min, deep_gru_fc_dst_min, deep_gru_fc_kp_min), device)\n",
    "RefinedGRU_hour = to_device(RefinedArchitecture(bidirectional_deepgru_encoder_hour, deep_gru_fc_dst_hour, deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-2\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 5e-1\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min_history += RefinedGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00043\n",
      "\ttrain_overall_loss: 1.6406\n",
      "\ttrain_main_loss: 1.6406\n",
      "\ttrain_output_loss: 0.0001\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.4343\n",
      "\tval_main_loss: 1.4343\n",
      "\tval_output_loss: 0.0002\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00050\n",
      "\ttrain_overall_loss: 1.1422\n",
      "\ttrain_main_loss: 1.1422\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.1519\n",
      "\tval_main_loss: 1.1519\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 62\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:73\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(wfd, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m to_child:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# start process\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m         hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(\n\u001b[0;32m     74\u001b[0m             python_exe, cmd,\n\u001b[0;32m     75\u001b[0m             \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mFalse\u001b[39;49;00m, \u001b[39m0\u001b[39;49m, env, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     76\u001b[0m         _winapi\u001b[39m.\u001b[39mCloseHandle(ht)\n\u001b[0;32m     77\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedGRU_hour_history += RefinedGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep Vanilla RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute encoders\n",
    "deep_rnn_encoder_min_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "bidirectional_deeprnn_encoder_min = BidirectionalRNNWithAttention(deep_rnn_encoder_min_forward,deep_rnn_encoder_min_backward)\n",
    "##Bidirectional hour encoders\n",
    "deep_rnn_encoder_hour_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "bidirectional_deeprnn_encoder_hour = BidirectionalRNNWithAttention(deep_rnn_encoder_hour_forward,deep_rnn_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min = to_device(RefinedArchitecture(bidirectional_deeprnn_encoder_min, deep_rnn_fc_dst_min, deep_rnn_fc_kp_min), device)\n",
    "RefinedVanillaRNN_hour = to_device(RefinedArchitecture(bidirectional_deeprnn_encoder_hour, deep_rnn_fc_dst_hour, deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min_history += RefinedVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3494\n",
      "\ttrain_main_loss: 1.3494\n",
      "\ttrain_output_loss: 0.0001\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.2106\n",
      "\tval_main_loss: 1.2106\n",
      "\tval_output_loss: 0.0002\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 1.0410\n",
      "\ttrain_main_loss: 1.0410\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.0773\n",
      "\tval_main_loss: 1.0773\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 71\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:248\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    245\u001b[0m     sched\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    247\u001b[0m \u001b[39m# Fase de validación\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(val_loader)\n\u001b[0;32m    249\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mtrain_overall_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(train_losses)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem() \n\u001b[0;32m    250\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mtrain_main_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(main_losses)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem() \n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:201\u001b[0m, in \u001b[0;36mRefinedArchitecture.evaluate\u001b[1;34m(self, val_loader)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, val_loader):\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 201\u001b[0m     outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m    202\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:201\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, val_loader):\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 201\u001b[0m     outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m    202\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedVanillaRNN_hour_history += RefinedVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional non deep architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_lstm_forward_min = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_min = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_min = BidirectionalRNNWithAttention(non_deep_lstm_forward_min, non_deep_lstm_backward_min)\n",
    "\n",
    "non_deep_lstm_forward_hour = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_hour = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_hour = BidirectionalRNNWithAttention(non_deep_lstm_forward_hour, non_deep_lstm_backward_hour)\n",
    "#fc layer\n",
    "non_deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min = to_device(RefinedArchitecture(bidirectional_lstm_encoder_min, non_deep_lstm_fc_dst_min, non_deep_lstm_fc_kp_min), device)\n",
    "RefinedNonDeepLSTM_hour = to_device(RefinedArchitecture(bidirectional_lstm_encoder_hour, non_deep_lstm_fc_dst_hour, non_deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min_history += RefinedNonDeepLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3338\n",
      "\ttrain_main_loss: 1.3338\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.1319\n",
      "\tval_main_loss: 1.1319\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 0.9605\n",
      "\ttrain_main_loss: 0.9605\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.9760\n",
      "\tval_main_loss: 0.9760\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.8491\n",
      "\ttrain_main_loss: 0.8491\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.8663\n",
      "\tval_main_loss: 0.8663\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_overall_loss: 0.7699\n",
      "\ttrain_main_loss: 0.7698\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.7792\n",
      "\tval_main_loss: 0.7792\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_overall_loss: 0.7140\n",
      "\ttrain_main_loss: 0.7140\n",
      "\ttrain_output_loss: 0.0012\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.7207\n",
      "\tval_main_loss: 0.7206\n",
      "\tval_output_loss: 0.0008\n",
      "\tval_encoder_loss: 0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 79\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y314sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepLSTM_hour_history += RefinedNonDeepLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_gru_forward_min = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_min = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_min = BidirectionalRNNWithAttention(non_deep_gru_forward_min, non_deep_gru_backward_min)\n",
    "\n",
    "non_deep_gru_forward_hour = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_hour = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_hour = BidirectionalRNNWithAttention(non_deep_gru_forward_hour, non_deep_gru_backward_hour)\n",
    "#fc layer\n",
    "non_deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min = to_device(RefinedArchitecture(bidirectional_gru_encoder_min, non_deep_gru_fc_dst_min, non_deep_gru_fc_kp_min), device)\n",
    "RefinedNonDeepGRU_hour = to_device(RefinedArchitecture(bidirectional_gru_encoder_hour, non_deep_gru_fc_dst_hour, non_deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min_history += RefinedNonDeepGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3516\n",
      "\ttrain_main_loss: 1.3516\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.1860\n",
      "\tval_main_loss: 1.1860\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 0.9823\n",
      "\ttrain_main_loss: 0.9823\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.0192\n",
      "\tval_main_loss: 1.0192\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.8637\n",
      "\ttrain_main_loss: 0.8637\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.9084\n",
      "\tval_main_loss: 0.9084\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_overall_loss: 0.7905\n",
      "\ttrain_main_loss: 0.7905\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.8263\n",
      "\tval_main_loss: 0.8263\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_overall_loss: 0.7357\n",
      "\ttrain_main_loss: 0.7357\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7559\n",
      "\tval_main_loss: 0.7559\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 86\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepGRU_hour_history += RefinedNonDeepGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_rnn_forward_min = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_min = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_min = BidirectionalRNNWithAttention(non_deep_rnn_forward_min, non_deep_rnn_backward_min)\n",
    "\n",
    "non_deep_rnn_forward_hour = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_hour = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_hour = BidirectionalRNNWithAttention(non_deep_rnn_forward_hour, non_deep_rnn_backward_hour)\n",
    "#fc layer\n",
    "non_deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min = to_device(RefinedArchitecture(bidirectional_rnn_encoder_min, non_deep_rnn_fc_dst_min, non_deep_rnn_fc_kp_min), device)\n",
    "RefinedNonDeepVanillaRNN_hour = to_device(RefinedArchitecture(bidirectional_rnn_encoder_hour, non_deep_rnn_fc_dst_hour, non_deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history += RefinedNonDeepVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.2946\n",
      "\ttrain_main_loss: 1.2946\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.1871\n",
      "\tval_main_loss: 1.1871\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 1.0257\n",
      "\ttrain_main_loss: 1.0257\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.0831\n",
      "\tval_main_loss: 1.0830\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.9554\n",
      "\ttrain_main_loss: 0.9554\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.0201\n",
      "\tval_main_loss: 1.0201\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 93\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y161sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepVanillaRNN_hour_history += RefinedNonDeepVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal models with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Convolutional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "cnn_encoder_min = Simple1DCNN(architecture, input_size, hidden_size)\n",
    "cnn_encoder_hour = Simple1DCNN(architecture, input_size, hidden_size)\n",
    "#fc layer\n",
    "cnn_fc_dst_min = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_min = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "cnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min = to_device(NormalArchitecture(cnn_encoder_min, cnn_fc_dst_min, cnn_fc_kp_min), device)\n",
    "NormalCNN_hour = to_device(NormalArchitecture(cnn_encoder_hour, cnn_fc_dst_hour, cnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min_history += NormalCNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [10, 20, 3], expected input[32, 10, 20] to have 20 channels, but got 10 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 103\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y204sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalCNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalCNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:72\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:23\u001b[0m, in \u001b[0;36mNormalArchitecture.training_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     21\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m#initialize loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m feature, dst, kp \u001b[39m=\u001b[39m batch \u001b[39m#decompose batch\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m dst_out, kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(feature)        \n\u001b[0;32m     24\u001b[0m \u001b[39m#dst index cost-1st head\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(dst_out, dst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:16\u001b[0m, in \u001b[0;36mNormalArchitecture.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     17\u001b[0m     dst_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_dst(out)\n\u001b[0;32m     18\u001b[0m     kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_kp(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:55\u001b[0m, in \u001b[0;36mSimple1DCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 55\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1d(x)\n\u001b[0;32m     56\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     57\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 20, 3], expected input[32, 10, 20] to have 20 channels, but got 10 channels instead"
     ]
    }
   ],
   "source": [
    "NormalCNN_hour_history += NormalCNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_lstm_encoder_min_forward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_min_backward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_min = BidirectionalRNNWithAttention(deep_lstm_encoder_min_forward,deep_lstm_encoder_min_backward)\n",
    "\n",
    "deep_lstm_encoder_hour_forward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_hour_backward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_hour = BidirectionalRNNWithAttention(deep_lstm_encoder_hour_forward,deep_lstm_encoder_hour_backward)\n",
    "\n",
    "#fc layer\n",
    "deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min = to_device(NormalArchitecture(deep_lstm_encoder_min, deep_lstm_fc_dst_min, deep_lstm_fc_kp_min), device)\n",
    "NormalLSTM_hour = to_device(NormalArchitecture(deep_lstm_encoder_hour, deep_lstm_fc_dst_hour, deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min_history += NormalLSTM_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 1.3096\n",
      "\tval_loss: 0.9849\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 0.9692\n",
      "\tval_loss: 0.8660\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_loss: 0.8529\n",
      "\tval_loss: 0.7863\n",
      "Epoch [3]:\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_loss: 0.7619\n",
      "\tval_loss: 0.7326\n",
      "Epoch [4]:\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_loss: 0.7028\n",
      "\tval_loss: 0.6870\n",
      "Epoch [5]:\n",
      "\tlast_lr: 0.00013\n",
      "\ttrain_loss: 0.6619\n",
      "\tval_loss: 0.6704\n",
      "Epoch [6]:\n",
      "\tlast_lr: 0.00016\n",
      "\ttrain_loss: 0.6341\n",
      "\tval_loss: 0.6449\n",
      "Epoch [7]:\n",
      "\tlast_lr: 0.00020\n",
      "\ttrain_loss: 0.6039\n",
      "\tval_loss: 0.6322\n",
      "Epoch [8]:\n",
      "\tlast_lr: 0.00024\n",
      "\ttrain_loss: 0.5860\n",
      "\tval_loss: 0.6194\n",
      "Epoch [9]:\n",
      "\tlast_lr: 0.00028\n",
      "\ttrain_loss: 0.5695\n",
      "\tval_loss: 0.5994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 112\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y216sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:76\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     74\u001b[0m train_losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m     75\u001b[0m \u001b[39m#Calcular las derivadas parciales\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     78\u001b[0m \u001b[39m# Gradient clipping, para que no ocurra el exploding gradient\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m grad_clip:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalLSTM_hour_history += NormalLSTM_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "\n",
    "deep_gru_encoder_min_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min = BidirectionalRNNWithAttention(deep_gru_encoder_min_forward,deep_gru_encoder_min_backward)\n",
    "\n",
    "deep_gru_encoder_hour_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour = BidirectionalRNNWithAttention(deep_gru_encoder_hour_forward,deep_gru_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size,hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min = to_device(NormalArchitecture(deep_gru_encoder_min, deep_gru_fc_dst_min, deep_gru_fc_kp_min), device)\n",
    "NormalGRU_hour = to_device(NormalArchitecture(deep_gru_encoder_hour, deep_gru_fc_dst_hour, deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 119\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y226sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalGRU_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalGRU_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:72\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:23\u001b[0m, in \u001b[0;36mNormalArchitecture.training_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     21\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m#initialize loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m feature, dst, kp \u001b[39m=\u001b[39m batch \u001b[39m#decompose batch\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m dst_out, kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(feature)        \n\u001b[0;32m     24\u001b[0m \u001b[39m#dst index cost-1st head\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(dst_out, dst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:16\u001b[0m, in \u001b[0;36mNormalArchitecture.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     17\u001b[0m     dst_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_dst(out)\n\u001b[0;32m     18\u001b[0m     kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_kp(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:241\u001b[0m, in \u001b[0;36mBidirectionalRNNWithAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    240\u001b[0m     \u001b[39m# Forward pass through the first RNN\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     hidden1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn1(x)\n\u001b[0;32m    242\u001b[0m     \u001b[39m# Reverse the input sequence for the second RNN\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     x_backward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflip(x, [\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:153\u001b[0m, in \u001b[0;36mDeepGRU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    151\u001b[0m xt \u001b[39m=\u001b[39m x[:, t, :]\n\u001b[0;32m    152\u001b[0m Z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ_h(hn)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ_x(xt))\n\u001b[1;32m--> 153\u001b[0m R \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mR_h(hn)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mR_x(xt))\n\u001b[0;32m    154\u001b[0m H_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_hat_h(hn\u001b[39m*\u001b[39mR)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_hat_x(xt))\n\u001b[0;32m    155\u001b[0m hn \u001b[39m=\u001b[39m hn\u001b[39m*\u001b[39mZ \u001b[39m+\u001b[39m (torch\u001b[39m.\u001b[39mones_like(Z)\u001b[39m-\u001b[39mZ)\u001b[39m*\u001b[39mH_hat\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:42\u001b[0m, in \u001b[0;36mDeepNeuralNetwork.forward\u001b[1;34m(self, xb)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xb):\n\u001b[0;32m     41\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_structure(xb)\n\u001b[1;32m---> 42\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_layer(out)\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "NormalGRU_min_history += NormalGRU_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 0.9408\n",
      "\tval_loss: 0.8459\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 121\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y231sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:83\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     80\u001b[0m     nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_value_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters(), grad_clip)\n\u001b[0;32m     82\u001b[0m \u001b[39m#Efectuar el descensod e gradiente y borrar el historial\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     84\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     86\u001b[0m \u001b[39m# Guardar el learning rate utilizado en el cycle.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:269\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[0;32m    268\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m    270\u001b[0m     \u001b[39m# call optimizer step pre hooks\u001b[39;00m\n\u001b[0;32m    271\u001b[0m     \u001b[39mfor\u001b[39;00m pre_hook \u001b[39min\u001b[39;00m chain(_global_optimizer_pre_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_pre_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    272\u001b[0m         result \u001b[39m=\u001b[39m pre_hook(\u001b[39mself\u001b[39m, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n\u001b[0;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs \u001b[39mor\u001b[39;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalGRU_hour_history += NormalGRU_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep Vanilla RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_rnn_encoder_min_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min = BidirectionalRNNWithAttention(deep_rnn_encoder_min_forward, deep_rnn_encoder_min_backward)\n",
    "\n",
    "deep_rnn_encoder_hour_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour = BidirectionalRNNWithAttention(deep_rnn_encoder_hour_forward,deep_rnn_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min = to_device(NormalArchitecture(deep_rnn_encoder_min, deep_rnn_fc_dst_min, deep_rnn_fc_kp_min), device)\n",
    "NormalVanillaRNN_hour = to_device(NormalArchitecture(deep_rnn_encoder_hour, deep_rnn_fc_dst_hour, deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min_history += NormalVanillaRNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 1.3040\n",
      "\tval_loss: 1.0009\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 1.0306\n",
      "\tval_loss: 0.9201\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_loss: 0.9532\n",
      "\tval_loss: 0.8801\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 130\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y243sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalVanillaRNN_hour_history += NormalVanillaRNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non deep bidirectional architectures with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_lstm_forward_min = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_min = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_min = BidirectionalRNNWithAttention(non_deep_lstm_forward_min, non_deep_lstm_backward_min)\n",
    "\n",
    "non_deep_lstm_forward_hour = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_hour = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_hour = BidirectionalRNNWithAttention(non_deep_lstm_forward_hour, non_deep_lstm_backward_hour)\n",
    "#fc layer\n",
    "non_deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min = to_device(NormalArchitecture(bidirectional_lstm_encoder_min, non_deep_lstm_fc_dst_min, non_deep_lstm_fc_kp_min), device)\n",
    "NormalNonDeepLSTM_hour = to_device(NormalArchitecture(bidirectional_lstm_encoder_hour, non_deep_lstm_fc_dst_hour, non_deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min_history += NormalNonDeepLSTM_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.0350\n",
      "\tval_loss: 2.0597\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_loss: 2.0237\n",
      "\tval_loss: 2.0414\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00026\n",
      "\ttrain_loss: 1.9437\n",
      "\tval_loss: 1.7768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 138\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y254sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepLSTM_hour_history += NormalNonDeepLSTM_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_gru_forward_min = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_min = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_min = BidirectionalRNNWithAttention(non_deep_gru_forward_min, non_deep_gru_backward_min)\n",
    "\n",
    "non_deep_gru_forward_hour = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_hour = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_hour = BidirectionalRNNWithAttention(non_deep_gru_forward_hour, non_deep_gru_backward_hour)\n",
    "#fc layer\n",
    "non_deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min = to_device(NormalArchitecture(bidirectional_gru_encoder_min, non_deep_gru_fc_dst_min, non_deep_gru_fc_kp_min), device)\n",
    "NormalNonDeepGRU_hour = to_device(NormalArchitecture(bidirectional_gru_encoder_hour, non_deep_gru_fc_dst_hour, non_deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min_history += NormalNonDeepGRU_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.1161\n",
      "\tval_loss: 2.1215\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_loss: 2.0831\n",
      "\tval_loss: 2.0747\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 145\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y264sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepGRU_hour_history += NormalNonDeepGRU_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_rnn_forward_min = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_min = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_min = BidirectionalRNNWithAttention(non_deep_rnn_forward_min, non_deep_rnn_backward_min)\n",
    "\n",
    "non_deep_rnn_forward_hour = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_hour = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_hour = BidirectionalRNNWithAttention(non_deep_rnn_forward_hour, non_deep_rnn_backward_hour)\n",
    "#fc layer\n",
    "non_deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_min = to_device(NormalArchitecture(bidirectional_rnn_encoder_min, non_deep_rnn_fc_dst_min, non_deep_rnn_fc_kp_min), device)\n",
    "NormalNonDeepVanillaRNN_hour = to_device(NormalArchitecture(bidirectional_rnn_encoder_hour, non_deep_rnn_fc_dst_hour, non_deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history += NormalNonDeepVanillaRNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.0527\n",
      "\tval_loss: 2.0624\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 152\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y304sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepVanillaRNN_hour_history += NormalNonDeepVanillaRNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
