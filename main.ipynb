{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocessing import *\n",
    "from data.data_utils import *\n",
    "from models.macro_architectures import *\n",
    "from models.micro_architectures import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format: YYYYMMDD\n",
    "start_time = '20220801'\n",
    "end_time = '20230801'\n",
    "scrap_date = interval_time(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(set([day[:6] for day in scrap_date]))\n",
    "import_Dst(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_sample, l2_sample, dst, kp = automated_preprocessing(scrap_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving missing values with interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_ = f'{start_time[:4]}-{start_time[4:6]}-{start_time[-2:]} 00:00:00'\n",
    "end_time_ = f'{end_time[:4]}-{end_time[4:6]}-{end_time[-2:]} 23:59:00' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = '1T'\n",
    "\n",
    "full_time_index = pd.date_range(start=start_time_, end=end_time_, freq=freq)\n",
    "\n",
    "l1_sample = l1_sample.reindex(full_time_index)\n",
    "\n",
    "l1_sample = l1_sample.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_sample = l2_sample.reindex(full_time_index)\n",
    "\n",
    "l2_sample = l2_sample.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 (raw) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>-478.65714</td>\n",
       "      <td>43.071430</td>\n",
       "      <td>-18.400000</td>\n",
       "      <td>-478.65714</td>\n",
       "      <td>40.957146</td>\n",
       "      <td>-22.714285</td>\n",
       "      <td>480.95712</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>173441.860</td>\n",
       "      <td>8.791893</td>\n",
       "      <td>7.086200</td>\n",
       "      <td>-4.019755</td>\n",
       "      <td>3.270043</td>\n",
       "      <td>21.840690</td>\n",
       "      <td>330.44970</td>\n",
       "      <td>7.086200</td>\n",
       "      <td>-3.664647</td>\n",
       "      <td>3.663627</td>\n",
       "      <td>24.632782</td>\n",
       "      <td>332.67020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:01:00</th>\n",
       "      <td>-480.98570</td>\n",
       "      <td>42.057140</td>\n",
       "      <td>-22.585714</td>\n",
       "      <td>-480.98570</td>\n",
       "      <td>39.514286</td>\n",
       "      <td>-26.742857</td>\n",
       "      <td>483.37143</td>\n",
       "      <td>8.464286</td>\n",
       "      <td>185467.140</td>\n",
       "      <td>8.582591</td>\n",
       "      <td>6.739781</td>\n",
       "      <td>-4.466785</td>\n",
       "      <td>2.769711</td>\n",
       "      <td>18.872953</td>\n",
       "      <td>326.47080</td>\n",
       "      <td>6.739781</td>\n",
       "      <td>-4.159703</td>\n",
       "      <td>3.212529</td>\n",
       "      <td>22.036581</td>\n",
       "      <td>328.33280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:02:00</th>\n",
       "      <td>-491.07144</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>-22.014284</td>\n",
       "      <td>-491.07144</td>\n",
       "      <td>53.642857</td>\n",
       "      <td>-27.642857</td>\n",
       "      <td>495.05713</td>\n",
       "      <td>9.305715</td>\n",
       "      <td>218374.280</td>\n",
       "      <td>7.703689</td>\n",
       "      <td>5.968021</td>\n",
       "      <td>-2.387868</td>\n",
       "      <td>3.884053</td>\n",
       "      <td>30.909138</td>\n",
       "      <td>339.15740</td>\n",
       "      <td>5.968021</td>\n",
       "      <td>-1.976642</td>\n",
       "      <td>4.108515</td>\n",
       "      <td>32.785530</td>\n",
       "      <td>314.55447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:03:00</th>\n",
       "      <td>-493.52856</td>\n",
       "      <td>68.014290</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>-493.52856</td>\n",
       "      <td>65.214290</td>\n",
       "      <td>-30.857143</td>\n",
       "      <td>498.91428</td>\n",
       "      <td>9.671428</td>\n",
       "      <td>228698.580</td>\n",
       "      <td>7.239092</td>\n",
       "      <td>5.971862</td>\n",
       "      <td>-0.815659</td>\n",
       "      <td>3.879902</td>\n",
       "      <td>32.538246</td>\n",
       "      <td>309.05472</td>\n",
       "      <td>5.971862</td>\n",
       "      <td>-0.412276</td>\n",
       "      <td>3.943251</td>\n",
       "      <td>33.105440</td>\n",
       "      <td>263.87167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:04:00</th>\n",
       "      <td>-484.83334</td>\n",
       "      <td>53.383330</td>\n",
       "      <td>-15.783334</td>\n",
       "      <td>-484.83334</td>\n",
       "      <td>51.483334</td>\n",
       "      <td>-21.199999</td>\n",
       "      <td>488.08334</td>\n",
       "      <td>9.080000</td>\n",
       "      <td>204210.000</td>\n",
       "      <td>7.844100</td>\n",
       "      <td>6.698265</td>\n",
       "      <td>-1.942467</td>\n",
       "      <td>3.496836</td>\n",
       "      <td>26.688057</td>\n",
       "      <td>343.98862</td>\n",
       "      <td>6.698265</td>\n",
       "      <td>-1.571605</td>\n",
       "      <td>3.678486</td>\n",
       "      <td>28.167646</td>\n",
       "      <td>346.98236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:55:00</th>\n",
       "      <td>-390.41000</td>\n",
       "      <td>20.689999</td>\n",
       "      <td>-2.420000</td>\n",
       "      <td>-390.41000</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>-4.620000</td>\n",
       "      <td>390.99000</td>\n",
       "      <td>8.613000</td>\n",
       "      <td>79090.400</td>\n",
       "      <td>8.708879</td>\n",
       "      <td>3.890249</td>\n",
       "      <td>-7.049568</td>\n",
       "      <td>3.313216</td>\n",
       "      <td>22.363012</td>\n",
       "      <td>298.89180</td>\n",
       "      <td>3.890249</td>\n",
       "      <td>-6.658564</td>\n",
       "      <td>4.041955</td>\n",
       "      <td>27.656048</td>\n",
       "      <td>300.29570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:56:00</th>\n",
       "      <td>-393.74445</td>\n",
       "      <td>17.411110</td>\n",
       "      <td>-2.655556</td>\n",
       "      <td>-393.74445</td>\n",
       "      <td>17.011112</td>\n",
       "      <td>-4.477778</td>\n",
       "      <td>394.14444</td>\n",
       "      <td>9.308888</td>\n",
       "      <td>104618.664</td>\n",
       "      <td>8.466495</td>\n",
       "      <td>3.683012</td>\n",
       "      <td>-7.056999</td>\n",
       "      <td>2.848440</td>\n",
       "      <td>19.695435</td>\n",
       "      <td>297.55127</td>\n",
       "      <td>3.683012</td>\n",
       "      <td>-6.714469</td>\n",
       "      <td>3.581986</td>\n",
       "      <td>25.071960</td>\n",
       "      <td>298.73755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:57:00</th>\n",
       "      <td>-390.28183</td>\n",
       "      <td>17.427273</td>\n",
       "      <td>-3.790909</td>\n",
       "      <td>-390.28183</td>\n",
       "      <td>16.936363</td>\n",
       "      <td>-5.627273</td>\n",
       "      <td>390.70908</td>\n",
       "      <td>8.784545</td>\n",
       "      <td>78793.630</td>\n",
       "      <td>8.379578</td>\n",
       "      <td>3.853854</td>\n",
       "      <td>-6.783406</td>\n",
       "      <td>3.052517</td>\n",
       "      <td>21.368494</td>\n",
       "      <td>299.60187</td>\n",
       "      <td>3.853854</td>\n",
       "      <td>-6.419947</td>\n",
       "      <td>3.757228</td>\n",
       "      <td>26.645920</td>\n",
       "      <td>300.97607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:58:00</th>\n",
       "      <td>-391.43634</td>\n",
       "      <td>20.827272</td>\n",
       "      <td>2.209091</td>\n",
       "      <td>-391.43634</td>\n",
       "      <td>20.954546</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>392.16360</td>\n",
       "      <td>9.211819</td>\n",
       "      <td>100566.910</td>\n",
       "      <td>8.261917</td>\n",
       "      <td>4.074574</td>\n",
       "      <td>-4.820900</td>\n",
       "      <td>4.966876</td>\n",
       "      <td>37.815850</td>\n",
       "      <td>311.42163</td>\n",
       "      <td>4.074574</td>\n",
       "      <td>-4.263566</td>\n",
       "      <td>5.452666</td>\n",
       "      <td>42.207394</td>\n",
       "      <td>315.36426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:59:00</th>\n",
       "      <td>-389.10000</td>\n",
       "      <td>25.187500</td>\n",
       "      <td>9.925000</td>\n",
       "      <td>-389.10000</td>\n",
       "      <td>26.125000</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>390.10000</td>\n",
       "      <td>8.717500</td>\n",
       "      <td>76896.375</td>\n",
       "      <td>8.233093</td>\n",
       "      <td>4.010084</td>\n",
       "      <td>-4.380499</td>\n",
       "      <td>5.672841</td>\n",
       "      <td>43.632923</td>\n",
       "      <td>312.56330</td>\n",
       "      <td>4.010084</td>\n",
       "      <td>-3.749102</td>\n",
       "      <td>6.108538</td>\n",
       "      <td>47.981370</td>\n",
       "      <td>317.04538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527040 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2022-08-01 00:00:00     -478.65714      43.071430     -18.400000   \n",
       "2022-08-01 00:01:00     -480.98570      42.057140     -22.585714   \n",
       "2022-08-01 00:02:00     -491.07144      56.200000     -22.014284   \n",
       "2022-08-01 00:03:00     -493.52856      68.014290     -24.000000   \n",
       "2022-08-01 00:04:00     -484.83334      53.383330     -15.783334   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 23:55:00     -390.41000      20.689999      -2.420000   \n",
       "2023-08-01 23:56:00     -393.74445      17.411110      -2.655556   \n",
       "2023-08-01 23:57:00     -390.28183      17.427273      -3.790909   \n",
       "2023-08-01 23:58:00     -391.43634      20.827272       2.209091   \n",
       "2023-08-01 23:59:00     -389.10000      25.187500       9.925000   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2022-08-01 00:00:00     -478.65714      40.957146     -22.714285   \n",
       "2022-08-01 00:01:00     -480.98570      39.514286     -26.742857   \n",
       "2022-08-01 00:02:00     -491.07144      53.642857     -27.642857   \n",
       "2022-08-01 00:03:00     -493.52856      65.214290     -30.857143   \n",
       "2022-08-01 00:04:00     -484.83334      51.483334     -21.199999   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 23:55:00     -390.41000      20.330000      -4.620000   \n",
       "2023-08-01 23:56:00     -393.74445      17.011112      -4.477778   \n",
       "2023-08-01 23:57:00     -390.28183      16.936363      -5.627273   \n",
       "2023-08-01 23:58:00     -391.43634      20.954546      -0.027273   \n",
       "2023-08-01 23:59:00     -389.10000      26.125000       7.187500   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2022-08-01 00:00:00     480.95712        8.510000          173441.860   \n",
       "2022-08-01 00:01:00     483.37143        8.464286          185467.140   \n",
       "2022-08-01 00:02:00     495.05713        9.305715          218374.280   \n",
       "2022-08-01 00:03:00     498.91428        9.671428          228698.580   \n",
       "2022-08-01 00:04:00     488.08334        9.080000          204210.000   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-01 23:55:00     390.99000        8.613000           79090.400   \n",
       "2023-08-01 23:56:00     394.14444        9.308888          104618.664   \n",
       "2023-08-01 23:57:00     390.70908        8.784545           78793.630   \n",
       "2023-08-01 23:58:00     392.16360        9.211819          100566.910   \n",
       "2023-08-01 23:59:00     390.10000        8.717500           76896.375   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2022-08-01 00:00:00  8.791893  7.086200 -4.019755  3.270043  21.840690   \n",
       "2022-08-01 00:01:00  8.582591  6.739781 -4.466785  2.769711  18.872953   \n",
       "2022-08-01 00:02:00  7.703689  5.968021 -2.387868  3.884053  30.909138   \n",
       "2022-08-01 00:03:00  7.239092  5.971862 -0.815659  3.879902  32.538246   \n",
       "2022-08-01 00:04:00  7.844100  6.698265 -1.942467  3.496836  26.688057   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-01 23:55:00  8.708879  3.890249 -7.049568  3.313216  22.363012   \n",
       "2023-08-01 23:56:00  8.466495  3.683012 -7.056999  2.848440  19.695435   \n",
       "2023-08-01 23:57:00  8.379578  3.853854 -6.783406  3.052517  21.368494   \n",
       "2023-08-01 23:58:00  8.261917  4.074574 -4.820900  4.966876  37.815850   \n",
       "2023-08-01 23:59:00  8.233093  4.010084 -4.380499  5.672841  43.632923   \n",
       "\n",
       "                       phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2022-08-01 00:00:00  330.44970  7.086200 -3.664647  3.663627  24.632782   \n",
       "2022-08-01 00:01:00  326.47080  6.739781 -4.159703  3.212529  22.036581   \n",
       "2022-08-01 00:02:00  339.15740  5.968021 -1.976642  4.108515  32.785530   \n",
       "2022-08-01 00:03:00  309.05472  5.971862 -0.412276  3.943251  33.105440   \n",
       "2022-08-01 00:04:00  343.98862  6.698265 -1.571605  3.678486  28.167646   \n",
       "...                        ...       ...       ...       ...        ...   \n",
       "2023-08-01 23:55:00  298.89180  3.890249 -6.658564  4.041955  27.656048   \n",
       "2023-08-01 23:56:00  297.55127  3.683012 -6.714469  3.581986  25.071960   \n",
       "2023-08-01 23:57:00  299.60187  3.853854 -6.419947  3.757228  26.645920   \n",
       "2023-08-01 23:58:00  311.42163  4.074574 -4.263566  5.452666  42.207394   \n",
       "2023-08-01 23:59:00  312.56330  4.010084 -3.749102  6.108538  47.981370   \n",
       "\n",
       "                       phi_gsm  \n",
       "2022-08-01 00:00:00  332.67020  \n",
       "2022-08-01 00:01:00  328.33280  \n",
       "2022-08-01 00:02:00  314.55447  \n",
       "2022-08-01 00:03:00  263.87167  \n",
       "2022-08-01 00:04:00  346.98236  \n",
       "...                        ...  \n",
       "2023-08-01 23:55:00  300.29570  \n",
       "2023-08-01 23:56:00  298.73755  \n",
       "2023-08-01 23:57:00  300.97607  \n",
       "2023-08-01 23:58:00  315.36426  \n",
       "2023-08-01 23:59:00  317.04538  \n",
       "\n",
       "[527040 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>-489.302281</td>\n",
       "      <td>57.179857</td>\n",
       "      <td>-21.269801</td>\n",
       "      <td>-489.302281</td>\n",
       "      <td>54.485076</td>\n",
       "      <td>-27.490186</td>\n",
       "      <td>493.251960</td>\n",
       "      <td>9.247633</td>\n",
       "      <td>198485.987167</td>\n",
       "      <td>7.543399</td>\n",
       "      <td>6.291421</td>\n",
       "      <td>-1.856414</td>\n",
       "      <td>2.859877</td>\n",
       "      <td>22.954698</td>\n",
       "      <td>300.997411</td>\n",
       "      <td>6.291421</td>\n",
       "      <td>-1.527907</td>\n",
       "      <td>3.041643</td>\n",
       "      <td>24.361645</td>\n",
       "      <td>297.380635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 01:00:00</th>\n",
       "      <td>-508.790815</td>\n",
       "      <td>51.889845</td>\n",
       "      <td>-27.850028</td>\n",
       "      <td>-508.790815</td>\n",
       "      <td>47.635167</td>\n",
       "      <td>-34.453706</td>\n",
       "      <td>512.453934</td>\n",
       "      <td>9.912636</td>\n",
       "      <td>234197.626667</td>\n",
       "      <td>6.141733</td>\n",
       "      <td>4.452409</td>\n",
       "      <td>-2.402331</td>\n",
       "      <td>1.739807</td>\n",
       "      <td>16.432656</td>\n",
       "      <td>265.105190</td>\n",
       "      <td>4.452409</td>\n",
       "      <td>-2.157465</td>\n",
       "      <td>2.061328</td>\n",
       "      <td>19.703389</td>\n",
       "      <td>240.259886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 02:00:00</th>\n",
       "      <td>-522.989989</td>\n",
       "      <td>46.409234</td>\n",
       "      <td>-34.373814</td>\n",
       "      <td>-522.989989</td>\n",
       "      <td>40.170385</td>\n",
       "      <td>-41.611131</td>\n",
       "      <td>526.401869</td>\n",
       "      <td>9.133113</td>\n",
       "      <td>218915.152667</td>\n",
       "      <td>5.931544</td>\n",
       "      <td>0.184564</td>\n",
       "      <td>-2.469814</td>\n",
       "      <td>-0.172089</td>\n",
       "      <td>-2.568171</td>\n",
       "      <td>204.232442</td>\n",
       "      <td>0.184564</td>\n",
       "      <td>-2.453588</td>\n",
       "      <td>0.207707</td>\n",
       "      <td>1.573937</td>\n",
       "      <td>197.414516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 03:00:00</th>\n",
       "      <td>-498.359199</td>\n",
       "      <td>43.835917</td>\n",
       "      <td>-35.477302</td>\n",
       "      <td>-498.359199</td>\n",
       "      <td>35.712523</td>\n",
       "      <td>-43.524897</td>\n",
       "      <td>501.855898</td>\n",
       "      <td>7.695283</td>\n",
       "      <td>193808.512500</td>\n",
       "      <td>6.292952</td>\n",
       "      <td>5.306359</td>\n",
       "      <td>-1.672818</td>\n",
       "      <td>1.302133</td>\n",
       "      <td>11.992297</td>\n",
       "      <td>274.047466</td>\n",
       "      <td>5.306359</td>\n",
       "      <td>-1.384970</td>\n",
       "      <td>1.622839</td>\n",
       "      <td>15.157878</td>\n",
       "      <td>257.554610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 04:00:00</th>\n",
       "      <td>-525.964391</td>\n",
       "      <td>31.554381</td>\n",
       "      <td>-37.966738</td>\n",
       "      <td>-525.964391</td>\n",
       "      <td>21.319488</td>\n",
       "      <td>-44.454766</td>\n",
       "      <td>528.562193</td>\n",
       "      <td>8.653108</td>\n",
       "      <td>209614.043500</td>\n",
       "      <td>5.501450</td>\n",
       "      <td>0.355088</td>\n",
       "      <td>-3.930183</td>\n",
       "      <td>-0.112578</td>\n",
       "      <td>-1.028107</td>\n",
       "      <td>266.247303</td>\n",
       "      <td>0.355088</td>\n",
       "      <td>-3.853669</td>\n",
       "      <td>0.840545</td>\n",
       "      <td>10.024766</td>\n",
       "      <td>266.188024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 19:00:00</th>\n",
       "      <td>-382.680769</td>\n",
       "      <td>0.217665</td>\n",
       "      <td>-15.192104</td>\n",
       "      <td>-382.680769</td>\n",
       "      <td>-2.215317</td>\n",
       "      <td>-15.036393</td>\n",
       "      <td>383.136132</td>\n",
       "      <td>9.807184</td>\n",
       "      <td>66666.911150</td>\n",
       "      <td>9.816390</td>\n",
       "      <td>6.217887</td>\n",
       "      <td>-7.306248</td>\n",
       "      <td>-0.344754</td>\n",
       "      <td>-2.062787</td>\n",
       "      <td>310.312771</td>\n",
       "      <td>6.217887</td>\n",
       "      <td>-7.258762</td>\n",
       "      <td>0.820913</td>\n",
       "      <td>4.873037</td>\n",
       "      <td>310.610893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 20:00:00</th>\n",
       "      <td>-382.508196</td>\n",
       "      <td>-0.425859</td>\n",
       "      <td>-19.921152</td>\n",
       "      <td>-382.508196</td>\n",
       "      <td>-2.982734</td>\n",
       "      <td>-19.695648</td>\n",
       "      <td>383.090436</td>\n",
       "      <td>10.251275</td>\n",
       "      <td>56155.322900</td>\n",
       "      <td>9.312197</td>\n",
       "      <td>5.133512</td>\n",
       "      <td>-7.576634</td>\n",
       "      <td>-1.271946</td>\n",
       "      <td>-7.821866</td>\n",
       "      <td>304.145239</td>\n",
       "      <td>5.133512</td>\n",
       "      <td>-7.679039</td>\n",
       "      <td>-0.282955</td>\n",
       "      <td>-1.693841</td>\n",
       "      <td>303.807800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 21:00:00</th>\n",
       "      <td>-378.749960</td>\n",
       "      <td>-7.459660</td>\n",
       "      <td>-28.139573</td>\n",
       "      <td>-378.749960</td>\n",
       "      <td>-10.480231</td>\n",
       "      <td>-27.167887</td>\n",
       "      <td>380.014618</td>\n",
       "      <td>9.695502</td>\n",
       "      <td>58283.928467</td>\n",
       "      <td>8.919270</td>\n",
       "      <td>5.942875</td>\n",
       "      <td>-6.403760</td>\n",
       "      <td>-0.588859</td>\n",
       "      <td>-3.800311</td>\n",
       "      <td>312.912670</td>\n",
       "      <td>5.942875</td>\n",
       "      <td>-6.430948</td>\n",
       "      <td>0.113013</td>\n",
       "      <td>0.756934</td>\n",
       "      <td>312.845110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 22:00:00</th>\n",
       "      <td>-388.897926</td>\n",
       "      <td>9.909498</td>\n",
       "      <td>-4.975384</td>\n",
       "      <td>-388.897926</td>\n",
       "      <td>9.369652</td>\n",
       "      <td>-5.926781</td>\n",
       "      <td>389.483691</td>\n",
       "      <td>9.748028</td>\n",
       "      <td>103017.672383</td>\n",
       "      <td>8.472186</td>\n",
       "      <td>5.815027</td>\n",
       "      <td>-5.407756</td>\n",
       "      <td>2.184644</td>\n",
       "      <td>14.794651</td>\n",
       "      <td>316.942325</td>\n",
       "      <td>5.815027</td>\n",
       "      <td>-5.162399</td>\n",
       "      <td>2.712489</td>\n",
       "      <td>18.609071</td>\n",
       "      <td>318.306821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:00:00</th>\n",
       "      <td>-390.817842</td>\n",
       "      <td>18.406591</td>\n",
       "      <td>-1.972806</td>\n",
       "      <td>-390.817842</td>\n",
       "      <td>18.118264</td>\n",
       "      <td>-3.852759</td>\n",
       "      <td>391.421486</td>\n",
       "      <td>8.746741</td>\n",
       "      <td>91400.260000</td>\n",
       "      <td>8.147829</td>\n",
       "      <td>4.140885</td>\n",
       "      <td>-5.553662</td>\n",
       "      <td>3.373441</td>\n",
       "      <td>24.279417</td>\n",
       "      <td>306.572643</td>\n",
       "      <td>4.140885</td>\n",
       "      <td>-5.176985</td>\n",
       "      <td>3.923564</td>\n",
       "      <td>28.809884</td>\n",
       "      <td>307.551947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8784 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2022-08-01 00:00:00    -489.302281      57.179857     -21.269801   \n",
       "2022-08-01 01:00:00    -508.790815      51.889845     -27.850028   \n",
       "2022-08-01 02:00:00    -522.989989      46.409234     -34.373814   \n",
       "2022-08-01 03:00:00    -498.359199      43.835917     -35.477302   \n",
       "2022-08-01 04:00:00    -525.964391      31.554381     -37.966738   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 19:00:00    -382.680769       0.217665     -15.192104   \n",
       "2023-08-01 20:00:00    -382.508196      -0.425859     -19.921152   \n",
       "2023-08-01 21:00:00    -378.749960      -7.459660     -28.139573   \n",
       "2023-08-01 22:00:00    -388.897926       9.909498      -4.975384   \n",
       "2023-08-01 23:00:00    -390.817842      18.406591      -1.972806   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2022-08-01 00:00:00    -489.302281      54.485076     -27.490186   \n",
       "2022-08-01 01:00:00    -508.790815      47.635167     -34.453706   \n",
       "2022-08-01 02:00:00    -522.989989      40.170385     -41.611131   \n",
       "2022-08-01 03:00:00    -498.359199      35.712523     -43.524897   \n",
       "2022-08-01 04:00:00    -525.964391      21.319488     -44.454766   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 19:00:00    -382.680769      -2.215317     -15.036393   \n",
       "2023-08-01 20:00:00    -382.508196      -2.982734     -19.695648   \n",
       "2023-08-01 21:00:00    -378.749960     -10.480231     -27.167887   \n",
       "2023-08-01 22:00:00    -388.897926       9.369652      -5.926781   \n",
       "2023-08-01 23:00:00    -390.817842      18.118264      -3.852759   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2022-08-01 00:00:00    493.251960        9.247633       198485.987167   \n",
       "2022-08-01 01:00:00    512.453934        9.912636       234197.626667   \n",
       "2022-08-01 02:00:00    526.401869        9.133113       218915.152667   \n",
       "2022-08-01 03:00:00    501.855898        7.695283       193808.512500   \n",
       "2022-08-01 04:00:00    528.562193        8.653108       209614.043500   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-01 19:00:00    383.136132        9.807184        66666.911150   \n",
       "2023-08-01 20:00:00    383.090436       10.251275        56155.322900   \n",
       "2023-08-01 21:00:00    380.014618        9.695502        58283.928467   \n",
       "2023-08-01 22:00:00    389.483691        9.748028       103017.672383   \n",
       "2023-08-01 23:00:00    391.421486        8.746741        91400.260000   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2022-08-01 00:00:00  7.543399  6.291421 -1.856414  2.859877  22.954698   \n",
       "2022-08-01 01:00:00  6.141733  4.452409 -2.402331  1.739807  16.432656   \n",
       "2022-08-01 02:00:00  5.931544  0.184564 -2.469814 -0.172089  -2.568171   \n",
       "2022-08-01 03:00:00  6.292952  5.306359 -1.672818  1.302133  11.992297   \n",
       "2022-08-01 04:00:00  5.501450  0.355088 -3.930183 -0.112578  -1.028107   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-01 19:00:00  9.816390  6.217887 -7.306248 -0.344754  -2.062787   \n",
       "2023-08-01 20:00:00  9.312197  5.133512 -7.576634 -1.271946  -7.821866   \n",
       "2023-08-01 21:00:00  8.919270  5.942875 -6.403760 -0.588859  -3.800311   \n",
       "2023-08-01 22:00:00  8.472186  5.815027 -5.407756  2.184644  14.794651   \n",
       "2023-08-01 23:00:00  8.147829  4.140885 -5.553662  3.373441  24.279417   \n",
       "\n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2022-08-01 00:00:00  300.997411  6.291421 -1.527907  3.041643  24.361645   \n",
       "2022-08-01 01:00:00  265.105190  4.452409 -2.157465  2.061328  19.703389   \n",
       "2022-08-01 02:00:00  204.232442  0.184564 -2.453588  0.207707   1.573937   \n",
       "2022-08-01 03:00:00  274.047466  5.306359 -1.384970  1.622839  15.157878   \n",
       "2022-08-01 04:00:00  266.247303  0.355088 -3.853669  0.840545  10.024766   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "2023-08-01 19:00:00  310.312771  6.217887 -7.258762  0.820913   4.873037   \n",
       "2023-08-01 20:00:00  304.145239  5.133512 -7.679039 -0.282955  -1.693841   \n",
       "2023-08-01 21:00:00  312.912670  5.942875 -6.430948  0.113013   0.756934   \n",
       "2023-08-01 22:00:00  316.942325  5.815027 -5.162399  2.712489  18.609071   \n",
       "2023-08-01 23:00:00  306.572643  4.140885 -5.176985  3.923564  28.809884   \n",
       "\n",
       "                        phi_gsm  \n",
       "2022-08-01 00:00:00  297.380635  \n",
       "2022-08-01 01:00:00  240.259886  \n",
       "2022-08-01 02:00:00  197.414516  \n",
       "2022-08-01 03:00:00  257.554610  \n",
       "2022-08-01 04:00:00  266.188024  \n",
       "...                         ...  \n",
       "2023-08-01 19:00:00  310.610893  \n",
       "2023-08-01 20:00:00  303.807800  \n",
       "2023-08-01 21:00:00  312.845110  \n",
       "2023-08-01 22:00:00  318.306821  \n",
       "2023-08-01 23:00:00  307.551947  \n",
       "\n",
       "[8784 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_sample_hour = l1_sample.resample('60min').mean()\n",
    "l1_sample_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 (cleaned) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>-478.8</td>\n",
       "      <td>42.3</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>-478.8</td>\n",
       "      <td>40.3</td>\n",
       "      <td>-22.5</td>\n",
       "      <td>481.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>173700.0</td>\n",
       "      <td>8.79</td>\n",
       "      <td>7.08</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>3.28</td>\n",
       "      <td>21.91</td>\n",
       "      <td>330.34</td>\n",
       "      <td>7.08</td>\n",
       "      <td>-3.68</td>\n",
       "      <td>3.67</td>\n",
       "      <td>24.72</td>\n",
       "      <td>332.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:01:00</th>\n",
       "      <td>-480.9</td>\n",
       "      <td>42.2</td>\n",
       "      <td>-23.3</td>\n",
       "      <td>-480.9</td>\n",
       "      <td>39.6</td>\n",
       "      <td>-27.5</td>\n",
       "      <td>483.3</td>\n",
       "      <td>8.40</td>\n",
       "      <td>180724.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>6.74</td>\n",
       "      <td>-4.48</td>\n",
       "      <td>2.76</td>\n",
       "      <td>18.81</td>\n",
       "      <td>326.42</td>\n",
       "      <td>6.74</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>3.20</td>\n",
       "      <td>21.98</td>\n",
       "      <td>328.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:02:00</th>\n",
       "      <td>-491.4</td>\n",
       "      <td>56.1</td>\n",
       "      <td>-22.1</td>\n",
       "      <td>-491.4</td>\n",
       "      <td>53.6</td>\n",
       "      <td>-27.7</td>\n",
       "      <td>495.1</td>\n",
       "      <td>9.23</td>\n",
       "      <td>209072.0</td>\n",
       "      <td>7.69</td>\n",
       "      <td>6.04</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>3.86</td>\n",
       "      <td>30.63</td>\n",
       "      <td>337.82</td>\n",
       "      <td>6.04</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>32.69</td>\n",
       "      <td>341.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:03:00</th>\n",
       "      <td>-493.5</td>\n",
       "      <td>67.6</td>\n",
       "      <td>-25.9</td>\n",
       "      <td>-493.5</td>\n",
       "      <td>64.6</td>\n",
       "      <td>-32.7</td>\n",
       "      <td>498.8</td>\n",
       "      <td>9.64</td>\n",
       "      <td>225575.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5.99</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>3.86</td>\n",
       "      <td>32.52</td>\n",
       "      <td>351.67</td>\n",
       "      <td>5.99</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>3.93</td>\n",
       "      <td>33.18</td>\n",
       "      <td>355.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:04:00</th>\n",
       "      <td>-483.7</td>\n",
       "      <td>52.9</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>-483.7</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>486.9</td>\n",
       "      <td>9.06</td>\n",
       "      <td>200746.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>6.75</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>3.51</td>\n",
       "      <td>26.62</td>\n",
       "      <td>344.43</td>\n",
       "      <td>6.75</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>3.69</td>\n",
       "      <td>28.06</td>\n",
       "      <td>347.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:55:00</th>\n",
       "      <td>-390.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-390.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>390.9</td>\n",
       "      <td>8.57</td>\n",
       "      <td>79088.0</td>\n",
       "      <td>8.71</td>\n",
       "      <td>3.90</td>\n",
       "      <td>-7.05</td>\n",
       "      <td>3.33</td>\n",
       "      <td>22.46</td>\n",
       "      <td>298.92</td>\n",
       "      <td>3.90</td>\n",
       "      <td>-6.66</td>\n",
       "      <td>4.06</td>\n",
       "      <td>27.75</td>\n",
       "      <td>300.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:56:00</th>\n",
       "      <td>-394.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-394.4</td>\n",
       "      <td>17.3</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>394.8</td>\n",
       "      <td>9.41</td>\n",
       "      <td>110712.0</td>\n",
       "      <td>8.46</td>\n",
       "      <td>3.67</td>\n",
       "      <td>-7.05</td>\n",
       "      <td>2.86</td>\n",
       "      <td>19.79</td>\n",
       "      <td>297.53</td>\n",
       "      <td>3.67</td>\n",
       "      <td>-6.71</td>\n",
       "      <td>3.59</td>\n",
       "      <td>25.17</td>\n",
       "      <td>298.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:57:00</th>\n",
       "      <td>-389.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-389.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>389.9</td>\n",
       "      <td>8.63</td>\n",
       "      <td>58271.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>3.05</td>\n",
       "      <td>21.38</td>\n",
       "      <td>299.62</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-6.42</td>\n",
       "      <td>3.76</td>\n",
       "      <td>26.65</td>\n",
       "      <td>300.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:58:00</th>\n",
       "      <td>-391.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-391.6</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>392.2</td>\n",
       "      <td>9.19</td>\n",
       "      <td>108681.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>4.07</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>4.69</td>\n",
       "      <td>35.80</td>\n",
       "      <td>308.73</td>\n",
       "      <td>4.07</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>5.21</td>\n",
       "      <td>40.47</td>\n",
       "      <td>311.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:59:00</th>\n",
       "      <td>-388.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-388.7</td>\n",
       "      <td>25.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>389.6</td>\n",
       "      <td>8.79</td>\n",
       "      <td>71505.0</td>\n",
       "      <td>8.23</td>\n",
       "      <td>4.02</td>\n",
       "      <td>-4.39</td>\n",
       "      <td>5.68</td>\n",
       "      <td>43.63</td>\n",
       "      <td>312.43</td>\n",
       "      <td>4.02</td>\n",
       "      <td>-3.76</td>\n",
       "      <td>6.11</td>\n",
       "      <td>47.99</td>\n",
       "      <td>316.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527040 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2022-08-01 00:00:00         -478.8           42.3          -18.2   \n",
       "2022-08-01 00:01:00         -480.9           42.2          -23.3   \n",
       "2022-08-01 00:02:00         -491.4           56.1          -22.1   \n",
       "2022-08-01 00:03:00         -493.5           67.6          -25.9   \n",
       "2022-08-01 00:04:00         -483.7           52.9          -15.9   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 23:55:00         -390.4           19.9           -3.1   \n",
       "2023-08-01 23:56:00         -394.4           17.7           -2.6   \n",
       "2023-08-01 23:57:00         -389.5           17.7           -4.3   \n",
       "2023-08-01 23:58:00         -391.6           20.7            2.4   \n",
       "2023-08-01 23:59:00         -388.7           24.7            9.7   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2022-08-01 00:00:00         -478.8           40.3          -22.5   \n",
       "2022-08-01 00:01:00         -480.9           39.6          -27.5   \n",
       "2022-08-01 00:02:00         -491.4           53.6          -27.7   \n",
       "2022-08-01 00:03:00         -493.5           64.6          -32.7   \n",
       "2022-08-01 00:04:00         -483.7           51.0          -21.2   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 23:55:00         -390.4           19.5           -5.2   \n",
       "2023-08-01 23:56:00         -394.4           17.3           -4.5   \n",
       "2023-08-01 23:57:00         -389.5           17.1           -6.2   \n",
       "2023-08-01 23:58:00         -391.6           20.8            0.2   \n",
       "2023-08-01 23:59:00         -388.7           25.6            7.0   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature    bt  \\\n",
       "2022-08-01 00:00:00         481.0            8.43            173700.0  8.79   \n",
       "2022-08-01 00:01:00         483.3            8.40            180724.0  8.59   \n",
       "2022-08-01 00:02:00         495.1            9.23            209072.0  7.69   \n",
       "2022-08-01 00:03:00         498.8            9.64            225575.0  7.24   \n",
       "2022-08-01 00:04:00         486.9            9.06            200746.0  7.87   \n",
       "...                           ...             ...                 ...   ...   \n",
       "2023-08-01 23:55:00         390.9            8.57             79088.0  8.71   \n",
       "2023-08-01 23:56:00         394.8            9.41            110712.0  8.46   \n",
       "2023-08-01 23:57:00         389.9            8.63             58271.0  8.38   \n",
       "2023-08-01 23:58:00         392.2            9.19            108681.0  8.26   \n",
       "2023-08-01 23:59:00         389.6            8.79             71505.0  8.23   \n",
       "\n",
       "                     bx_gse  by_gse  bz_gse  theta_gse  phi_gse  bx_gsm  \\\n",
       "2022-08-01 00:00:00    7.08   -4.03    3.28      21.91   330.34    7.08   \n",
       "2022-08-01 00:01:00    6.74   -4.48    2.76      18.81   326.42    6.74   \n",
       "2022-08-01 00:02:00    6.04   -2.46    3.86      30.63   337.82    6.04   \n",
       "2022-08-01 00:03:00    5.99   -0.88    3.86      32.52   351.67    5.99   \n",
       "2022-08-01 00:04:00    6.75   -1.88    3.51      26.62   344.43    6.75   \n",
       "...                     ...     ...     ...        ...      ...     ...   \n",
       "2023-08-01 23:55:00    3.90   -7.05    3.33      22.46   298.92    3.90   \n",
       "2023-08-01 23:56:00    3.67   -7.05    2.86      19.79   297.53    3.67   \n",
       "2023-08-01 23:57:00    3.85   -6.78    3.05      21.38   299.62    3.85   \n",
       "2023-08-01 23:58:00    4.07   -5.07    4.69      35.80   308.73    4.07   \n",
       "2023-08-01 23:59:00    4.02   -4.39    5.68      43.63   312.43    4.02   \n",
       "\n",
       "                     by_gsm  bz_gsm  theta_gsm  phi_gsm  \n",
       "2022-08-01 00:00:00   -3.68    3.67      24.72   332.56  \n",
       "2022-08-01 00:01:00   -4.17    3.20      21.98   328.26  \n",
       "2022-08-01 00:02:00   -2.05    4.10      32.69   341.22  \n",
       "2022-08-01 00:03:00   -0.48    3.93      33.18   355.46  \n",
       "2022-08-01 00:04:00   -1.51    3.69      28.06   347.39  \n",
       "...                     ...     ...        ...      ...  \n",
       "2023-08-01 23:55:00   -6.66    4.06      27.75   300.33  \n",
       "2023-08-01 23:56:00   -6.71    3.59      25.17   298.72  \n",
       "2023-08-01 23:57:00   -6.42    3.76      26.65   300.99  \n",
       "2023-08-01 23:58:00   -4.55    5.21      40.47   311.84  \n",
       "2023-08-01 23:59:00   -3.76    6.11      47.99   316.87  \n",
       "\n",
       "[527040 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>-489.208333</td>\n",
       "      <td>57.145000</td>\n",
       "      <td>-21.240000</td>\n",
       "      <td>-489.208333</td>\n",
       "      <td>54.460000</td>\n",
       "      <td>-27.443333</td>\n",
       "      <td>493.095000</td>\n",
       "      <td>9.246667</td>\n",
       "      <td>197578.583333</td>\n",
       "      <td>7.543333</td>\n",
       "      <td>6.303667</td>\n",
       "      <td>-1.872000</td>\n",
       "      <td>2.862500</td>\n",
       "      <td>23.042667</td>\n",
       "      <td>303.207333</td>\n",
       "      <td>6.303667</td>\n",
       "      <td>-1.544167</td>\n",
       "      <td>3.046000</td>\n",
       "      <td>24.468000</td>\n",
       "      <td>305.825500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 01:00:00</th>\n",
       "      <td>-508.771667</td>\n",
       "      <td>51.758333</td>\n",
       "      <td>-27.611667</td>\n",
       "      <td>-508.771667</td>\n",
       "      <td>47.553333</td>\n",
       "      <td>-34.195000</td>\n",
       "      <td>512.376667</td>\n",
       "      <td>9.911833</td>\n",
       "      <td>234221.300000</td>\n",
       "      <td>6.146833</td>\n",
       "      <td>4.458000</td>\n",
       "      <td>-2.411000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>16.625167</td>\n",
       "      <td>259.985167</td>\n",
       "      <td>4.458000</td>\n",
       "      <td>-2.165167</td>\n",
       "      <td>2.072333</td>\n",
       "      <td>19.910000</td>\n",
       "      <td>244.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 02:00:00</th>\n",
       "      <td>-522.971667</td>\n",
       "      <td>46.445000</td>\n",
       "      <td>-34.198333</td>\n",
       "      <td>-522.971667</td>\n",
       "      <td>40.241667</td>\n",
       "      <td>-41.433333</td>\n",
       "      <td>526.340000</td>\n",
       "      <td>9.119667</td>\n",
       "      <td>217786.800000</td>\n",
       "      <td>5.940000</td>\n",
       "      <td>0.200833</td>\n",
       "      <td>-2.490000</td>\n",
       "      <td>-0.181167</td>\n",
       "      <td>-2.719167</td>\n",
       "      <td>202.435000</td>\n",
       "      <td>0.200833</td>\n",
       "      <td>-2.474333</td>\n",
       "      <td>0.201833</td>\n",
       "      <td>1.558500</td>\n",
       "      <td>193.670667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 03:00:00</th>\n",
       "      <td>-498.388333</td>\n",
       "      <td>43.578333</td>\n",
       "      <td>-35.293333</td>\n",
       "      <td>-498.388333</td>\n",
       "      <td>35.510000</td>\n",
       "      <td>-43.275000</td>\n",
       "      <td>501.780000</td>\n",
       "      <td>7.701000</td>\n",
       "      <td>193128.650000</td>\n",
       "      <td>6.293667</td>\n",
       "      <td>5.318833</td>\n",
       "      <td>-1.675667</td>\n",
       "      <td>1.297167</td>\n",
       "      <td>12.009167</td>\n",
       "      <td>270.250167</td>\n",
       "      <td>5.318833</td>\n",
       "      <td>-1.389833</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>15.186333</td>\n",
       "      <td>242.839500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 04:00:00</th>\n",
       "      <td>-526.130000</td>\n",
       "      <td>31.710000</td>\n",
       "      <td>-37.916667</td>\n",
       "      <td>-526.130000</td>\n",
       "      <td>21.496667</td>\n",
       "      <td>-44.436667</td>\n",
       "      <td>528.681667</td>\n",
       "      <td>8.655500</td>\n",
       "      <td>209349.483333</td>\n",
       "      <td>5.515833</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>-3.937167</td>\n",
       "      <td>-0.106500</td>\n",
       "      <td>-1.025167</td>\n",
       "      <td>267.512000</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>-3.859000</td>\n",
       "      <td>0.846833</td>\n",
       "      <td>10.312333</td>\n",
       "      <td>267.249167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 19:00:00</th>\n",
       "      <td>-382.586667</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>-15.218333</td>\n",
       "      <td>-382.586667</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>-15.053333</td>\n",
       "      <td>382.978333</td>\n",
       "      <td>9.779667</td>\n",
       "      <td>65301.266667</td>\n",
       "      <td>9.817000</td>\n",
       "      <td>6.212000</td>\n",
       "      <td>-7.315667</td>\n",
       "      <td>-0.357333</td>\n",
       "      <td>-2.134333</td>\n",
       "      <td>310.247500</td>\n",
       "      <td>6.212000</td>\n",
       "      <td>-7.269500</td>\n",
       "      <td>0.811833</td>\n",
       "      <td>4.826333</td>\n",
       "      <td>310.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 20:00:00</th>\n",
       "      <td>-382.468333</td>\n",
       "      <td>-0.383333</td>\n",
       "      <td>-19.765000</td>\n",
       "      <td>-382.468333</td>\n",
       "      <td>-2.926667</td>\n",
       "      <td>-19.533333</td>\n",
       "      <td>383.011667</td>\n",
       "      <td>10.239167</td>\n",
       "      <td>55382.900000</td>\n",
       "      <td>9.318000</td>\n",
       "      <td>5.136667</td>\n",
       "      <td>-7.581167</td>\n",
       "      <td>-1.270667</td>\n",
       "      <td>-7.814667</td>\n",
       "      <td>304.145667</td>\n",
       "      <td>5.136667</td>\n",
       "      <td>-7.683833</td>\n",
       "      <td>-0.279333</td>\n",
       "      <td>-1.674333</td>\n",
       "      <td>303.811667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 21:00:00</th>\n",
       "      <td>-378.730000</td>\n",
       "      <td>-7.340000</td>\n",
       "      <td>-28.055000</td>\n",
       "      <td>-378.730000</td>\n",
       "      <td>-10.360000</td>\n",
       "      <td>-27.098333</td>\n",
       "      <td>379.943333</td>\n",
       "      <td>9.687167</td>\n",
       "      <td>57833.183333</td>\n",
       "      <td>8.919167</td>\n",
       "      <td>5.942833</td>\n",
       "      <td>-6.407333</td>\n",
       "      <td>-0.580333</td>\n",
       "      <td>-3.743667</td>\n",
       "      <td>312.893000</td>\n",
       "      <td>5.942833</td>\n",
       "      <td>-6.433500</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>312.825667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 22:00:00</th>\n",
       "      <td>-388.971667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-4.993333</td>\n",
       "      <td>-388.971667</td>\n",
       "      <td>9.453333</td>\n",
       "      <td>-5.953333</td>\n",
       "      <td>389.476667</td>\n",
       "      <td>9.755667</td>\n",
       "      <td>102499.000000</td>\n",
       "      <td>8.478000</td>\n",
       "      <td>5.823167</td>\n",
       "      <td>-5.413333</td>\n",
       "      <td>2.193833</td>\n",
       "      <td>14.888167</td>\n",
       "      <td>316.923833</td>\n",
       "      <td>5.823167</td>\n",
       "      <td>-5.166667</td>\n",
       "      <td>2.723000</td>\n",
       "      <td>18.712333</td>\n",
       "      <td>318.278333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 23:00:00</th>\n",
       "      <td>-390.960000</td>\n",
       "      <td>18.510000</td>\n",
       "      <td>-2.025000</td>\n",
       "      <td>-390.960000</td>\n",
       "      <td>18.225000</td>\n",
       "      <td>-3.918333</td>\n",
       "      <td>391.515000</td>\n",
       "      <td>8.735167</td>\n",
       "      <td>91170.183333</td>\n",
       "      <td>8.154833</td>\n",
       "      <td>4.148500</td>\n",
       "      <td>-5.562667</td>\n",
       "      <td>3.372500</td>\n",
       "      <td>24.301333</td>\n",
       "      <td>306.792833</td>\n",
       "      <td>4.148500</td>\n",
       "      <td>-5.187167</td>\n",
       "      <td>3.922500</td>\n",
       "      <td>28.849833</td>\n",
       "      <td>308.562333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8784 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2022-08-01 00:00:00    -489.208333      57.145000     -21.240000   \n",
       "2022-08-01 01:00:00    -508.771667      51.758333     -27.611667   \n",
       "2022-08-01 02:00:00    -522.971667      46.445000     -34.198333   \n",
       "2022-08-01 03:00:00    -498.388333      43.578333     -35.293333   \n",
       "2022-08-01 04:00:00    -526.130000      31.710000     -37.916667   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 19:00:00    -382.586667       0.195000     -15.218333   \n",
       "2023-08-01 20:00:00    -382.468333      -0.383333     -19.765000   \n",
       "2023-08-01 21:00:00    -378.730000      -7.340000     -28.055000   \n",
       "2023-08-01 22:00:00    -388.971667      10.000000      -4.993333   \n",
       "2023-08-01 23:00:00    -390.960000      18.510000      -2.025000   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2022-08-01 00:00:00    -489.208333      54.460000     -27.443333   \n",
       "2022-08-01 01:00:00    -508.771667      47.553333     -34.195000   \n",
       "2022-08-01 02:00:00    -522.971667      40.241667     -41.433333   \n",
       "2022-08-01 03:00:00    -498.388333      35.510000     -43.275000   \n",
       "2022-08-01 04:00:00    -526.130000      21.496667     -44.436667   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-01 19:00:00    -382.586667      -2.250000     -15.053333   \n",
       "2023-08-01 20:00:00    -382.468333      -2.926667     -19.533333   \n",
       "2023-08-01 21:00:00    -378.730000     -10.360000     -27.098333   \n",
       "2023-08-01 22:00:00    -388.971667       9.453333      -5.953333   \n",
       "2023-08-01 23:00:00    -390.960000      18.225000      -3.918333   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2022-08-01 00:00:00    493.095000        9.246667       197578.583333   \n",
       "2022-08-01 01:00:00    512.376667        9.911833       234221.300000   \n",
       "2022-08-01 02:00:00    526.340000        9.119667       217786.800000   \n",
       "2022-08-01 03:00:00    501.780000        7.701000       193128.650000   \n",
       "2022-08-01 04:00:00    528.681667        8.655500       209349.483333   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-01 19:00:00    382.978333        9.779667        65301.266667   \n",
       "2023-08-01 20:00:00    383.011667       10.239167        55382.900000   \n",
       "2023-08-01 21:00:00    379.943333        9.687167        57833.183333   \n",
       "2023-08-01 22:00:00    389.476667        9.755667       102499.000000   \n",
       "2023-08-01 23:00:00    391.515000        8.735167        91170.183333   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2022-08-01 00:00:00  7.543333  6.303667 -1.872000  2.862500  23.042667   \n",
       "2022-08-01 01:00:00  6.146833  4.458000 -2.411000  1.750000  16.625167   \n",
       "2022-08-01 02:00:00  5.940000  0.200833 -2.490000 -0.181167  -2.719167   \n",
       "2022-08-01 03:00:00  6.293667  5.318833 -1.675667  1.297167  12.009167   \n",
       "2022-08-01 04:00:00  5.515833  0.348000 -3.937167 -0.106500  -1.025167   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-01 19:00:00  9.817000  6.212000 -7.315667 -0.357333  -2.134333   \n",
       "2023-08-01 20:00:00  9.318000  5.136667 -7.581167 -1.270667  -7.814667   \n",
       "2023-08-01 21:00:00  8.919167  5.942833 -6.407333 -0.580333  -3.743667   \n",
       "2023-08-01 22:00:00  8.478000  5.823167 -5.413333  2.193833  14.888167   \n",
       "2023-08-01 23:00:00  8.154833  4.148500 -5.562667  3.372500  24.301333   \n",
       "\n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2022-08-01 00:00:00  303.207333  6.303667 -1.544167  3.046000  24.468000   \n",
       "2022-08-01 01:00:00  259.985167  4.458000 -2.165167  2.072333  19.910000   \n",
       "2022-08-01 02:00:00  202.435000  0.200833 -2.474333  0.201833   1.558500   \n",
       "2022-08-01 03:00:00  270.250167  5.318833 -1.389833  1.618000  15.186333   \n",
       "2022-08-01 04:00:00  267.512000  0.348000 -3.859000  0.846833  10.312333   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "2023-08-01 19:00:00  310.247500  6.212000 -7.269500  0.811833   4.826333   \n",
       "2023-08-01 20:00:00  304.145667  5.136667 -7.683833 -0.279333  -1.674333   \n",
       "2023-08-01 21:00:00  312.893000  5.942833 -6.433500  0.122500   0.823333   \n",
       "2023-08-01 22:00:00  316.923833  5.823167 -5.166667  2.723000  18.712333   \n",
       "2023-08-01 23:00:00  306.792833  4.148500 -5.187167  3.922500  28.849833   \n",
       "\n",
       "                        phi_gsm  \n",
       "2022-08-01 00:00:00  305.825500  \n",
       "2022-08-01 01:00:00  244.457500  \n",
       "2022-08-01 02:00:00  193.670667  \n",
       "2022-08-01 03:00:00  242.839500  \n",
       "2022-08-01 04:00:00  267.249167  \n",
       "...                         ...  \n",
       "2023-08-01 19:00:00  310.531000  \n",
       "2023-08-01 20:00:00  303.811667  \n",
       "2023-08-01 21:00:00  312.825667  \n",
       "2023-08-01 22:00:00  318.278333  \n",
       "2023-08-01 23:00:00  308.562333  \n",
       "\n",
       "[8784 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_sample_hour = l2_sample.resample('60min').mean()\n",
    "l2_sample_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dst data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        8\n",
       "2       10\n",
       "3        3\n",
       "4       -1\n",
       "        ..\n",
       "8779    14\n",
       "8780    13\n",
       "8781    11\n",
       "8782     6\n",
       "8783     5\n",
       "Name: Dst, Length: 8784, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3-\n",
       "1       2+\n",
       "2       2-\n",
       "3       2-\n",
       "4        2\n",
       "        ..\n",
       "2923    1+\n",
       "2924     3\n",
       "2925    3-\n",
       "2926    2+\n",
       "2927     2\n",
       "Name: Kp, Length: 2928, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "### Descriptions:\n",
    "**hn_dl**: hour normal dataloader\n",
    "\n",
    "**mn_dl**: minute normal dataloader\n",
    "\n",
    "**hr_dl**: minute normal dataloader\n",
    "\n",
    "**mr_dl**: minute normal dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_hour = 10  #hour\n",
    "sequence_length_minute = 600 #minute\n",
    "pred_length = 6 #hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normal\n",
    "hour_Normal_dataset = NormalTrainingDataset(l1_sample_hour, dst, kp, sequence_length_hour, pred_length, hour = True)\n",
    "minute_Normal_dataset = NormalTrainingDataset(l1_sample, dst, kp, sequence_length_minute, pred_length, hour = False)\n",
    "##Refined(new method)\n",
    "hour_Refined_dataset = RefinedTrainingDataset(l1_sample_hour, l2_sample_hour, dst,kp,sequence_length_hour, pred_length, hour = True)\n",
    "minute_Refined_dataset = RefinedTrainingDataset(l1_sample, l2_sample, dst,kp,sequence_length_minute, pred_length, hour = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(hour_Normal_dataset))\n",
    "\n",
    "train_hn_ds, test_hn_ds = random_split(hour_Normal_dataset , [len(hour_Normal_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hn_dl = DataLoader(train_hn_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hn_dl = DeviceDataLoader(train_hn_dl, device)\n",
    "test_hn_dl = DataLoader(test_hn_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hn_dl = DeviceDataLoader(test_hn_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(minute_Normal_dataset))\n",
    "\n",
    "train_mn_ds, test_mn_ds = random_split(minute_Normal_dataset , [len(minute_Normal_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_mn_dl = DataLoader(train_mn_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_mn_dl = DeviceDataLoader(train_mn_dl, device)\n",
    "test_mn_dl = DataLoader(test_mn_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_mn_dl = DeviceDataLoader(test_mn_dl, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(hour_Refined_dataset))\n",
    "\n",
    "train_hr_ds, test_hr_ds = random_split(hour_Refined_dataset , [len(hour_Refined_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hr_dl = DataLoader(train_hr_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hr_dl = DeviceDataLoader(train_hr_dl, device)\n",
    "test_hr_dl = DataLoader(test_hr_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hr_dl = DeviceDataLoader(test_hr_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(minute_Refined_dataset))\n",
    "\n",
    "train_mr_ds, test_mr_ds = random_split(minute_Refined_dataset , [len(minute_Refined_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_mr_dl = DataLoader(train_mr_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_mr_dl = DeviceDataLoader(train_mr_dl, device)\n",
    "test_mr_dl = DataLoader(test_mr_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_mr_dl = DeviceDataLoader(test_mr_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined models with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Convolutional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "cnn_encoder_min = Simple1DCNN(architecture, sequence_length_minute, hidden_size)\n",
    "cnn_encoder_hour = Simple1DCNN(architecture, sequence_length_hour, hidden_size)\n",
    "#fc layer\n",
    "cnn_fc_dst_min = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_min = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "cnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_min = to_device(RefinedArchitecture(cnn_encoder_min, cnn_fc_dst_min, cnn_fc_kp_min), device)\n",
    "RefinedCNN_hour = to_device(RefinedArchitecture(cnn_encoder_hour, cnn_fc_dst_hour, cnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 161, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedCNN_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedCNN_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1345\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1346\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1372\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1373\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"C:\\Users\\jorge\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 161, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "source": [
    "RefinedCNN_min_history += RefinedCNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_hour_history += RefinedCNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute based models\n",
    "deep_lstm_encoder_min_forward = DeepLSTM(hidden_size, input_size, batch_size, architecture)\n",
    "deep_lstm_encoder_min_backward = DeepLSTM(hidden_size, input_size, batch_size, architecture)\n",
    "bidirectional_deeplstm_encoder_min = BidirectionalRNNWithAttention(deep_lstm_encoder_min_forward, deep_lstm_encoder_min_backward)\n",
    "##Bidirectional hour based models\n",
    "deep_lstm_encoder_hour_forward = DeepLSTM(hidden_size, input_size, batch_size, architecture)\n",
    "deep_lstm_encoder_hour_backward = DeepLSTM(hidden_size, input_size, batch_size, architecture)\n",
    "bidirectional_deeplstm_encoder_hour = BidirectionalRNNWithAttention(deep_lstm_encoder_hour_forward, deep_lstm_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture) #the multiplying factor because concatenating hidden_states on bidirectional arch\n",
    "deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_min = to_device(RefinedArchitecture(bidirectional_deeplstm_encoder_min, deep_lstm_fc_dst_min, deep_lstm_fc_kp_min), device)\n",
    "RefinedLSTM_hour = to_device(RefinedArchitecture(bidirectional_deeplstm_encoder_hour, deep_lstm_fc_dst_hour, deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (600) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedLSTM_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedLSTM_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:225\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:117\u001b[0m, in \u001b[0;36mRefinedArchitecture.training_step\u001b[1;34m(self, batch, weigths)\u001b[0m\n\u001b[0;32m    115\u001b[0m l1_sample, l2_sample, dst, kp \u001b[39m=\u001b[39m batch\n\u001b[0;32m    116\u001b[0m \u001b[39m#encoder loss\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m h_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(l1_sample)\n\u001b[0;32m    118\u001b[0m h_t_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(l2_sample)\n\u001b[0;32m    119\u001b[0m encoder_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(h_t, h_t_hat)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:168\u001b[0m, in \u001b[0;36mBidirectionalRNNWithAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Forward pass through the first RNN\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     hidden1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn1(x)\n\u001b[0;32m    170\u001b[0m     \u001b[39m# Reverse the input sequence for the second RNN\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     x_backward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflip(x, [\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:90\u001b[0m, in \u001b[0;36mDeepLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 90\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma_F \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mF_h(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mH) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mF_x(x)\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mF \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma_F)\n\u001b[0;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma_I \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI_h(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI_x(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (600) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "RefinedLSTM_min_history += RefinedLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_hour_history += RefinedLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute based models\n",
    "deep_gru_encoder_min_forward= DeepGRU(hidden_size, input_size, batch_size, architecture)\n",
    "deep_gru_encoder_min_backward= DeepGRU(hidden_size, input_size, batch_size, architecture)\n",
    "bidirectional_deepgru_encoder_min = BidirectionalRNNWithAttention(deep_gru_encoder_min_forward, deep_gru_encoder_min_backward)\n",
    "##Bidirectional hour based models\n",
    "deep_gru_encoder_hour_forward = DeepGRU(hidden_size, input_size, batch_size, architecture)\n",
    "deep_gru_encoder_hour_backward = DeepGRU(hidden_size, input_size, batch_size, architecture)\n",
    "bidirectional_deepgru_encoder_hour = BidirectionalRNNWithAttention(deep_gru_encoder_hour_forward, deep_gru_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min = to_device(RefinedArchitecture(bidirectional_deepgru_encoder_min, deep_gru_fc_dst_min, deep_gru_fc_kp_min), device)\n",
    "RefinedGRU_hour = to_device(RefinedArchitecture(bidirectional_deepgru_encoder_hour, deep_gru_fc_dst_hour, deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min_history += RefinedGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_hour_history += RefinedGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep Vanilla RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute encoders\n",
    "deep_rnn_encoder_min_forward = DeepVanillaRNN(hidden_size, input_size, batch_size, architecture)\n",
    "deep_rnn_encoder_min_backward = DeepVanillaRNN(hidden_size, input_size, batch_size, architecture)\n",
    "bidirectional_deeprnn_encoder_min = BidirectionalRNNWithAttention(deep_rnn_encoder_min_forward,deep_rnn_encoder_min_backward)\n",
    "##Bidirectional hour encoders\n",
    "deep_rnn_encoder_hour_forward = DeepVanillaRNN(hidden_size, input_size, batch_size, architecture)\n",
    "deep_rnn_encoder_hour_backward = DeepVanillaRNN(hidden_size, input_size, batch_size, architecture)\n",
    "bidirectional_deeprnn_encoder_hour = BidirectionalRNNWithAttention(deep_rnn_encoder_hour_forward,deep_rnn_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min = to_device(RefinedArchitecture(bidirectional_deeprnn_encoder_min, deep_rnn_fc_dst_min, deep_rnn_fc_kp_min), device)\n",
    "RefinedVanillaRNN_hour = to_device(RefinedArchitecture(bidirectional_deeprnn_encoder_hour, deep_rnn_fc_dst_hour, deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min_history += RefinedVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_hour_history += RefinedVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional non deep architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_lstm_forward_min = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_min = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_min = BidirectionalRNNWithAttention(non_deep_lstm_forward_min, non_deep_lstm_backward_min)\n",
    "\n",
    "non_deep_lstm_forward_hour = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_hour = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_hour = BidirectionalRNNWithAttention(non_deep_lstm_forward_hour, non_deep_lstm_backward_hour)\n",
    "#fc layer\n",
    "non_deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "non_deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min = to_device(RefinedArchitecture(bidirectional_lstm_encoder_min, non_deep_lstm_fc_dst_min, non_deep_lstm_fc_kp_min), device)\n",
    "RefinedNonDeepLSTM_hour = to_device(RefinedArchitecture(bidirectional_lstm_encoder_hour, non_deep_lstm_fc_dst_hour, non_deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min_history += RefinedNonDeepLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_hour_history += RefinedNonDeepLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_gru_forward_min = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_min = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_min = BidirectionalRNNWithAttention(non_deep_gru_forward_min, non_deep_gru_backward_min)\n",
    "\n",
    "non_deep_gru_forward_hour = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_hour = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_hour = BidirectionalRNNWithAttention(non_deep_gru_forward_hour, non_deep_gru_backward_hour)\n",
    "#fc layer\n",
    "non_deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "non_deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min = to_device(RefinedArchitecture(bidirectional_gru_encoder_min, non_deep_gru_fc_dst_min, non_deep_gru_fc_kp_min), device)\n",
    "RefinedNonDeepGRU_hour = to_device(RefinedArchitecture(bidirectional_gru_encoder_hour, non_deep_gru_fc_dst_hour, non_deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min_history += RefinedNonDeepGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_hour_history += RefinedNonDeepGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_rnn_forward_min = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_min = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_min = BidirectionalRNNWithAttention(non_deep_rnn_forward_min, non_deep_rnn_backward_min)\n",
    "\n",
    "non_deep_rnn_forward_hour = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_hour = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_hour = BidirectionalRNNWithAttention(non_deep_rnn_forward_hour, non_deep_rnn_backward_hour)\n",
    "#fc layer\n",
    "non_deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "non_deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min = to_device(RefinedArchitecture(bidirectional_rnn_encoder_min, non_deep_rnn_fc_dst_min, non_deep_rnn_fc_kp_min), device)\n",
    "RefinedNonDeepVanillaRNN_hour = to_device(RefinedArchitecture(bidirectional_rnn_encoder_hour, non_deep_rnn_fc_dst_hour, non_deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history += RefinedNonDeepVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_hour_history += RefinedNonDeepVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal models with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Convolutional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (16,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "cnn_encoder_min = Simple1DCNN(architecture, input_size, hidden_size)\n",
    "cnn_encoder_hour = Simple1DCNN(architecture, input_size, hidden_size)\n",
    "#fc layer\n",
    "cnn_fc_dst_min = DeepNeuralNetwork(hidden_size, 1, *architecture)\n",
    "cnn_fc_kp_min = DeepNeuralNetwork(hidden_size, 29, *architecture)\n",
    "\n",
    "cnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, 1, *architecture)\n",
    "cnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, 29, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min = to_device(NormalArchitecture(cnn_encoder_min, cnn_fc_dst_min, cnn_fc_kp_min), device)\n",
    "NormalCNN_hour = to_device(NormalArchitecture(cnn_encoder_hour, cnn_fc_dst_hour, cnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min_history += NormalCNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_hour_history += NormalCNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_lstm_encoder_min = DeepLSTM(hidden_size, input_size, batch_size, architecture)\n",
    "deep_lstm_encoder_hour = DeepLSTM(hidden_size, input_size, batch_size, architecture)\n",
    "#fc layer\n",
    "deep_lstm_fc_dst_min = DeepNeuralNetwork(hidden_size, 1, *architecture)\n",
    "deep_lstm_fc_kp_min = DeepNeuralNetwork(hidden_size, 29, *architecture)\n",
    "\n",
    "deep_lstm_fc_dst_hour = DeepNeuralNetwork(hidden_size, 1, *architecture)\n",
    "deep_lstm_fc_kp_hour = DeepNeuralNetwork(hidden_size, 29, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min = to_device(NormalArchitecture(deep_lstm_encoder_min, deep_lstm_fc_dst_min, deep_lstm_fc_kp_min), device)\n",
    "NormalLSTM_hour = to_device(NormalArchitecture(deep_lstm_encoder_hour, deep_lstm_fc_dst_hour, deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min_history += NormalLSTM_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_hour_history += NormalLSTM_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_gru_encoder_min = DeepGRU(hidden_size, input_size, batch_size, architecture)\n",
    "deep_gru_encoder_hour = DeepGRU(hidden_size, input_size, batch_size, architecture)\n",
    "#fc layer\n",
    "deep_gru_fc_dst_min = DeepNeuralNetwork(hidden_size, 1, *architecture)\n",
    "deep_gru_fc_kp_min = DeepNeuralNetwork(hidden_size, 29, *architecture)\n",
    "\n",
    "deep_gru_fc_dst_hour = DeepNeuralNetwork(hidden_size, 1, *architecture)\n",
    "deep_gru_fc_kp_hour = DeepNeuralNetwork(hidden_size, 29, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min = to_device(NormalArchitecture(deep_gru_encoder_min, deep_gru_fc_dst_min, deep_gru_fc_kp_min), device)\n",
    "NormalGRU_hour = to_device(NormalArchitecture(deep_gru_encoder_hour, deep_gru_fc_dst_hour, deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min_history += NormalGRU_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_hour_history += NormalGRU_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep Vanilla RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_rnn_encoder_min = DeepVanillaRNN(hidden_size, input_size, batch_size, architecture)\n",
    "deep_rnn_encoder_hour = DeepVanillaRNN(hidden_size, input_size, batch_size, architecture)\n",
    "#fc layer\n",
    "deep_rnn_fc_dst_min = DeepNeuralNetwork(hidden_size, 1, *architecture)\n",
    "deep_rnn_fc_kp_min = DeepNeuralNetwork(hidden_size, 29, *architecture)\n",
    "\n",
    "deep_rnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, 1, *architecture)\n",
    "deep_rnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, 29, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min = to_device(RefinedArchitecture(deep_rnn_encoder_min, deep_rnn_fc_dst_min, deep_rnn_fc_kp_min), device)\n",
    "NormalVanillaRNN_hour = to_device(RefinedArchitecture(deep_rnn_encoder_hour, deep_rnn_fc_dst_hour, deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min_history += NormalVanillaRNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_hour_history += NormalVanillaRNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non deep bidirectional architectures with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_lstm_forward_min = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_min = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_min = BidirectionalRNNWithAttention(non_deep_lstm_forward_min, non_deep_lstm_backward_min)\n",
    "\n",
    "non_deep_lstm_forward_hour = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_hour = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_hour = BidirectionalRNNWithAttention(non_deep_lstm_forward_hour, non_deep_lstm_backward_hour)\n",
    "#fc layer\n",
    "non_deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "non_deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min = to_device(NormalArchitecture(bidirectional_lstm_encoder_min, non_deep_lstm_fc_dst_min, non_deep_lstm_fc_kp_min), device)\n",
    "NormalNonDeepLSTM_hour = to_device(NormalArchitecture(bidirectional_lstm_encoder_hour, non_deep_lstm_fc_dst_hour, non_deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min_history += NormalNonDeepLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_hour_history += NormalNonDeepLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_gru_forward_min = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_min = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_min = BidirectionalRNNWithAttention(non_deep_gru_forward_min, non_deep_gru_backward_min)\n",
    "\n",
    "non_deep_gru_forward_hour = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_hour = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_hour = BidirectionalRNNWithAttention(non_deep_gru_forward_hour, non_deep_gru_backward_hour)\n",
    "#fc layer\n",
    "non_deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "non_deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min = to_device(NormalArchitecture(bidirectional_gru_encoder_min, non_deep_gru_fc_dst_min, non_deep_gru_fc_kp_min), device)\n",
    "NormalNonDeepGRU_hour = to_device(NormalArchitecture(bidirectional_gru_encoder_hour, non_deep_gru_fc_dst_hour, non_deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min_history += NormalNonDeepGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_hour_history += NormalNonDeepGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_rnn_forward_min = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_min = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_min = BidirectionalRNNWithAttention(non_deep_rnn_forward_min, non_deep_rnn_backward_min)\n",
    "\n",
    "non_deep_rnn_forward_hour = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_hour = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_hour = BidirectionalRNNWithAttention(non_deep_rnn_forward_hour, non_deep_rnn_backward_hour)\n",
    "#fc layer\n",
    "non_deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "\n",
    "non_deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_min = to_device(NormalArchitecture(bidirectional_rnn_encoder_min, non_deep_rnn_fc_dst_min, non_deep_rnn_fc_kp_min), device)\n",
    "NormalNonDeepVanillaRNN_hour = to_device(NormalArchitecture(bidirectional_rnn_encoder_hour, non_deep_rnn_fc_dst_hour, non_deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history += NormalNonDeepVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_hour_history += NormalNonDeepVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
