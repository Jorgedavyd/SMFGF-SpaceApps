{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocessing import *\n",
    "from data.data_utils import *\n",
    "from models.macro_architectures import *\n",
    "from models.micro_architectures import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format: YYYYMMDD\n",
    "start_time = '20201231'\n",
    "end_time = '20230803'\n",
    "scrap_date = interval_time(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(set([day[:6] for day in scrap_date]))\n",
    "import_Dst(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\data\\preprocessing.py:158: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  mg1 = pd.concat(mg1_list)\n"
     ]
    }
   ],
   "source": [
    "l1_sample, l2_sample, dst, kp = automated_preprocessing(scrap_date, sep = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 (raw) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:00:00</th>\n",
       "      <td>-459.95712</td>\n",
       "      <td>20.771427</td>\n",
       "      <td>-37.828570</td>\n",
       "      <td>-459.95712</td>\n",
       "      <td>29.357143</td>\n",
       "      <td>-31.628570</td>\n",
       "      <td>462.02856</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>154177.420</td>\n",
       "      <td>3.103543</td>\n",
       "      <td>-1.372186</td>\n",
       "      <td>-1.481739</td>\n",
       "      <td>-2.347711</td>\n",
       "      <td>-49.236874</td>\n",
       "      <td>212.29163</td>\n",
       "      <td>-1.372186</td>\n",
       "      <td>-0.863934</td>\n",
       "      <td>-2.638353</td>\n",
       "      <td>-58.362057</td>\n",
       "      <td>212.29163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:01:00</th>\n",
       "      <td>-458.98570</td>\n",
       "      <td>18.614286</td>\n",
       "      <td>-40.314290</td>\n",
       "      <td>-458.98570</td>\n",
       "      <td>27.914286</td>\n",
       "      <td>-34.542860</td>\n",
       "      <td>461.18573</td>\n",
       "      <td>5.697143</td>\n",
       "      <td>143959.140</td>\n",
       "      <td>3.121529</td>\n",
       "      <td>-1.600045</td>\n",
       "      <td>-1.255240</td>\n",
       "      <td>-2.361683</td>\n",
       "      <td>-49.195217</td>\n",
       "      <td>201.94005</td>\n",
       "      <td>-1.600045</td>\n",
       "      <td>-0.641299</td>\n",
       "      <td>-2.596520</td>\n",
       "      <td>-56.349064</td>\n",
       "      <td>201.94005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:02:00</th>\n",
       "      <td>-460.80002</td>\n",
       "      <td>19.028570</td>\n",
       "      <td>-37.328570</td>\n",
       "      <td>-460.80002</td>\n",
       "      <td>27.571428</td>\n",
       "      <td>-31.542858</td>\n",
       "      <td>462.82858</td>\n",
       "      <td>5.862857</td>\n",
       "      <td>153136.140</td>\n",
       "      <td>3.229239</td>\n",
       "      <td>-1.357512</td>\n",
       "      <td>-2.009158</td>\n",
       "      <td>-1.942433</td>\n",
       "      <td>-37.763630</td>\n",
       "      <td>224.33852</td>\n",
       "      <td>-1.357512</td>\n",
       "      <td>-1.475083</td>\n",
       "      <td>-2.373543</td>\n",
       "      <td>-47.985750</td>\n",
       "      <td>224.33852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:03:00</th>\n",
       "      <td>-458.98750</td>\n",
       "      <td>21.837500</td>\n",
       "      <td>-39.425000</td>\n",
       "      <td>-458.98750</td>\n",
       "      <td>30.775002</td>\n",
       "      <td>-32.900000</td>\n",
       "      <td>461.37500</td>\n",
       "      <td>5.867500</td>\n",
       "      <td>146527.750</td>\n",
       "      <td>2.966850</td>\n",
       "      <td>-1.500373</td>\n",
       "      <td>-1.187357</td>\n",
       "      <td>-1.967772</td>\n",
       "      <td>-42.944990</td>\n",
       "      <td>200.96104</td>\n",
       "      <td>-1.500373</td>\n",
       "      <td>-0.672283</td>\n",
       "      <td>-2.197755</td>\n",
       "      <td>-48.643024</td>\n",
       "      <td>200.96104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:04:00</th>\n",
       "      <td>-460.91428</td>\n",
       "      <td>21.199999</td>\n",
       "      <td>-39.257140</td>\n",
       "      <td>-460.91428</td>\n",
       "      <td>30.085714</td>\n",
       "      <td>-32.928570</td>\n",
       "      <td>463.17142</td>\n",
       "      <td>5.845714</td>\n",
       "      <td>141359.140</td>\n",
       "      <td>2.932062</td>\n",
       "      <td>-1.586736</td>\n",
       "      <td>-1.057594</td>\n",
       "      <td>-2.214242</td>\n",
       "      <td>-49.151546</td>\n",
       "      <td>197.24292</td>\n",
       "      <td>-1.586736</td>\n",
       "      <td>-0.486791</td>\n",
       "      <td>-2.405081</td>\n",
       "      <td>-55.295593</td>\n",
       "      <td>197.24292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:55:00</th>\n",
       "      <td>-458.07272</td>\n",
       "      <td>8.363636</td>\n",
       "      <td>-20.463636</td>\n",
       "      <td>-458.07272</td>\n",
       "      <td>5.927273</td>\n",
       "      <td>-21.281816</td>\n",
       "      <td>459.57272</td>\n",
       "      <td>0.124545</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>9.148619</td>\n",
       "      <td>-7.701201</td>\n",
       "      <td>4.927823</td>\n",
       "      <td>0.234573</td>\n",
       "      <td>1.467366</td>\n",
       "      <td>147.38512</td>\n",
       "      <td>-7.701201</td>\n",
       "      <td>4.921561</td>\n",
       "      <td>-0.341616</td>\n",
       "      <td>-2.142453</td>\n",
       "      <td>147.41812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:56:00</th>\n",
       "      <td>-457.90000</td>\n",
       "      <td>31.890000</td>\n",
       "      <td>-21.760000</td>\n",
       "      <td>-457.90000</td>\n",
       "      <td>29.130000</td>\n",
       "      <td>-25.340000</td>\n",
       "      <td>462.02002</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>4756.600</td>\n",
       "      <td>9.117077</td>\n",
       "      <td>-7.746156</td>\n",
       "      <td>4.771574</td>\n",
       "      <td>0.456540</td>\n",
       "      <td>2.871917</td>\n",
       "      <td>148.36537</td>\n",
       "      <td>-7.746156</td>\n",
       "      <td>4.792239</td>\n",
       "      <td>-0.103969</td>\n",
       "      <td>-0.652903</td>\n",
       "      <td>148.25417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:57:00</th>\n",
       "      <td>-460.56366</td>\n",
       "      <td>1.745455</td>\n",
       "      <td>-13.645455</td>\n",
       "      <td>-460.56366</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-13.754546</td>\n",
       "      <td>460.77274</td>\n",
       "      <td>0.833636</td>\n",
       "      <td>14152.454</td>\n",
       "      <td>9.129887</td>\n",
       "      <td>-7.796285</td>\n",
       "      <td>4.708487</td>\n",
       "      <td>0.402483</td>\n",
       "      <td>2.526587</td>\n",
       "      <td>148.86864</td>\n",
       "      <td>-7.796285</td>\n",
       "      <td>4.723234</td>\n",
       "      <td>-0.151295</td>\n",
       "      <td>-0.951697</td>\n",
       "      <td>148.78772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:58:00</th>\n",
       "      <td>-463.80002</td>\n",
       "      <td>-14.516666</td>\n",
       "      <td>-4.116667</td>\n",
       "      <td>-463.80002</td>\n",
       "      <td>-14.891667</td>\n",
       "      <td>-2.391667</td>\n",
       "      <td>465.94998</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>9470.083</td>\n",
       "      <td>9.107132</td>\n",
       "      <td>-7.686605</td>\n",
       "      <td>4.833078</td>\n",
       "      <td>0.528950</td>\n",
       "      <td>3.330908</td>\n",
       "      <td>147.84564</td>\n",
       "      <td>-7.686605</td>\n",
       "      <td>4.861768</td>\n",
       "      <td>-0.041320</td>\n",
       "      <td>-0.259435</td>\n",
       "      <td>147.69276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:59:00</th>\n",
       "      <td>-439.42502</td>\n",
       "      <td>1.658333</td>\n",
       "      <td>-13.025001</td>\n",
       "      <td>-439.42502</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-13.125000</td>\n",
       "      <td>439.63333</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>8913.667</td>\n",
       "      <td>9.114652</td>\n",
       "      <td>-7.897603</td>\n",
       "      <td>4.496427</td>\n",
       "      <td>0.588675</td>\n",
       "      <td>3.703073</td>\n",
       "      <td>150.34690</td>\n",
       "      <td>-7.897603</td>\n",
       "      <td>4.534444</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>0.353977</td>\n",
       "      <td>150.13960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1362240 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2020-12-31 00:00:00     -459.95712      20.771427     -37.828570   \n",
       "2020-12-31 00:01:00     -458.98570      18.614286     -40.314290   \n",
       "2020-12-31 00:02:00     -460.80002      19.028570     -37.328570   \n",
       "2020-12-31 00:03:00     -458.98750      21.837500     -39.425000   \n",
       "2020-12-31 00:04:00     -460.91428      21.199999     -39.257140   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 23:55:00     -458.07272       8.363636     -20.463636   \n",
       "2023-08-03 23:56:00     -457.90000      31.890000     -21.760000   \n",
       "2023-08-03 23:57:00     -460.56366       1.745455     -13.645455   \n",
       "2023-08-03 23:58:00     -463.80002     -14.516666      -4.116667   \n",
       "2023-08-03 23:59:00     -439.42502       1.658333     -13.025001   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2020-12-31 00:00:00     -459.95712      29.357143     -31.628570   \n",
       "2020-12-31 00:01:00     -458.98570      27.914286     -34.542860   \n",
       "2020-12-31 00:02:00     -460.80002      27.571428     -31.542858   \n",
       "2020-12-31 00:03:00     -458.98750      30.775002     -32.900000   \n",
       "2020-12-31 00:04:00     -460.91428      30.085714     -32.928570   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 23:55:00     -458.07272       5.927273     -21.281816   \n",
       "2023-08-03 23:56:00     -457.90000      29.130000     -25.340000   \n",
       "2023-08-03 23:57:00     -460.56366       0.136364     -13.754546   \n",
       "2023-08-03 23:58:00     -463.80002     -14.891667      -2.391667   \n",
       "2023-08-03 23:59:00     -439.42502       0.100000     -13.125000   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2020-12-31 00:00:00     462.02856        6.050000          154177.420   \n",
       "2020-12-31 00:01:00     461.18573        5.697143          143959.140   \n",
       "2020-12-31 00:02:00     462.82858        5.862857          153136.140   \n",
       "2020-12-31 00:03:00     461.37500        5.867500          146527.750   \n",
       "2020-12-31 00:04:00     463.17142        5.845714          141359.140   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-03 23:55:00     459.57272        0.124545            2000.000   \n",
       "2023-08-03 23:56:00     462.02002        0.403000            4756.600   \n",
       "2023-08-03 23:57:00     460.77274        0.833636           14152.454   \n",
       "2023-08-03 23:58:00     465.94998        0.733333            9470.083   \n",
       "2023-08-03 23:59:00     439.63333        0.785000            8913.667   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2020-12-31 00:00:00  3.103543 -1.372186 -1.481739 -2.347711 -49.236874   \n",
       "2020-12-31 00:01:00  3.121529 -1.600045 -1.255240 -2.361683 -49.195217   \n",
       "2020-12-31 00:02:00  3.229239 -1.357512 -2.009158 -1.942433 -37.763630   \n",
       "2020-12-31 00:03:00  2.966850 -1.500373 -1.187357 -1.967772 -42.944990   \n",
       "2020-12-31 00:04:00  2.932062 -1.586736 -1.057594 -2.214242 -49.151546   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-03 23:55:00  9.148619 -7.701201  4.927823  0.234573   1.467366   \n",
       "2023-08-03 23:56:00  9.117077 -7.746156  4.771574  0.456540   2.871917   \n",
       "2023-08-03 23:57:00  9.129887 -7.796285  4.708487  0.402483   2.526587   \n",
       "2023-08-03 23:58:00  9.107132 -7.686605  4.833078  0.528950   3.330908   \n",
       "2023-08-03 23:59:00  9.114652 -7.897603  4.496427  0.588675   3.703073   \n",
       "\n",
       "                       phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2020-12-31 00:00:00  212.29163 -1.372186 -0.863934 -2.638353 -58.362057   \n",
       "2020-12-31 00:01:00  201.94005 -1.600045 -0.641299 -2.596520 -56.349064   \n",
       "2020-12-31 00:02:00  224.33852 -1.357512 -1.475083 -2.373543 -47.985750   \n",
       "2020-12-31 00:03:00  200.96104 -1.500373 -0.672283 -2.197755 -48.643024   \n",
       "2020-12-31 00:04:00  197.24292 -1.586736 -0.486791 -2.405081 -55.295593   \n",
       "...                        ...       ...       ...       ...        ...   \n",
       "2023-08-03 23:55:00  147.38512 -7.701201  4.921561 -0.341616  -2.142453   \n",
       "2023-08-03 23:56:00  148.36537 -7.746156  4.792239 -0.103969  -0.652903   \n",
       "2023-08-03 23:57:00  148.86864 -7.796285  4.723234 -0.151295  -0.951697   \n",
       "2023-08-03 23:58:00  147.84564 -7.686605  4.861768 -0.041320  -0.259435   \n",
       "2023-08-03 23:59:00  150.34690 -7.897603  4.534444  0.056465   0.353977   \n",
       "\n",
       "                       phi_gsm  \n",
       "2020-12-31 00:00:00  212.29163  \n",
       "2020-12-31 00:01:00  201.94005  \n",
       "2020-12-31 00:02:00  224.33852  \n",
       "2020-12-31 00:03:00  200.96104  \n",
       "2020-12-31 00:04:00  197.24292  \n",
       "...                        ...  \n",
       "2023-08-03 23:55:00  147.41812  \n",
       "2023-08-03 23:56:00  148.25417  \n",
       "2023-08-03 23:57:00  148.78772  \n",
       "2023-08-03 23:58:00  147.69276  \n",
       "2023-08-03 23:59:00  150.13960  \n",
       "\n",
       "[1362240 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:00:00</th>\n",
       "      <td>-461.712648</td>\n",
       "      <td>23.564702</td>\n",
       "      <td>-41.086875</td>\n",
       "      <td>-461.712648</td>\n",
       "      <td>32.661459</td>\n",
       "      <td>-34.307589</td>\n",
       "      <td>464.346162</td>\n",
       "      <td>5.811333</td>\n",
       "      <td>146978.770000</td>\n",
       "      <td>3.196159</td>\n",
       "      <td>-1.654849</td>\n",
       "      <td>-1.847285</td>\n",
       "      <td>-1.694565</td>\n",
       "      <td>-33.542051</td>\n",
       "      <td>215.702141</td>\n",
       "      <td>-1.654849</td>\n",
       "      <td>-1.390457</td>\n",
       "      <td>-2.081981</td>\n",
       "      <td>-41.945192</td>\n",
       "      <td>215.702141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 01:00:00</th>\n",
       "      <td>-457.052138</td>\n",
       "      <td>17.513274</td>\n",
       "      <td>-27.782113</td>\n",
       "      <td>-457.052138</td>\n",
       "      <td>23.151429</td>\n",
       "      <td>-23.313929</td>\n",
       "      <td>458.318929</td>\n",
       "      <td>6.294155</td>\n",
       "      <td>197023.787333</td>\n",
       "      <td>2.760782</td>\n",
       "      <td>-0.405533</td>\n",
       "      <td>-2.105541</td>\n",
       "      <td>0.021299</td>\n",
       "      <td>-0.177205</td>\n",
       "      <td>258.416425</td>\n",
       "      <td>-0.405533</td>\n",
       "      <td>-2.051862</td>\n",
       "      <td>-0.433943</td>\n",
       "      <td>-11.797873</td>\n",
       "      <td>258.416425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 02:00:00</th>\n",
       "      <td>-453.349376</td>\n",
       "      <td>12.962054</td>\n",
       "      <td>-25.639137</td>\n",
       "      <td>-453.349376</td>\n",
       "      <td>17.454822</td>\n",
       "      <td>-22.815923</td>\n",
       "      <td>454.335716</td>\n",
       "      <td>6.812452</td>\n",
       "      <td>230582.338333</td>\n",
       "      <td>2.872992</td>\n",
       "      <td>0.120363</td>\n",
       "      <td>-2.265247</td>\n",
       "      <td>0.865786</td>\n",
       "      <td>20.457005</td>\n",
       "      <td>270.883119</td>\n",
       "      <td>0.120363</td>\n",
       "      <td>-2.386412</td>\n",
       "      <td>0.432359</td>\n",
       "      <td>10.488156</td>\n",
       "      <td>270.883119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 03:00:00</th>\n",
       "      <td>-457.754936</td>\n",
       "      <td>15.503958</td>\n",
       "      <td>-34.397917</td>\n",
       "      <td>-457.754936</td>\n",
       "      <td>20.284434</td>\n",
       "      <td>-31.818393</td>\n",
       "      <td>459.367022</td>\n",
       "      <td>6.874756</td>\n",
       "      <td>212633.102667</td>\n",
       "      <td>2.612051</td>\n",
       "      <td>-0.610070</td>\n",
       "      <td>-1.577324</td>\n",
       "      <td>-1.464512</td>\n",
       "      <td>-37.558328</td>\n",
       "      <td>237.178338</td>\n",
       "      <td>-0.610070</td>\n",
       "      <td>-1.357049</td>\n",
       "      <td>-1.681922</td>\n",
       "      <td>-44.019162</td>\n",
       "      <td>237.178338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 04:00:00</th>\n",
       "      <td>-441.350564</td>\n",
       "      <td>14.754673</td>\n",
       "      <td>-28.015595</td>\n",
       "      <td>-441.350564</td>\n",
       "      <td>17.365982</td>\n",
       "      <td>-26.479821</td>\n",
       "      <td>442.711253</td>\n",
       "      <td>6.524396</td>\n",
       "      <td>211812.393500</td>\n",
       "      <td>2.835215</td>\n",
       "      <td>-0.076185</td>\n",
       "      <td>-2.472715</td>\n",
       "      <td>0.753232</td>\n",
       "      <td>14.703117</td>\n",
       "      <td>268.512925</td>\n",
       "      <td>-0.076185</td>\n",
       "      <td>-2.524382</td>\n",
       "      <td>0.514577</td>\n",
       "      <td>9.325356</td>\n",
       "      <td>268.512925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 19:00:00</th>\n",
       "      <td>-336.646294</td>\n",
       "      <td>2.560524</td>\n",
       "      <td>-40.894559</td>\n",
       "      <td>-336.646294</td>\n",
       "      <td>-4.469508</td>\n",
       "      <td>-40.811081</td>\n",
       "      <td>339.976270</td>\n",
       "      <td>3.297642</td>\n",
       "      <td>10603.785207</td>\n",
       "      <td>8.881810</td>\n",
       "      <td>-8.397860</td>\n",
       "      <td>-0.315262</td>\n",
       "      <td>2.761895</td>\n",
       "      <td>18.125610</td>\n",
       "      <td>182.149904</td>\n",
       "      <td>-8.397860</td>\n",
       "      <td>0.161601</td>\n",
       "      <td>2.780559</td>\n",
       "      <td>18.254308</td>\n",
       "      <td>178.913148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 20:00:00</th>\n",
       "      <td>-332.942454</td>\n",
       "      <td>-19.543290</td>\n",
       "      <td>-8.267044</td>\n",
       "      <td>-332.942454</td>\n",
       "      <td>-20.459794</td>\n",
       "      <td>-5.348601</td>\n",
       "      <td>335.023164</td>\n",
       "      <td>1.821652</td>\n",
       "      <td>6775.375603</td>\n",
       "      <td>9.278263</td>\n",
       "      <td>-8.971080</td>\n",
       "      <td>-0.909717</td>\n",
       "      <td>1.199496</td>\n",
       "      <td>7.538724</td>\n",
       "      <td>185.612646</td>\n",
       "      <td>-8.971080</td>\n",
       "      <td>-0.730964</td>\n",
       "      <td>1.308748</td>\n",
       "      <td>8.197190</td>\n",
       "      <td>184.480378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 21:00:00</th>\n",
       "      <td>-325.770046</td>\n",
       "      <td>5.254784</td>\n",
       "      <td>-28.044986</td>\n",
       "      <td>-325.770046</td>\n",
       "      <td>1.841405</td>\n",
       "      <td>-28.512537</td>\n",
       "      <td>328.366749</td>\n",
       "      <td>2.553373</td>\n",
       "      <td>7479.847265</td>\n",
       "      <td>9.491237</td>\n",
       "      <td>-9.264703</td>\n",
       "      <td>-0.280312</td>\n",
       "      <td>1.955153</td>\n",
       "      <td>11.896596</td>\n",
       "      <td>181.740103</td>\n",
       "      <td>-9.264703</td>\n",
       "      <td>-0.044151</td>\n",
       "      <td>1.975867</td>\n",
       "      <td>12.025461</td>\n",
       "      <td>180.281581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 22:00:00</th>\n",
       "      <td>-357.435846</td>\n",
       "      <td>15.239832</td>\n",
       "      <td>-27.647399</td>\n",
       "      <td>-357.435846</td>\n",
       "      <td>12.085765</td>\n",
       "      <td>-29.165588</td>\n",
       "      <td>359.615137</td>\n",
       "      <td>3.209151</td>\n",
       "      <td>65709.495525</td>\n",
       "      <td>9.317494</td>\n",
       "      <td>-9.089208</td>\n",
       "      <td>0.564847</td>\n",
       "      <td>1.426778</td>\n",
       "      <td>8.788789</td>\n",
       "      <td>176.384023</td>\n",
       "      <td>-9.089208</td>\n",
       "      <td>0.719256</td>\n",
       "      <td>1.356400</td>\n",
       "      <td>8.346369</td>\n",
       "      <td>175.425802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:00:00</th>\n",
       "      <td>-471.629934</td>\n",
       "      <td>2.330469</td>\n",
       "      <td>-14.573993</td>\n",
       "      <td>-471.629934</td>\n",
       "      <td>0.667548</td>\n",
       "      <td>-14.742996</td>\n",
       "      <td>472.017339</td>\n",
       "      <td>3.669411</td>\n",
       "      <td>208994.500400</td>\n",
       "      <td>9.134143</td>\n",
       "      <td>-8.516804</td>\n",
       "      <td>2.958169</td>\n",
       "      <td>0.946576</td>\n",
       "      <td>5.953639</td>\n",
       "      <td>160.870878</td>\n",
       "      <td>-8.516804</td>\n",
       "      <td>3.045140</td>\n",
       "      <td>0.605140</td>\n",
       "      <td>3.804584</td>\n",
       "      <td>160.345478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22704 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2020-12-31 00:00:00    -461.712648      23.564702     -41.086875   \n",
       "2020-12-31 01:00:00    -457.052138      17.513274     -27.782113   \n",
       "2020-12-31 02:00:00    -453.349376      12.962054     -25.639137   \n",
       "2020-12-31 03:00:00    -457.754936      15.503958     -34.397917   \n",
       "2020-12-31 04:00:00    -441.350564      14.754673     -28.015595   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 19:00:00    -336.646294       2.560524     -40.894559   \n",
       "2023-08-03 20:00:00    -332.942454     -19.543290      -8.267044   \n",
       "2023-08-03 21:00:00    -325.770046       5.254784     -28.044986   \n",
       "2023-08-03 22:00:00    -357.435846      15.239832     -27.647399   \n",
       "2023-08-03 23:00:00    -471.629934       2.330469     -14.573993   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2020-12-31 00:00:00    -461.712648      32.661459     -34.307589   \n",
       "2020-12-31 01:00:00    -457.052138      23.151429     -23.313929   \n",
       "2020-12-31 02:00:00    -453.349376      17.454822     -22.815923   \n",
       "2020-12-31 03:00:00    -457.754936      20.284434     -31.818393   \n",
       "2020-12-31 04:00:00    -441.350564      17.365982     -26.479821   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 19:00:00    -336.646294      -4.469508     -40.811081   \n",
       "2023-08-03 20:00:00    -332.942454     -20.459794      -5.348601   \n",
       "2023-08-03 21:00:00    -325.770046       1.841405     -28.512537   \n",
       "2023-08-03 22:00:00    -357.435846      12.085765     -29.165588   \n",
       "2023-08-03 23:00:00    -471.629934       0.667548     -14.742996   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2020-12-31 00:00:00    464.346162        5.811333       146978.770000   \n",
       "2020-12-31 01:00:00    458.318929        6.294155       197023.787333   \n",
       "2020-12-31 02:00:00    454.335716        6.812452       230582.338333   \n",
       "2020-12-31 03:00:00    459.367022        6.874756       212633.102667   \n",
       "2020-12-31 04:00:00    442.711253        6.524396       211812.393500   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-03 19:00:00    339.976270        3.297642        10603.785207   \n",
       "2023-08-03 20:00:00    335.023164        1.821652         6775.375603   \n",
       "2023-08-03 21:00:00    328.366749        2.553373         7479.847265   \n",
       "2023-08-03 22:00:00    359.615137        3.209151        65709.495525   \n",
       "2023-08-03 23:00:00    472.017339        3.669411       208994.500400   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2020-12-31 00:00:00  3.196159 -1.654849 -1.847285 -1.694565 -33.542051   \n",
       "2020-12-31 01:00:00  2.760782 -0.405533 -2.105541  0.021299  -0.177205   \n",
       "2020-12-31 02:00:00  2.872992  0.120363 -2.265247  0.865786  20.457005   \n",
       "2020-12-31 03:00:00  2.612051 -0.610070 -1.577324 -1.464512 -37.558328   \n",
       "2020-12-31 04:00:00  2.835215 -0.076185 -2.472715  0.753232  14.703117   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-03 19:00:00  8.881810 -8.397860 -0.315262  2.761895  18.125610   \n",
       "2023-08-03 20:00:00  9.278263 -8.971080 -0.909717  1.199496   7.538724   \n",
       "2023-08-03 21:00:00  9.491237 -9.264703 -0.280312  1.955153  11.896596   \n",
       "2023-08-03 22:00:00  9.317494 -9.089208  0.564847  1.426778   8.788789   \n",
       "2023-08-03 23:00:00  9.134143 -8.516804  2.958169  0.946576   5.953639   \n",
       "\n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2020-12-31 00:00:00  215.702141 -1.654849 -1.390457 -2.081981 -41.945192   \n",
       "2020-12-31 01:00:00  258.416425 -0.405533 -2.051862 -0.433943 -11.797873   \n",
       "2020-12-31 02:00:00  270.883119  0.120363 -2.386412  0.432359  10.488156   \n",
       "2020-12-31 03:00:00  237.178338 -0.610070 -1.357049 -1.681922 -44.019162   \n",
       "2020-12-31 04:00:00  268.512925 -0.076185 -2.524382  0.514577   9.325356   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "2023-08-03 19:00:00  182.149904 -8.397860  0.161601  2.780559  18.254308   \n",
       "2023-08-03 20:00:00  185.612646 -8.971080 -0.730964  1.308748   8.197190   \n",
       "2023-08-03 21:00:00  181.740103 -9.264703 -0.044151  1.975867  12.025461   \n",
       "2023-08-03 22:00:00  176.384023 -9.089208  0.719256  1.356400   8.346369   \n",
       "2023-08-03 23:00:00  160.870878 -8.516804  3.045140  0.605140   3.804584   \n",
       "\n",
       "                        phi_gsm  \n",
       "2020-12-31 00:00:00  215.702141  \n",
       "2020-12-31 01:00:00  258.416425  \n",
       "2020-12-31 02:00:00  270.883119  \n",
       "2020-12-31 03:00:00  237.178338  \n",
       "2020-12-31 04:00:00  268.512925  \n",
       "...                         ...  \n",
       "2023-08-03 19:00:00  178.913148  \n",
       "2023-08-03 20:00:00  184.480378  \n",
       "2023-08-03 21:00:00  180.281581  \n",
       "2023-08-03 22:00:00  175.425802  \n",
       "2023-08-03 23:00:00  160.345478  \n",
       "\n",
       "[22704 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_sample_hour = l1_sample.resample('60min').mean()\n",
    "l1_sample_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 (cleaned) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:00:00</th>\n",
       "      <td>-461.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>-37.7</td>\n",
       "      <td>-461.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>-31.5</td>\n",
       "      <td>463.0</td>\n",
       "      <td>6.32</td>\n",
       "      <td>156370.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>-49.29</td>\n",
       "      <td>227.20</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-2.64</td>\n",
       "      <td>-58.42</td>\n",
       "      <td>212.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:01:00</th>\n",
       "      <td>-459.2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-39.2</td>\n",
       "      <td>-459.2</td>\n",
       "      <td>26.7</td>\n",
       "      <td>-33.7</td>\n",
       "      <td>461.2</td>\n",
       "      <td>6.03</td>\n",
       "      <td>145922.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-49.37</td>\n",
       "      <td>218.17</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>-56.53</td>\n",
       "      <td>201.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:02:00</th>\n",
       "      <td>-461.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>-39.2</td>\n",
       "      <td>-461.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>463.8</td>\n",
       "      <td>6.12</td>\n",
       "      <td>152728.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>-39.75</td>\n",
       "      <td>234.57</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>-50.62</td>\n",
       "      <td>225.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:03:00</th>\n",
       "      <td>-459.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-38.1</td>\n",
       "      <td>-459.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>-31.5</td>\n",
       "      <td>461.6</td>\n",
       "      <td>6.33</td>\n",
       "      <td>144651.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>-49.14</td>\n",
       "      <td>211.31</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-54.72</td>\n",
       "      <td>194.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:04:00</th>\n",
       "      <td>-461.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>-38.5</td>\n",
       "      <td>-461.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>-32.2</td>\n",
       "      <td>463.6</td>\n",
       "      <td>6.04</td>\n",
       "      <td>141876.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-49.18</td>\n",
       "      <td>214.07</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>-55.40</td>\n",
       "      <td>197.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:55:00</th>\n",
       "      <td>-458.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>-458.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>458.5</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>9.15</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.46</td>\n",
       "      <td>147.41</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>4.92</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>147.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:56:00</th>\n",
       "      <td>-457.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>-457.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-7.75</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.83</td>\n",
       "      <td>148.35</td>\n",
       "      <td>-7.75</td>\n",
       "      <td>4.80</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>148.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:57:00</th>\n",
       "      <td>-460.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>-460.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>460.6</td>\n",
       "      <td>0.81</td>\n",
       "      <td>12657.0</td>\n",
       "      <td>9.13</td>\n",
       "      <td>-7.81</td>\n",
       "      <td>4.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.43</td>\n",
       "      <td>149.01</td>\n",
       "      <td>-7.81</td>\n",
       "      <td>4.70</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>148.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:58:00</th>\n",
       "      <td>-463.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>-463.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-13.8</td>\n",
       "      <td>464.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>9024.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3.24</td>\n",
       "      <td>147.90</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>4.86</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>147.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:59:00</th>\n",
       "      <td>-461.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>-461.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-13.8</td>\n",
       "      <td>461.5</td>\n",
       "      <td>0.79</td>\n",
       "      <td>9548.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.59</td>\n",
       "      <td>3.73</td>\n",
       "      <td>150.31</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.37</td>\n",
       "      <td>150.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1362240 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2020-12-31 00:00:00         -461.0           20.6          -37.7   \n",
       "2020-12-31 00:01:00         -459.2           17.7          -39.2   \n",
       "2020-12-31 00:02:00         -461.8           18.1          -39.2   \n",
       "2020-12-31 00:03:00         -459.5           22.5          -38.1   \n",
       "2020-12-31 00:04:00         -461.5           21.1          -38.5   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 23:55:00         -458.3            1.8          -13.6   \n",
       "2023-08-03 23:56:00         -457.8            1.7          -13.6   \n",
       "2023-08-03 23:57:00         -460.4            1.7          -13.6   \n",
       "2023-08-03 23:58:00         -463.8            1.8          -13.7   \n",
       "2023-08-03 23:59:00         -461.3            1.7          -13.7   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2020-12-31 00:00:00         -461.0           29.2          -31.5   \n",
       "2020-12-31 00:01:00         -459.2           26.7          -33.7   \n",
       "2020-12-31 00:02:00         -461.8           27.1          -33.6   \n",
       "2020-12-31 00:03:00         -459.5           31.1          -31.5   \n",
       "2020-12-31 00:04:00         -461.5           29.9          -32.2   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 23:55:00         -458.3            0.2          -13.7   \n",
       "2023-08-03 23:56:00         -457.8            0.1          -13.7   \n",
       "2023-08-03 23:57:00         -460.4            0.1          -13.7   \n",
       "2023-08-03 23:58:00         -463.8            0.2          -13.8   \n",
       "2023-08-03 23:59:00         -461.3            0.1          -13.8   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature    bt  \\\n",
       "2020-12-31 00:00:00         463.0            6.32            156370.0  3.10   \n",
       "2020-12-31 00:01:00         461.2            6.03            145922.0  3.12   \n",
       "2020-12-31 00:02:00         463.8            6.12            152728.0  3.23   \n",
       "2020-12-31 00:03:00         461.6            6.33            144651.0  2.96   \n",
       "2020-12-31 00:04:00         463.6            6.04            141876.0  2.93   \n",
       "...                           ...             ...                 ...   ...   \n",
       "2023-08-03 23:55:00         458.5            0.12              2000.0  9.15   \n",
       "2023-08-03 23:56:00         458.0            0.37              2000.0  9.12   \n",
       "2023-08-03 23:57:00         460.6            0.81             12657.0  9.13   \n",
       "2023-08-03 23:58:00         464.0            0.72              9024.0  9.11   \n",
       "2023-08-03 23:59:00         461.5            0.79              9548.0  9.11   \n",
       "\n",
       "                     bx_gse  by_gse  bz_gse  theta_gse  phi_gse  bx_gsm  \\\n",
       "2020-12-31 00:00:00   -1.37   -1.48   -2.35     -49.29   227.20   -1.37   \n",
       "2020-12-31 00:01:00   -1.59   -1.25   -2.36     -49.37   218.17   -1.59   \n",
       "2020-12-31 00:02:00   -1.40   -1.97   -2.02     -39.75   234.57   -1.40   \n",
       "2020-12-31 00:03:00   -1.60   -0.97   -2.16     -49.14   211.31   -1.60   \n",
       "2020-12-31 00:04:00   -1.58   -1.07   -2.21     -49.18   214.07   -1.58   \n",
       "...                     ...     ...     ...        ...      ...     ...   \n",
       "2023-08-03 23:55:00   -7.70    4.92    0.23       1.46   147.41   -7.70   \n",
       "2023-08-03 23:56:00   -7.75    4.78    0.45       2.83   148.35   -7.75   \n",
       "2023-08-03 23:57:00   -7.81    4.69    0.39       2.43   149.01   -7.81   \n",
       "2023-08-03 23:58:00   -7.70    4.83    0.51       3.24   147.90   -7.70   \n",
       "2023-08-03 23:59:00   -7.90    4.50    0.59       3.73   150.31   -7.90   \n",
       "\n",
       "                     by_gsm  bz_gsm  theta_gsm  phi_gsm  \n",
       "2020-12-31 00:00:00   -0.86   -2.64     -58.42   212.19  \n",
       "2020-12-31 00:01:00   -0.64   -2.60     -56.53   201.83  \n",
       "2020-12-31 00:02:00   -1.42   -2.44     -50.62   225.38  \n",
       "2020-12-31 00:03:00   -0.42   -2.33     -54.72   194.58  \n",
       "2020-12-31 00:04:00   -0.50   -2.41     -55.40   197.52  \n",
       "...                     ...     ...        ...      ...  \n",
       "2023-08-03 23:55:00    4.92   -0.34      -2.14   147.44  \n",
       "2023-08-03 23:56:00    4.80   -0.11      -0.69   148.24  \n",
       "2023-08-03 23:57:00    4.70   -0.16      -1.03   148.94  \n",
       "2023-08-03 23:58:00    4.86   -0.05      -0.35   147.75  \n",
       "2023-08-03 23:59:00    4.54    0.06       0.37   150.10  \n",
       "\n",
       "[1362240 rows x 20 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proton_vx_gse</th>\n",
       "      <th>proton_vy_gse</th>\n",
       "      <th>proton_vz_gse</th>\n",
       "      <th>proton_vx_gsm</th>\n",
       "      <th>proton_vy_gsm</th>\n",
       "      <th>proton_vz_gsm</th>\n",
       "      <th>proton_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>proton_temperature</th>\n",
       "      <th>bt</th>\n",
       "      <th>bx_gse</th>\n",
       "      <th>by_gse</th>\n",
       "      <th>bz_gse</th>\n",
       "      <th>theta_gse</th>\n",
       "      <th>phi_gse</th>\n",
       "      <th>bx_gsm</th>\n",
       "      <th>by_gsm</th>\n",
       "      <th>bz_gsm</th>\n",
       "      <th>theta_gsm</th>\n",
       "      <th>phi_gsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:00:00</th>\n",
       "      <td>-462.145000</td>\n",
       "      <td>22.706667</td>\n",
       "      <td>-40.606667</td>\n",
       "      <td>-462.145000</td>\n",
       "      <td>31.723333</td>\n",
       "      <td>-34.036667</td>\n",
       "      <td>464.526667</td>\n",
       "      <td>6.024000</td>\n",
       "      <td>147974.900000</td>\n",
       "      <td>3.196333</td>\n",
       "      <td>-1.657667</td>\n",
       "      <td>-1.849500</td>\n",
       "      <td>-1.700000</td>\n",
       "      <td>-33.725000</td>\n",
       "      <td>225.520000</td>\n",
       "      <td>-1.657667</td>\n",
       "      <td>-1.390833</td>\n",
       "      <td>-2.088833</td>\n",
       "      <td>-42.233667</td>\n",
       "      <td>215.938167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 01:00:00</th>\n",
       "      <td>-457.590000</td>\n",
       "      <td>17.478333</td>\n",
       "      <td>-27.850000</td>\n",
       "      <td>-457.590000</td>\n",
       "      <td>23.135000</td>\n",
       "      <td>-23.376667</td>\n",
       "      <td>458.808333</td>\n",
       "      <td>6.346000</td>\n",
       "      <td>197041.233333</td>\n",
       "      <td>2.764000</td>\n",
       "      <td>-0.405833</td>\n",
       "      <td>-2.111667</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>-0.183000</td>\n",
       "      <td>261.027000</td>\n",
       "      <td>-0.405833</td>\n",
       "      <td>-2.058167</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>-11.922167</td>\n",
       "      <td>259.814167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 02:00:00</th>\n",
       "      <td>-453.828333</td>\n",
       "      <td>13.290000</td>\n",
       "      <td>-25.736667</td>\n",
       "      <td>-453.828333</td>\n",
       "      <td>17.811667</td>\n",
       "      <td>-22.845000</td>\n",
       "      <td>454.766667</td>\n",
       "      <td>6.834000</td>\n",
       "      <td>233766.700000</td>\n",
       "      <td>2.872333</td>\n",
       "      <td>0.114333</td>\n",
       "      <td>-2.272667</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>20.795500</td>\n",
       "      <td>269.079667</td>\n",
       "      <td>0.114333</td>\n",
       "      <td>-2.395333</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>10.766000</td>\n",
       "      <td>271.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 03:00:00</th>\n",
       "      <td>-458.330000</td>\n",
       "      <td>15.601667</td>\n",
       "      <td>-34.370000</td>\n",
       "      <td>-458.330000</td>\n",
       "      <td>20.390000</td>\n",
       "      <td>-31.761667</td>\n",
       "      <td>459.913333</td>\n",
       "      <td>6.911000</td>\n",
       "      <td>213284.966667</td>\n",
       "      <td>2.611667</td>\n",
       "      <td>-0.609000</td>\n",
       "      <td>-1.573833</td>\n",
       "      <td>-1.474833</td>\n",
       "      <td>-38.339667</td>\n",
       "      <td>252.523333</td>\n",
       "      <td>-0.609000</td>\n",
       "      <td>-1.351500</td>\n",
       "      <td>-1.691833</td>\n",
       "      <td>-44.940667</td>\n",
       "      <td>239.751500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 04:00:00</th>\n",
       "      <td>-441.168333</td>\n",
       "      <td>14.753333</td>\n",
       "      <td>-27.376667</td>\n",
       "      <td>-441.168333</td>\n",
       "      <td>17.310000</td>\n",
       "      <td>-25.830000</td>\n",
       "      <td>442.366667</td>\n",
       "      <td>6.511333</td>\n",
       "      <td>211253.916667</td>\n",
       "      <td>2.838000</td>\n",
       "      <td>-0.072167</td>\n",
       "      <td>-2.477667</td>\n",
       "      <td>0.751000</td>\n",
       "      <td>14.600500</td>\n",
       "      <td>268.564667</td>\n",
       "      <td>-0.072167</td>\n",
       "      <td>-2.529833</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>9.170167</td>\n",
       "      <td>268.554667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 19:00:00</th>\n",
       "      <td>-336.648333</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>-41.610000</td>\n",
       "      <td>-336.648333</td>\n",
       "      <td>-2.953333</td>\n",
       "      <td>-41.776667</td>\n",
       "      <td>339.760000</td>\n",
       "      <td>3.311167</td>\n",
       "      <td>10654.400000</td>\n",
       "      <td>8.882167</td>\n",
       "      <td>-8.398167</td>\n",
       "      <td>-0.316333</td>\n",
       "      <td>2.763167</td>\n",
       "      <td>18.135000</td>\n",
       "      <td>182.157833</td>\n",
       "      <td>-8.398167</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>2.781667</td>\n",
       "      <td>18.264833</td>\n",
       "      <td>178.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 20:00:00</th>\n",
       "      <td>-331.586667</td>\n",
       "      <td>-20.721667</td>\n",
       "      <td>-8.181667</td>\n",
       "      <td>-331.586667</td>\n",
       "      <td>-21.613333</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>333.200000</td>\n",
       "      <td>1.798500</td>\n",
       "      <td>6084.233333</td>\n",
       "      <td>9.278833</td>\n",
       "      <td>-8.971667</td>\n",
       "      <td>-0.909500</td>\n",
       "      <td>1.197667</td>\n",
       "      <td>7.533833</td>\n",
       "      <td>185.614333</td>\n",
       "      <td>-8.971667</td>\n",
       "      <td>-0.730333</td>\n",
       "      <td>1.307333</td>\n",
       "      <td>8.195333</td>\n",
       "      <td>184.482500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 21:00:00</th>\n",
       "      <td>-325.763333</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>-28.608333</td>\n",
       "      <td>-325.763333</td>\n",
       "      <td>3.903333</td>\n",
       "      <td>-29.333333</td>\n",
       "      <td>327.763333</td>\n",
       "      <td>2.565167</td>\n",
       "      <td>7487.116667</td>\n",
       "      <td>9.491667</td>\n",
       "      <td>-9.265500</td>\n",
       "      <td>-0.279167</td>\n",
       "      <td>1.955333</td>\n",
       "      <td>11.903167</td>\n",
       "      <td>181.734500</td>\n",
       "      <td>-9.265500</td>\n",
       "      <td>-0.042833</td>\n",
       "      <td>1.977167</td>\n",
       "      <td>12.030000</td>\n",
       "      <td>180.273833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 22:00:00</th>\n",
       "      <td>-357.271667</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>-27.151667</td>\n",
       "      <td>-357.271667</td>\n",
       "      <td>12.301667</td>\n",
       "      <td>-28.686667</td>\n",
       "      <td>359.123333</td>\n",
       "      <td>3.185167</td>\n",
       "      <td>63931.000000</td>\n",
       "      <td>9.318167</td>\n",
       "      <td>-9.089667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.428333</td>\n",
       "      <td>8.796833</td>\n",
       "      <td>176.370833</td>\n",
       "      <td>-9.089667</td>\n",
       "      <td>0.721667</td>\n",
       "      <td>1.356833</td>\n",
       "      <td>8.353333</td>\n",
       "      <td>175.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-03 23:00:00</th>\n",
       "      <td>-474.641667</td>\n",
       "      <td>1.821667</td>\n",
       "      <td>-14.065000</td>\n",
       "      <td>-474.641667</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>-14.176667</td>\n",
       "      <td>474.856667</td>\n",
       "      <td>3.598000</td>\n",
       "      <td>205072.333333</td>\n",
       "      <td>9.134333</td>\n",
       "      <td>-8.518167</td>\n",
       "      <td>2.959333</td>\n",
       "      <td>0.948667</td>\n",
       "      <td>5.970333</td>\n",
       "      <td>160.867000</td>\n",
       "      <td>-8.518167</td>\n",
       "      <td>3.046167</td>\n",
       "      <td>0.607667</td>\n",
       "      <td>3.821167</td>\n",
       "      <td>160.341500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22704 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     proton_vx_gse  proton_vy_gse  proton_vz_gse  \\\n",
       "2020-12-31 00:00:00    -462.145000      22.706667     -40.606667   \n",
       "2020-12-31 01:00:00    -457.590000      17.478333     -27.850000   \n",
       "2020-12-31 02:00:00    -453.828333      13.290000     -25.736667   \n",
       "2020-12-31 03:00:00    -458.330000      15.601667     -34.370000   \n",
       "2020-12-31 04:00:00    -441.168333      14.753333     -27.376667   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 19:00:00    -336.648333       4.220000     -41.610000   \n",
       "2023-08-03 20:00:00    -331.586667     -20.721667      -8.181667   \n",
       "2023-08-03 21:00:00    -325.763333       7.400000     -28.608333   \n",
       "2023-08-03 22:00:00    -357.271667      15.400000     -27.151667   \n",
       "2023-08-03 23:00:00    -474.641667       1.821667     -14.065000   \n",
       "\n",
       "                     proton_vx_gsm  proton_vy_gsm  proton_vz_gsm  \\\n",
       "2020-12-31 00:00:00    -462.145000      31.723333     -34.036667   \n",
       "2020-12-31 01:00:00    -457.590000      23.135000     -23.376667   \n",
       "2020-12-31 02:00:00    -453.828333      17.811667     -22.845000   \n",
       "2020-12-31 03:00:00    -458.330000      20.390000     -31.761667   \n",
       "2020-12-31 04:00:00    -441.168333      17.310000     -25.830000   \n",
       "...                            ...            ...            ...   \n",
       "2023-08-03 19:00:00    -336.648333      -2.953333     -41.776667   \n",
       "2023-08-03 20:00:00    -331.586667     -21.613333      -5.080000   \n",
       "2023-08-03 21:00:00    -325.763333       3.903333     -29.333333   \n",
       "2023-08-03 22:00:00    -357.271667      12.301667     -28.686667   \n",
       "2023-08-03 23:00:00    -474.641667       0.216667     -14.176667   \n",
       "\n",
       "                     proton_speed  proton_density  proton_temperature  \\\n",
       "2020-12-31 00:00:00    464.526667        6.024000       147974.900000   \n",
       "2020-12-31 01:00:00    458.808333        6.346000       197041.233333   \n",
       "2020-12-31 02:00:00    454.766667        6.834000       233766.700000   \n",
       "2020-12-31 03:00:00    459.913333        6.911000       213284.966667   \n",
       "2020-12-31 04:00:00    442.366667        6.511333       211253.916667   \n",
       "...                           ...             ...                 ...   \n",
       "2023-08-03 19:00:00    339.760000        3.311167        10654.400000   \n",
       "2023-08-03 20:00:00    333.200000        1.798500         6084.233333   \n",
       "2023-08-03 21:00:00    327.763333        2.565167         7487.116667   \n",
       "2023-08-03 22:00:00    359.123333        3.185167        63931.000000   \n",
       "2023-08-03 23:00:00    474.856667        3.598000       205072.333333   \n",
       "\n",
       "                           bt    bx_gse    by_gse    bz_gse  theta_gse  \\\n",
       "2020-12-31 00:00:00  3.196333 -1.657667 -1.849500 -1.700000 -33.725000   \n",
       "2020-12-31 01:00:00  2.764000 -0.405833 -2.111667  0.024667  -0.183000   \n",
       "2020-12-31 02:00:00  2.872333  0.114333 -2.272667  0.877333  20.795500   \n",
       "2020-12-31 03:00:00  2.611667 -0.609000 -1.573833 -1.474833 -38.339667   \n",
       "2020-12-31 04:00:00  2.838000 -0.072167 -2.477667  0.751000  14.600500   \n",
       "...                       ...       ...       ...       ...        ...   \n",
       "2023-08-03 19:00:00  8.882167 -8.398167 -0.316333  2.763167  18.135000   \n",
       "2023-08-03 20:00:00  9.278833 -8.971667 -0.909500  1.197667   7.533833   \n",
       "2023-08-03 21:00:00  9.491667 -9.265500 -0.279167  1.955333  11.903167   \n",
       "2023-08-03 22:00:00  9.318167 -9.089667  0.566667  1.428333   8.796833   \n",
       "2023-08-03 23:00:00  9.134333 -8.518167  2.959333  0.948667   5.970333   \n",
       "\n",
       "                        phi_gse    bx_gsm    by_gsm    bz_gsm  theta_gsm  \\\n",
       "2020-12-31 00:00:00  225.520000 -1.657667 -1.390833 -2.088833 -42.233667   \n",
       "2020-12-31 01:00:00  261.027000 -0.405833 -2.058167 -0.433333 -11.922167   \n",
       "2020-12-31 02:00:00  269.079667  0.114333 -2.395333  0.441500  10.766000   \n",
       "2020-12-31 03:00:00  252.523333 -0.609000 -1.351500 -1.691833 -44.940667   \n",
       "2020-12-31 04:00:00  268.564667 -0.072167 -2.529833  0.510500   9.170167   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "2023-08-03 19:00:00  182.157833 -8.398167  0.161500  2.781667  18.264833   \n",
       "2023-08-03 20:00:00  185.614333 -8.971667 -0.730333  1.307333   8.195333   \n",
       "2023-08-03 21:00:00  181.734500 -9.265500 -0.042833  1.977167  12.030000   \n",
       "2023-08-03 22:00:00  176.370833 -9.089667  0.721667  1.356833   8.353333   \n",
       "2023-08-03 23:00:00  160.867000 -8.518167  3.046167  0.607667   3.821167   \n",
       "\n",
       "                        phi_gsm  \n",
       "2020-12-31 00:00:00  215.938167  \n",
       "2020-12-31 01:00:00  259.814167  \n",
       "2020-12-31 02:00:00  271.607000  \n",
       "2020-12-31 03:00:00  239.751500  \n",
       "2020-12-31 04:00:00  268.554667  \n",
       "...                         ...  \n",
       "2023-08-03 19:00:00  178.913500  \n",
       "2023-08-03 20:00:00  184.482500  \n",
       "2023-08-03 21:00:00  180.273833  \n",
       "2023-08-03 22:00:00  175.412000  \n",
       "2023-08-03 23:00:00  160.341500  \n",
       "\n",
       "[22704 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_sample_hour = l2_sample.resample('60min').mean()\n",
    "l2_sample_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dst data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -3\n",
       "1       -1\n",
       "2       -1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "22699    1\n",
       "22700   -2\n",
       "22701   -3\n",
       "22702   -6\n",
       "22703   -6\n",
       "Name: Dst, Length: 22704, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1+\n",
       "1        1\n",
       "2       0+\n",
       "3        1\n",
       "4       1-\n",
       "        ..\n",
       "7563     2\n",
       "7564    2-\n",
       "7565    1+\n",
       "7566    0+\n",
       "7567    0+\n",
       "Name: Kp, Length: 7568, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "### Descriptions:\n",
    "**hn_dl**: hour normal dataloader\n",
    "\n",
    "**mn_dl**: minute normal dataloader\n",
    "\n",
    "**hr_dl**: minute normal dataloader\n",
    "\n",
    "**mr_dl**: minute normal dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_hour = 10  #hour\n",
    "sequence_length_minute = 600 #minute\n",
    "pred_length = 9 #hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normal\n",
    "hour_Normal_dataset = NormalTrainingDataset(l1_sample_hour, dst, kp, sequence_length_hour, pred_length, hour = True)\n",
    "minute_Normal_dataset = NormalTrainingDataset(l1_sample, dst, kp, sequence_length_minute, pred_length, hour = False)\n",
    "##Refined(new method)\n",
    "hour_Refined_dataset = RefinedTrainingDataset(l1_sample_hour, l2_sample_hour, dst,kp,sequence_length_hour, pred_length, hour = True)\n",
    "minute_Refined_dataset = RefinedTrainingDataset(l1_sample, l2_sample, dst,kp,sequence_length_minute, pred_length, hour = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(hour_Normal_dataset))\n",
    "\n",
    "train_hn_ds, test_hn_ds = random_split(hour_Normal_dataset , [len(hour_Normal_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hn_dl = DataLoader(train_hn_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hn_dl = DeviceDataLoader(train_hn_dl, device)\n",
    "test_hn_dl = DataLoader(test_hn_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hn_dl = DeviceDataLoader(test_hn_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(minute_Normal_dataset))\n",
    "\n",
    "train_mn_ds, test_mn_ds = random_split(minute_Normal_dataset , [len(minute_Normal_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_mn_dl = DataLoader(train_mn_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_mn_dl = DeviceDataLoader(train_mn_dl, device)\n",
    "test_mn_dl = DataLoader(test_mn_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_mn_dl = DeviceDataLoader(test_mn_dl, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(hour_Refined_dataset))\n",
    "\n",
    "train_hr_ds, test_hr_ds = random_split(hour_Refined_dataset , [len(hour_Refined_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_hr_dl = DataLoader(train_hr_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hr_dl = DeviceDataLoader(train_hr_dl, device)\n",
    "test_hr_dl = DataLoader(test_hr_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hr_dl = DeviceDataLoader(test_hr_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(minute_Refined_dataset))\n",
    "\n",
    "train_mr_ds, test_mr_ds = random_split(minute_Refined_dataset , [len(minute_Refined_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_mr_dl = DataLoader(train_mr_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_mr_dl = DeviceDataLoader(train_mr_dl, device)\n",
    "test_mr_dl = DataLoader(test_mr_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_mr_dl = DeviceDataLoader(test_mr_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined models with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Convolutional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = (10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "cnn_encoder_min = Simple1DCNN(architecture, sequence_length_minute, hidden_size)\n",
    "cnn_encoder_hour = Simple1DCNN(architecture, sequence_length_hour, hidden_size)\n",
    "#fc layer\n",
    "cnn_fc_dst_min = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_min = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "cnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_min = to_device(RefinedArchitecture(cnn_encoder_min, cnn_fc_dst_min, cnn_fc_kp_min), device)\n",
    "RefinedCNN_hour = to_device(RefinedArchitecture(cnn_encoder_hour, cnn_fc_dst_hour, cnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 20\n",
    "max_lr = 5e-4\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 1e-1\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#Z1026sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedCNN_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedCNN_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:222\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    220\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    221\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    223\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    225\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\utils.py:66\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     67\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedCNN_min_history += RefinedCNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedCNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 1.7226\n",
      "\ttrain_main_loss: 1.7226\n",
      "\ttrain_output_loss: 0.0001\n",
      "\ttrain_encoder_loss: 0.0010\n",
      "\tval_overall_loss: 1.7158\n",
      "\tval_main_loss: 1.7158\n",
      "\tval_output_loss: 0.0002\n",
      "\tval_encoder_loss: 0.0015\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_overall_loss: 1.6239\n",
      "\ttrain_main_loss: 1.6239\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0016\n",
      "\tval_overall_loss: 1.6137\n",
      "\tval_main_loss: 1.6137\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "RefinedCNN_hour_history += RefinedCNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute based models\n",
    "deep_lstm_encoder_min_forward = DeepLSTM(hidden_size, input_size, architecture, attention = True).to(device)\n",
    "deep_lstm_encoder_min_backward = DeepLSTM(hidden_size, input_size, architecture, attention = True).to(device)\n",
    "bidirectional_deeplstm_encoder_min = BidirectionalRNN(deep_lstm_encoder_min_forward, deep_lstm_encoder_min_backward).to(device)\n",
    "##Bidirectional hour based models\n",
    "deep_lstm_encoder_hour_forward = DeepLSTM(hidden_size, input_size, architecture, attention = True).to(device)\n",
    "deep_lstm_encoder_hour_backward = DeepLSTM(hidden_size, input_size, architecture, attention = True).to(device)\n",
    "bidirectional_deeplstm_encoder_hour = BidirectionalRNN(deep_lstm_encoder_hour_forward, deep_lstm_encoder_hour_backward).to(device)\n",
    "#fc layer\n",
    "deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture).to(device) #the multiplying factor because concatenating hidden_states on bidirectional arch\n",
    "deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture).to(device)\n",
    "\n",
    "deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture).to(device)\n",
    "deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_min = to_device(RefinedArchitecture(bidirectional_deeplstm_encoder_min, deep_lstm_fc_dst_min, deep_lstm_fc_kp_min), device)\n",
    "RefinedLSTM_hour = to_device(RefinedArchitecture(bidirectional_deeplstm_encoder_hour, deep_lstm_fc_dst_hour, deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 10\n",
    "max_lr = 1e-2\n",
    "weigth_decay = 1e-3\n",
    "grad_clip = 1e-1\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 47\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#Z1132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedLSTM_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedLSTM_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:224\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    223\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m    225\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:116\u001b[0m, in \u001b[0;36mRefinedArchitecture.training_step\u001b[1;34m(self, batch, weigths)\u001b[0m\n\u001b[0;32m    114\u001b[0m l1_sample, l2_sample, dst, kp \u001b[39m=\u001b[39m batch\n\u001b[0;32m    115\u001b[0m \u001b[39m#encoder loss\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m h_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(l1_sample)\n\u001b[0;32m    117\u001b[0m h_t_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(l2_sample)\n\u001b[0;32m    118\u001b[0m encoder_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(h_t, h_t_hat)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:274\u001b[0m, in \u001b[0;36mBidirectionalRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    273\u001b[0m     \u001b[39m# Forward pass through the first RNN\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     hidden1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn1(x)\n\u001b[0;32m    275\u001b[0m     \u001b[39m# Reverse the input sequence for the second RNN\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     x_backward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflip(x, [\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:132\u001b[0m, in \u001b[0;36mDeepLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    130\u001b[0m xt \u001b[39m=\u001b[39m x[:, t, :]\n\u001b[0;32m    131\u001b[0m \u001b[39m#forward\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m a_F \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mF_h(hn) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mF_x(xt)\n\u001b[0;32m    133\u001b[0m F \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(a_F) \u001b[39m#forget gate\u001b[39;00m\n\u001b[0;32m    134\u001b[0m a_I \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI_h(hn) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mI_x(xt)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:29\u001b[0m, in \u001b[0;36mDeepNeuralNetwork.forward\u001b[1;34m(self, xb)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xb):\n\u001b[0;32m     28\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_structure(xb)\n\u001b[1;32m---> 29\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_layer(out)\n\u001b[0;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "RefinedLSTM_min_history += RefinedLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3423\n",
      "\ttrain_main_loss: 1.3423\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0000\n",
      "\tval_overall_loss: 0.9733\n",
      "\tval_main_loss: 0.9733\n",
      "\tval_output_loss: 0.0002\n",
      "\tval_encoder_loss: 0.0000\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 0.9529\n",
      "\ttrain_main_loss: 0.9529\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.8512\n",
      "\tval_main_loss: 0.8512\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.8301\n",
      "\ttrain_main_loss: 0.8301\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7807\n",
      "\tval_main_loss: 0.7807\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_overall_loss: 0.7586\n",
      "\ttrain_main_loss: 0.7586\n",
      "\ttrain_output_loss: 0.0007\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7456\n",
      "\tval_main_loss: 0.7456\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_overall_loss: 0.7159\n",
      "\ttrain_main_loss: 0.7159\n",
      "\ttrain_output_loss: 0.0006\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7054\n",
      "\tval_main_loss: 0.7054\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [5]\n",
      "\tlast_lr: 0.00013\n",
      "\ttrain_overall_loss: 0.6785\n",
      "\ttrain_main_loss: 0.6785\n",
      "\ttrain_output_loss: 0.0007\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.6804\n",
      "\tval_main_loss: 0.6804\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [6]\n",
      "\tlast_lr: 0.00016\n",
      "\ttrain_overall_loss: 0.6493\n",
      "\ttrain_main_loss: 0.6493\n",
      "\ttrain_output_loss: 0.0006\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.6488\n",
      "\tval_main_loss: 0.6488\n",
      "\tval_output_loss: 0.0007\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [7]\n",
      "\tlast_lr: 0.00020\n",
      "\ttrain_overall_loss: 0.6195\n",
      "\ttrain_main_loss: 0.6195\n",
      "\ttrain_output_loss: 0.0007\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.6199\n",
      "\tval_main_loss: 0.6199\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [8]\n",
      "\tlast_lr: 0.00024\n",
      "\ttrain_overall_loss: 0.6007\n",
      "\ttrain_main_loss: 0.6007\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.6158\n",
      "\tval_main_loss: 0.6158\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [9]\n",
      "\tlast_lr: 0.00028\n",
      "\ttrain_overall_loss: 0.5827\n",
      "\ttrain_main_loss: 0.5826\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5948\n",
      "\tval_main_loss: 0.5948\n",
      "\tval_output_loss: 0.0007\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [10]\n",
      "\tlast_lr: 0.00032\n",
      "\ttrain_overall_loss: 0.5660\n",
      "\ttrain_main_loss: 0.5660\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5816\n",
      "\tval_main_loss: 0.5816\n",
      "\tval_output_loss: 0.0007\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [11]\n",
      "\tlast_lr: 0.00037\n",
      "\ttrain_overall_loss: 0.5504\n",
      "\ttrain_main_loss: 0.5504\n",
      "\ttrain_output_loss: 0.0009\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5542\n",
      "\tval_main_loss: 0.5542\n",
      "\tval_output_loss: 0.0008\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [12]\n",
      "\tlast_lr: 0.00042\n",
      "\ttrain_overall_loss: 0.5379\n",
      "\ttrain_main_loss: 0.5379\n",
      "\ttrain_output_loss: 0.0010\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5567\n",
      "\tval_main_loss: 0.5567\n",
      "\tval_output_loss: 0.0008\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [13]\n",
      "\tlast_lr: 0.00047\n",
      "\ttrain_overall_loss: 0.5284\n",
      "\ttrain_main_loss: 0.5284\n",
      "\ttrain_output_loss: 0.0012\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5555\n",
      "\tval_main_loss: 0.5555\n",
      "\tval_output_loss: 0.0009\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [14]\n",
      "\tlast_lr: 0.00052\n",
      "\ttrain_overall_loss: 0.5186\n",
      "\ttrain_main_loss: 0.5186\n",
      "\ttrain_output_loss: 0.0013\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5363\n",
      "\tval_main_loss: 0.5363\n",
      "\tval_output_loss: 0.0010\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [15]\n",
      "\tlast_lr: 0.00057\n",
      "\ttrain_overall_loss: 0.5140\n",
      "\ttrain_main_loss: 0.5140\n",
      "\ttrain_output_loss: 0.0014\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.5398\n",
      "\tval_main_loss: 0.5398\n",
      "\tval_output_loss: 0.0011\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 53\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedLSTM_hour_history += RefinedLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute based models\n",
    "deep_gru_encoder_min_forward= DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min_backward= DeepGRU(hidden_size, input_size, architecture)\n",
    "bidirectional_deepgru_encoder_min = BidirectionalRNN(deep_gru_encoder_min_forward, deep_gru_encoder_min_backward)\n",
    "##Bidirectional hour based models\n",
    "deep_gru_encoder_hour_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "bidirectional_deepgru_encoder_hour = BidirectionalRNN(deep_gru_encoder_hour_forward, deep_gru_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min = to_device(RefinedArchitecture(bidirectional_deepgru_encoder_min, deep_gru_fc_dst_min, deep_gru_fc_kp_min), device)\n",
    "RefinedGRU_hour = to_device(RefinedArchitecture(bidirectional_deepgru_encoder_hour, deep_gru_fc_dst_hour, deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-2\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 5e-1\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_min_history += RefinedGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RefinedGRU_hour_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 58\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Innotronics/Desktop/SMFGF-SpaceApps/main.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedGRU_hour\u001b[39m.\u001b[39mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RefinedGRU_hour_history' is not defined"
     ]
    }
   ],
   "source": [
    "RefinedGRU_hour_history += RefinedGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep Vanilla RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "##Bidirectional minute encoders\n",
    "deep_rnn_encoder_min_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "bidirectional_deeprnn_encoder_min = BidirectionalRNN(deep_rnn_encoder_min_forward,deep_rnn_encoder_min_backward)\n",
    "##Bidirectional hour encoders\n",
    "deep_rnn_encoder_hour_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "bidirectional_deeprnn_encoder_hour = BidirectionalRNN(deep_rnn_encoder_hour_forward,deep_rnn_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min = to_device(RefinedArchitecture(bidirectional_deeprnn_encoder_min, deep_rnn_fc_dst_min, deep_rnn_fc_kp_min), device)\n",
    "RefinedVanillaRNN_hour = to_device(RefinedArchitecture(bidirectional_deeprnn_encoder_hour, deep_rnn_fc_dst_hour, deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_min_history += RefinedVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3494\n",
      "\ttrain_main_loss: 1.3494\n",
      "\ttrain_output_loss: 0.0001\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.2106\n",
      "\tval_main_loss: 1.2106\n",
      "\tval_output_loss: 0.0002\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 1.0410\n",
      "\ttrain_main_loss: 1.0410\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.0773\n",
      "\tval_main_loss: 1.0773\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 71\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:248\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    245\u001b[0m     sched\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    247\u001b[0m \u001b[39m# Fase de validación\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(val_loader)\n\u001b[0;32m    249\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mtrain_overall_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(train_losses)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem() \n\u001b[0;32m    250\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mtrain_main_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(main_losses)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem() \n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:201\u001b[0m, in \u001b[0;36mRefinedArchitecture.evaluate\u001b[1;34m(self, val_loader)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, val_loader):\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 201\u001b[0m     outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m    202\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:201\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, val_loader):\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 201\u001b[0m     outputs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m    202\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedVanillaRNN_hour_history += RefinedVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional non deep architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_lstm_forward_min = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_min = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_min = BidirectionalRNNWithAttention(non_deep_lstm_forward_min, non_deep_lstm_backward_min)\n",
    "\n",
    "non_deep_lstm_forward_hour = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_hour = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_hour = BidirectionalRNNWithAttention(non_deep_lstm_forward_hour, non_deep_lstm_backward_hour)\n",
    "#fc layer\n",
    "non_deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min = to_device(RefinedArchitecture(bidirectional_lstm_encoder_min, non_deep_lstm_fc_dst_min, non_deep_lstm_fc_kp_min), device)\n",
    "RefinedNonDeepLSTM_hour = to_device(RefinedArchitecture(bidirectional_lstm_encoder_hour, non_deep_lstm_fc_dst_hour, non_deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_min_history += RefinedNonDeepLSTM_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3338\n",
      "\ttrain_main_loss: 1.3338\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.1319\n",
      "\tval_main_loss: 1.1319\n",
      "\tval_output_loss: 0.0004\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 0.9605\n",
      "\ttrain_main_loss: 0.9605\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.9760\n",
      "\tval_main_loss: 0.9760\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.8491\n",
      "\ttrain_main_loss: 0.8491\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.8663\n",
      "\tval_main_loss: 0.8663\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_overall_loss: 0.7699\n",
      "\ttrain_main_loss: 0.7698\n",
      "\ttrain_output_loss: 0.0008\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.7792\n",
      "\tval_main_loss: 0.7792\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_overall_loss: 0.7140\n",
      "\ttrain_main_loss: 0.7140\n",
      "\ttrain_output_loss: 0.0012\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 0.7207\n",
      "\tval_main_loss: 0.7206\n",
      "\tval_output_loss: 0.0008\n",
      "\tval_encoder_loss: 0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 79\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y314sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepLSTM_hour_history += RefinedNonDeepLSTM_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_gru_forward_min = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_min = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_min = BidirectionalRNNWithAttention(non_deep_gru_forward_min, non_deep_gru_backward_min)\n",
    "\n",
    "non_deep_gru_forward_hour = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_hour = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_hour = BidirectionalRNNWithAttention(non_deep_gru_forward_hour, non_deep_gru_backward_hour)\n",
    "#fc layer\n",
    "non_deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min = to_device(RefinedArchitecture(bidirectional_gru_encoder_min, non_deep_gru_fc_dst_min, non_deep_gru_fc_kp_min), device)\n",
    "RefinedNonDeepGRU_hour = to_device(RefinedArchitecture(bidirectional_gru_encoder_hour, non_deep_gru_fc_dst_hour, non_deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_min_history += RefinedNonDeepGRU_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.3516\n",
      "\ttrain_main_loss: 1.3516\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.1860\n",
      "\tval_main_loss: 1.1860\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 0.9823\n",
      "\ttrain_main_loss: 0.9823\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 1.0192\n",
      "\tval_main_loss: 1.0192\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.8637\n",
      "\ttrain_main_loss: 0.8637\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.9084\n",
      "\tval_main_loss: 0.9084\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [3]\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_overall_loss: 0.7905\n",
      "\ttrain_main_loss: 0.7905\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.8263\n",
      "\tval_main_loss: 0.8263\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n",
      "Epoch [4]\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_overall_loss: 0.7357\n",
      "\ttrain_main_loss: 0.7357\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0001\n",
      "\tval_overall_loss: 0.7559\n",
      "\tval_main_loss: 0.7559\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 86\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepGRU_hour_history += RefinedNonDeepGRU_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_rnn_forward_min = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_min = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_min = BidirectionalRNNWithAttention(non_deep_rnn_forward_min, non_deep_rnn_backward_min)\n",
    "\n",
    "non_deep_rnn_forward_hour = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_hour = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_hour = BidirectionalRNNWithAttention(non_deep_rnn_forward_hour, non_deep_rnn_backward_hour)\n",
    "#fc layer\n",
    "non_deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min = to_device(RefinedArchitecture(bidirectional_rnn_encoder_min, non_deep_rnn_fc_dst_min, non_deep_rnn_fc_kp_min), device)\n",
    "RefinedNonDeepVanillaRNN_hour = to_device(RefinedArchitecture(bidirectional_rnn_encoder_hour, non_deep_rnn_fc_dst_hour, non_deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history += RefinedNonDeepVanillaRNN_min.fit(epochs, max_lr, train_mr_dl, test_mr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_overall_loss: 1.2946\n",
      "\ttrain_main_loss: 1.2946\n",
      "\ttrain_output_loss: 0.0002\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.1871\n",
      "\tval_main_loss: 1.1871\n",
      "\tval_output_loss: 0.0003\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [1]\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_overall_loss: 1.0257\n",
      "\ttrain_main_loss: 1.0257\n",
      "\ttrain_output_loss: 0.0003\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.0831\n",
      "\tval_main_loss: 1.0830\n",
      "\tval_output_loss: 0.0005\n",
      "\tval_encoder_loss: 0.0002\n",
      "Epoch [2]\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_overall_loss: 0.9554\n",
      "\ttrain_main_loss: 0.9554\n",
      "\ttrain_output_loss: 0.0005\n",
      "\ttrain_encoder_loss: 0.0002\n",
      "\tval_overall_loss: 1.0201\n",
      "\tval_main_loss: 1.0201\n",
      "\tval_output_loss: 0.0006\n",
      "\tval_encoder_loss: 0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 93\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y161sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RefinedNonDeepVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m RefinedNonDeepVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:223\u001b[0m, in \u001b[0;36mRefinedArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m    221\u001b[0m main_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     loss, encoder_loss, output_loss, main_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m    226\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RefinedNonDeepVanillaRNN_hour_history += RefinedNonDeepVanillaRNN_hour.fit(epochs, max_lr, train_hr_dl, test_hr_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal models with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Convolutional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "cnn_encoder_min = Simple1DCNN(architecture, input_size, hidden_size)\n",
    "cnn_encoder_hour = Simple1DCNN(architecture, input_size, hidden_size)\n",
    "#fc layer\n",
    "cnn_fc_dst_min = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_min = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "cnn_fc_dst_hour = DeepNeuralNetwork(hidden_size, pred_length, *architecture)\n",
    "cnn_fc_kp_hour = DeepNeuralNetwork(hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min = to_device(NormalArchitecture(cnn_encoder_min, cnn_fc_dst_min, cnn_fc_kp_min), device)\n",
    "NormalCNN_hour = to_device(NormalArchitecture(cnn_encoder_hour, cnn_fc_dst_hour, cnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_min_history += NormalCNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalCNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [10, 20, 3], expected input[32, 10, 20] to have 20 channels, but got 10 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 103\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y204sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalCNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalCNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:72\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:23\u001b[0m, in \u001b[0;36mNormalArchitecture.training_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     21\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m#initialize loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m feature, dst, kp \u001b[39m=\u001b[39m batch \u001b[39m#decompose batch\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m dst_out, kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(feature)        \n\u001b[0;32m     24\u001b[0m \u001b[39m#dst index cost-1st head\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(dst_out, dst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:16\u001b[0m, in \u001b[0;36mNormalArchitecture.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     17\u001b[0m     dst_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_dst(out)\n\u001b[0;32m     18\u001b[0m     kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_kp(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:55\u001b[0m, in \u001b[0;36mSimple1DCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 55\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1d(x)\n\u001b[0;32m     56\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     57\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 20, 3], expected input[32, 10, 20] to have 20 channels, but got 10 channels instead"
     ]
    }
   ],
   "source": [
    "NormalCNN_hour_history += NormalCNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_lstm_encoder_min_forward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_min_backward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_min = BidirectionalRNNWithAttention(deep_lstm_encoder_min_forward,deep_lstm_encoder_min_backward)\n",
    "\n",
    "deep_lstm_encoder_hour_forward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_hour_backward = DeepLSTM(hidden_size, input_size, architecture)\n",
    "deep_lstm_encoder_hour = BidirectionalRNNWithAttention(deep_lstm_encoder_hour_forward,deep_lstm_encoder_hour_backward)\n",
    "\n",
    "#fc layer\n",
    "deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min = to_device(NormalArchitecture(deep_lstm_encoder_min, deep_lstm_fc_dst_min, deep_lstm_fc_kp_min), device)\n",
    "NormalLSTM_hour = to_device(NormalArchitecture(deep_lstm_encoder_hour, deep_lstm_fc_dst_hour, deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_min_history += NormalLSTM_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 1.3096\n",
      "\tval_loss: 0.9849\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 0.9692\n",
      "\tval_loss: 0.8660\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_loss: 0.8529\n",
      "\tval_loss: 0.7863\n",
      "Epoch [3]:\n",
      "\tlast_lr: 0.00008\n",
      "\ttrain_loss: 0.7619\n",
      "\tval_loss: 0.7326\n",
      "Epoch [4]:\n",
      "\tlast_lr: 0.00010\n",
      "\ttrain_loss: 0.7028\n",
      "\tval_loss: 0.6870\n",
      "Epoch [5]:\n",
      "\tlast_lr: 0.00013\n",
      "\ttrain_loss: 0.6619\n",
      "\tval_loss: 0.6704\n",
      "Epoch [6]:\n",
      "\tlast_lr: 0.00016\n",
      "\ttrain_loss: 0.6341\n",
      "\tval_loss: 0.6449\n",
      "Epoch [7]:\n",
      "\tlast_lr: 0.00020\n",
      "\ttrain_loss: 0.6039\n",
      "\tval_loss: 0.6322\n",
      "Epoch [8]:\n",
      "\tlast_lr: 0.00024\n",
      "\ttrain_loss: 0.5860\n",
      "\tval_loss: 0.6194\n",
      "Epoch [9]:\n",
      "\tlast_lr: 0.00028\n",
      "\ttrain_loss: 0.5695\n",
      "\tval_loss: 0.5994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 112\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y216sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:76\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     74\u001b[0m train_losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m     75\u001b[0m \u001b[39m#Calcular las derivadas parciales\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     78\u001b[0m \u001b[39m# Gradient clipping, para que no ocurra el exploding gradient\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m grad_clip:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalLSTM_hour_history += NormalLSTM_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep GRU encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "\n",
    "deep_gru_encoder_min_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_min = BidirectionalRNNWithAttention(deep_gru_encoder_min_forward,deep_gru_encoder_min_backward)\n",
    "\n",
    "deep_gru_encoder_hour_forward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour_backward = DeepGRU(hidden_size, input_size, architecture)\n",
    "deep_gru_encoder_hour = BidirectionalRNNWithAttention(deep_gru_encoder_hour_forward,deep_gru_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size,hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min = to_device(NormalArchitecture(deep_gru_encoder_min, deep_gru_fc_dst_min, deep_gru_fc_kp_min), device)\n",
    "NormalGRU_hour = to_device(NormalArchitecture(deep_gru_encoder_hour, deep_gru_fc_dst_hour, deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 119\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y226sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalGRU_min_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalGRU_min\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:72\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:23\u001b[0m, in \u001b[0;36mNormalArchitecture.training_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     21\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m#initialize loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m feature, dst, kp \u001b[39m=\u001b[39m batch \u001b[39m#decompose batch\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m dst_out, kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(feature)        \n\u001b[0;32m     24\u001b[0m \u001b[39m#dst index cost-1st head\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(dst_out, dst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:16\u001b[0m, in \u001b[0;36mNormalArchitecture.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     17\u001b[0m     dst_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_dst(out)\n\u001b[0;32m     18\u001b[0m     kp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_kp(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:241\u001b[0m, in \u001b[0;36mBidirectionalRNNWithAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    240\u001b[0m     \u001b[39m# Forward pass through the first RNN\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     hidden1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn1(x)\n\u001b[0;32m    242\u001b[0m     \u001b[39m# Reverse the input sequence for the second RNN\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     x_backward \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflip(x, [\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:153\u001b[0m, in \u001b[0;36mDeepGRU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    151\u001b[0m xt \u001b[39m=\u001b[39m x[:, t, :]\n\u001b[0;32m    152\u001b[0m Z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ_h(hn)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ_x(xt))\n\u001b[1;32m--> 153\u001b[0m R \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mR_h(hn)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mR_x(xt))\n\u001b[0;32m    154\u001b[0m H_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_hat_h(hn\u001b[39m*\u001b[39mR)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_hat_x(xt))\n\u001b[0;32m    155\u001b[0m hn \u001b[39m=\u001b[39m hn\u001b[39m*\u001b[39mZ \u001b[39m+\u001b[39m (torch\u001b[39m.\u001b[39mones_like(Z)\u001b[39m-\u001b[39mZ)\u001b[39m*\u001b[39mH_hat\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\micro_architectures.py:42\u001b[0m, in \u001b[0;36mDeepNeuralNetwork.forward\u001b[1;34m(self, xb)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xb):\n\u001b[0;32m     41\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_structure(xb)\n\u001b[1;32m---> 42\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_layer(out)\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "NormalGRU_min_history += NormalGRU_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 0.9408\n",
      "\tval_loss: 0.8459\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 121\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y231sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:83\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     80\u001b[0m     nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_value_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters(), grad_clip)\n\u001b[0;32m     82\u001b[0m \u001b[39m#Efectuar el descensod e gradiente y borrar el historial\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     84\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     86\u001b[0m \u001b[39m# Guardar el learning rate utilizado en el cycle.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:269\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[0;32m    268\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m    270\u001b[0m     \u001b[39m# call optimizer step pre hooks\u001b[39;00m\n\u001b[0;32m    271\u001b[0m     \u001b[39mfor\u001b[39;00m pre_hook \u001b[39min\u001b[39;00m chain(_global_optimizer_pre_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_pre_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    272\u001b[0m         result \u001b[39m=\u001b[39m pre_hook(\u001b[39mself\u001b[39m, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n\u001b[0;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs \u001b[39mor\u001b[39;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalGRU_hour_history += NormalGRU_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Deep Vanilla RNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Architecture\n",
    "hidden_size = 10\n",
    "input_size = 20\n",
    "##nn architecture\n",
    "architecture = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoders\n",
    "deep_rnn_encoder_min_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_min = BidirectionalRNNWithAttention(deep_rnn_encoder_min_forward, deep_rnn_encoder_min_backward)\n",
    "\n",
    "deep_rnn_encoder_hour_forward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour_backward = DeepVanillaRNN(hidden_size, input_size, architecture)\n",
    "deep_rnn_encoder_hour = BidirectionalRNNWithAttention(deep_rnn_encoder_hour_forward,deep_rnn_encoder_hour_backward)\n",
    "#fc layer\n",
    "deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min = to_device(NormalArchitecture(deep_rnn_encoder_min, deep_rnn_fc_dst_min, deep_rnn_fc_kp_min), device)\n",
    "NormalVanillaRNN_hour = to_device(NormalArchitecture(deep_rnn_encoder_hour, deep_rnn_fc_dst_hour, deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 1e-3\n",
    "weigth_decay = 1e-4\n",
    "grad_clip = 1e-2\n",
    "#opt_func = Adam\n",
    "opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_min_history += NormalVanillaRNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00004\n",
      "\ttrain_loss: 1.3040\n",
      "\tval_loss: 1.0009\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 1.0306\n",
      "\tval_loss: 0.9201\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00006\n",
      "\ttrain_loss: 0.9532\n",
      "\tval_loss: 0.8801\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 130\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y243sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalVanillaRNN_hour_history += NormalVanillaRNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non deep bidirectional architectures with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_lstm_forward_min = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_min = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_min = BidirectionalRNNWithAttention(non_deep_lstm_forward_min, non_deep_lstm_backward_min)\n",
    "\n",
    "non_deep_lstm_forward_hour = LSTM(input_size, hidden_size)\n",
    "non_deep_lstm_backward_hour = LSTM(input_size, hidden_size)\n",
    "bidirectional_lstm_encoder_hour = BidirectionalRNNWithAttention(non_deep_lstm_forward_hour, non_deep_lstm_backward_hour)\n",
    "#fc layer\n",
    "non_deep_lstm_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_lstm_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_lstm_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min = to_device(NormalArchitecture(bidirectional_lstm_encoder_min, non_deep_lstm_fc_dst_min, non_deep_lstm_fc_kp_min), device)\n",
    "NormalNonDeepLSTM_hour = to_device(NormalArchitecture(bidirectional_lstm_encoder_hour, non_deep_lstm_fc_dst_hour, non_deep_lstm_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_min_history += NormalNonDeepLSTM_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepLSTM_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.0350\n",
      "\tval_loss: 2.0597\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_loss: 2.0237\n",
      "\tval_loss: 2.0414\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00026\n",
      "\ttrain_loss: 1.9437\n",
      "\tval_loss: 1.7768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 138\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y254sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepLSTM_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepLSTM_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepLSTM_hour_history += NormalNonDeepLSTM_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_gru_forward_min = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_min = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_min = BidirectionalRNNWithAttention(non_deep_gru_forward_min, non_deep_gru_backward_min)\n",
    "\n",
    "non_deep_gru_forward_hour = GRU(input_size, hidden_size)\n",
    "non_deep_gru_backward_hour = GRU(input_size, hidden_size)\n",
    "bidirectional_gru_encoder_hour = BidirectionalRNNWithAttention(non_deep_gru_forward_hour, non_deep_gru_backward_hour)\n",
    "#fc layer\n",
    "non_deep_gru_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_gru_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_gru_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min = to_device(NormalArchitecture(bidirectional_gru_encoder_min, non_deep_gru_fc_dst_min, non_deep_gru_fc_kp_min), device)\n",
    "NormalNonDeepGRU_hour = to_device(NormalArchitecture(bidirectional_gru_encoder_hour, non_deep_gru_fc_dst_hour, non_deep_gru_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_min_history += NormalNonDeepGRU_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepGRU_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.1161\n",
      "\tval_loss: 2.1215\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00014\n",
      "\ttrain_loss: 2.0831\n",
      "\tval_loss: 2.0747\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 145\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y264sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepGRU_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepGRU_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepGRU_hour_history += NormalNonDeepGRU_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_deep_rnn_forward_min = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_min = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_min = BidirectionalRNNWithAttention(non_deep_rnn_forward_min, non_deep_rnn_backward_min)\n",
    "\n",
    "non_deep_rnn_forward_hour = VanillaRNN(input_size, hidden_size)\n",
    "non_deep_rnn_backward_hour = VanillaRNN(input_size, hidden_size)\n",
    "bidirectional_rnn_encoder_hour = BidirectionalRNNWithAttention(non_deep_rnn_forward_hour, non_deep_rnn_backward_hour)\n",
    "#fc layer\n",
    "non_deep_rnn_fc_dst_min = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_min = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n",
    "\n",
    "non_deep_rnn_fc_dst_hour = DeepNeuralNetwork(2*hidden_size, pred_length, *architecture)\n",
    "non_deep_rnn_fc_kp_hour = DeepNeuralNetwork(2*hidden_size, hour_to_3_hour(pred_length), *architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_min = to_device(NormalArchitecture(bidirectional_rnn_encoder_min, non_deep_rnn_fc_dst_min, non_deep_rnn_fc_kp_min), device)\n",
    "NormalNonDeepVanillaRNN_hour = to_device(NormalArchitecture(bidirectional_rnn_encoder_hour, non_deep_rnn_fc_dst_hour, non_deep_rnn_fc_kp_hour), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_min_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RefinedNonDeepVanillaRNN_min_history += NormalNonDeepVanillaRNN_min.fit(epochs, max_lr, train_mn_dl, test_mn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalNonDeepVanillaRNN_hour_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00005\n",
      "\ttrain_loss: 2.0527\n",
      "\tval_loss: 2.0624\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\main.ipynb Cell 152\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF-SpaceApps/main.ipynb#Y304sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m NormalNonDeepVanillaRNN_hour_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m NormalNonDeepVanillaRNN_hour\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\models\\macro_architectures.py:70\u001b[0m, in \u001b[0;36mNormalArchitecture.fit\u001b[1;34m(self, epochs, max_lr, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     68\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     73\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF-SpaceApps\\utils.py:65\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n\u001b[0;32m     66\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NormalNonDeepVanillaRNN_hour_history += NormalNonDeepVanillaRNN_hour.fit(epochs, max_lr, train_hn_dl, test_hn_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
