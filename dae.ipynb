{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.optim.lr_scheduler import OneCycleLR, StepLR, LinearLR\n",
    "from data.preprocessing import *\n",
    "from data.data_utils import *\n",
    "from models.dae import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 20\n",
    "hidden_size = 40\n",
    "architecture = ()\n",
    "rnn_num_layers = 1\n",
    "sequence_length_hour = 96  #last 5 days\n",
    "num_heads = [2, 10]\n",
    "bidirectional = True\n",
    "dict_values = ['dst_kyoto', 'kp_gfz']\n",
    "time_steps = 0 #after how time steps you want to inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'LSTM'\n",
    "model = to_device(LSTMDenoisingAutoEncoder(input_size, hidden_size, rnn_num_layers, bidirectional=bidirectional, num_heads=num_heads, architecture=architecture), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\Documents\\SMFGF-SpaceApps\\data\\preprocessing.py:360: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  today_kp = kp[day][0:8]\n"
     ]
    }
   ],
   "source": [
    "#DATA PROCESSING\n",
    "start_time = '20210101'\n",
    "end_time = '20230802'\n",
    "scrap_date = interval_time(start_time, end_time)\n",
    "months = list(set([day[:6] for day in scrap_date]))\n",
    "import_Dst(months)\n",
    "l1_sample, l2_sample, dst, kp = automated_preprocessing(scrap_date, sep = False)\n",
    "l1_sample = l1_sample.resample('60min').mean()\n",
    "l2_sample = l2_sample.resample('60min').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_kp_dataset = MainToSingleTarget(l1_sample, dst, sequence_length_hour, 1, hour = True, sep = False, target_mode = 'dst_kyoto', l2_df = l2_sample, time_step_ahead = 0, dae = True, multiclass = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = []\n",
    "batch_r2 =[]\n",
    "for sample in hour_kp_dataset:\n",
    "    l1, l2 = sample\n",
    "    batch_loss.append(F.mse_loss(l1,l2))\n",
    "    batch_r2.append(r2(l1, l2))\n",
    "\n",
    "torch.stack(batch_loss).mean(), torch.stack(batch_r2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = sorted([(i, x.item()) for i, x in enumerate(batch_loss)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2325063223.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n",
      "\u001b[1;33m    train_idx = [i for i,_ in batch_loss[[0:1000, -5000:]]]\u001b[0m\n",
      "\u001b[1;37m                                           ^\u001b[0m\n",
      "\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "fault_train_idx = [i for i,_ in batch_loss[-6000:]]\n",
    "non_faulty_idx = [i for i, _ in batch_loss[: 4000]]\n",
    "test_idx = [i for i, _ in batch_loss[4000:-6000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dae_train = hour_kp_dataset[[fault_train_idx, non_faulty_idx]]\n",
    "dae_cross = hour_kp_dataset[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:20% training: 80%\n",
    "batch_size = 25  #Change based on GPU capacity\n",
    "\n",
    "train_hour_kp_dl = DataLoader(dae_train, batch_size, num_workers=4, pin_memory=True)\n",
    "train_hour_kp_dl = DeviceDataLoader(train_hour_kp_dl, device)\n",
    "test_hour_kp_dl = DataLoader(dae_cross, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hour_kp_dl = DeviceDataLoader(test_hour_kp_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr = 3e-3\n",
    "weigth_decay = 1e-8\n",
    "grad_clip = 1e-3\n",
    "opt_func = Adam\n",
    "#lr_sched = OneCycleLR  \n",
    "lr_sched = LinearLR\n",
    "start_factor = 1\n",
    "end_factor = 0.1\n",
    "steps = epochs\n",
    "gamma = 0.999\n",
    "weights = None\n",
    "encoder_forcing = None\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\jorge\\Documents\\SMFGF-SpaceApps\\dae.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Documents/SMFGF-SpaceApps/dae.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hour_kp_dl, test_hour_kp_dl, weigth_decay, grad_clip, opt_func, lr_sched, start_factor, end_factor, steps, gamma, weights, encoder_forcing)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Documents\\SMFGF-SpaceApps\\models\\base.py:121\u001b[0m, in \u001b[0;36mGeoBase.fit\u001b[1;34m(self, epochs, lr, train_loader, val_loader, weight_decay, grad_clip, opt_func, lr_sched, start_factor, end_factor, steps, gamma, weights, encoder_forcing)\u001b[0m\n",
      "\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m lr_sched \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;32m    120\u001b[0m     lrs \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m--> 121\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n",
      "\u001b[0;32m    122\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n",
      "\u001b[0;32m    123\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(batch, weights, encoder_forcing)\n",
      "\u001b[0;32m    124\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Documents\\SMFGF-SpaceApps\\utils.py:66\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[0;32m     65\u001b[0m     \u001b[39m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m---> 66\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl:\n",
      "\u001b[0;32m     67\u001b[0m         \u001b[39myield\u001b[39;00m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n",
      "\u001b[0;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n",
      "\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n",
      "\u001b[0;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n",
      "\u001b[0;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n",
      "\u001b[0;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n",
      "\u001b[0;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n",
      "\u001b[0;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n",
      "\u001b[0;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n",
      "\u001b[1;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n",
      "\u001b[0;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n",
      "\u001b[0;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n",
      "\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;32m    120\u001b[0m _cleanup()\n",
      "\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n",
      "\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n",
      "\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n",
      "\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n",
      "\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n",
      "\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n",
      "\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n",
      "\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n",
      "\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n",
      "\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n",
      "\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n",
      "\u001b[0;32m     93\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m     94\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n",
      "\u001b[1;32m---> 95\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n",
      "\u001b[0;32m     96\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n",
      "\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[0;32m     59\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n",
      "\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history += model.fit(epochs, max_lr, train_hour_kp_dl, test_hour_kp_dl, weigth_decay, grad_clip, opt_func, lr_sched, start_factor, end_factor, steps, gamma, weights, encoder_forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "name = f'{hidden_size}_{rnn_num_layers}_{time_steps}_{arch}'\n",
    "os.makedirs('dae', exist_ok=True)\n",
    "torch.save(model, f'dae/{name}.pt')\n",
    "try:     \n",
    "    os.remove(f'dae/{name}.csv')\n",
    "except FileNotFoundError:   \n",
    "    pass\n",
    "with open(f'dae/{name}.csv', 'w') as file:\n",
    "    file.write(','.join(map(str,list(history[-1].values()))))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
