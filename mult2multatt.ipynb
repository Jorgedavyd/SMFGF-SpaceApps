{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.optim.lr_scheduler import OneCycleLR, StepLR, LinearLR\n",
    "from data.preprocessing import *\n",
    "from data.data_utils import *\n",
    "from models.mult2multatt import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size_fc = 100\n",
    "hidden_size_mg = 100\n",
    "architecture = (100,50,25,5)\n",
    "rnn_num_layers = 5\n",
    "model_num_layers = 1\n",
    "sequence_length_hour = 96  #last 5 days\n",
    "sequence_length_minute = 300 #minute\n",
    "dict_values = ['dst_kyoto', 'kp_gfz']\n",
    "time_steps = 0 #after how time steps you want to inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'LSTM'\n",
    "encoder_fc = ResidualMultiheadAttentionLSTM(input_size = 9,hidden_size =  hidden_size_fc, num_heads=[3,10], num_layers_lstm = rnn_num_layers, bidirectional=False, overall_num_layers=model_num_layers)\n",
    "encoder_mg = ResidualMultiheadAttentionLSTM(input_size = 11, hidden_size = hidden_size_mg, num_heads=[11, 10], num_layers_lstm = rnn_num_layers, bidirectional=False, overall_num_layers=model_num_layers)\n",
    "decoder = ResidualMultiheadAttentionLSTM(input_size = encoder_mg.hidden_size+encoder_fc.hidden_size, hidden_size = hidden_size_fc+hidden_size_mg, num_heads = [20,20], num_layers_lstm = rnn_num_layers, bidirectional=False, overall_num_layers=model_num_layers)\n",
    "model = to_device(MultiHeaded2MultiheadAttentionLSTM(encoder_fc, encoder_mg, decoder, [10,10], architecture, task = 'regression'), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\Desktop\\SMFGF\\SMFGF-SpaceApps\\data\\preprocessing.py:360: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  today_kp = kp[day][0:8]\n"
     ]
    }
   ],
   "source": [
    "#DATA PROCESSING\n",
    "start_time = '20210101'\n",
    "end_time = '20230802'\n",
    "scrap_date = interval_time(start_time, end_time)\n",
    "months = list(set([day[:6] for day in scrap_date]))\n",
    "import_Dst(months)\n",
    "l1_sample, l2_sample, dst, kp = automated_preprocessing(scrap_date, sep = True)\n",
    "l1_sample_hour = (l1_sample[0].resample('60min').mean(), l1_sample[1].resample('60min').mean()) #multhead\n",
    "l2_sample_hour = (l2_sample[0].resample('60min').mean(), l2_sample[1].resample('60min').mean()) #multhead encoder forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_kp_dataset = MainToSingleTarget(l1_sample_hour, dst, sequence_length_hour, 1, hour = True, sep = True, target_mode = 'dst_kyoto', l2_df = l2_sample_hour, time_step_ahead = 0, dae = False, multiclass = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 90%\n",
    "\n",
    "test_size = round(0.05*len(hour_kp_dataset))\n",
    "\n",
    "train_hour_kp, test_hour_kp = random_split(hour_kp_dataset , [len(hour_kp_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 100  #Change based on GPU capacity\n",
    "\n",
    "train_hour_kp_dl = DataLoader(train_hour_kp, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hour_kp_dl = DeviceDataLoader(train_hour_kp_dl, device)\n",
    "test_hour_kp_dl = DataLoader(test_hour_kp, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hour_kp_dl = DeviceDataLoader(test_hour_kp_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 100\n",
    "max_lr =1e-2\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 1e-2\n",
    "opt_func = Adam\n",
    "#lr_sched = OneCycleLR  \n",
    "lr_sched = OneCycleLR\n",
    "start_factor = 1\n",
    "end_factor = 0.1\n",
    "steps = epochs\n",
    "gamma = 0.999\n",
    "weights = [0.1,0.1,0.2,1]\n",
    "encoder_forcing = True\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00043\n",
      "\ttrain_loss: 1.0098\n",
      "\tval_loss: 0.8473\n",
      "\tr2_score: -0.0079\n",
      "Epoch [1]:\n",
      "\tlast_lr: 0.00050\n",
      "\ttrain_loss: 1.0096\n",
      "\tval_loss: 0.8471\n",
      "\tr2_score: -0.0078\n",
      "Epoch [2]:\n",
      "\tlast_lr: 0.00063\n",
      "\ttrain_loss: 1.0100\n",
      "\tval_loss: 0.8473\n",
      "\tr2_score: -0.0078\n",
      "Epoch [3]:\n",
      "\tlast_lr: 0.00081\n",
      "\ttrain_loss: 1.0103\n",
      "\tval_loss: 0.8473\n",
      "\tr2_score: -0.0078\n",
      "Epoch [4]:\n",
      "\tlast_lr: 0.00104\n",
      "\ttrain_loss: 1.0089\n",
      "\tval_loss: 0.8472\n",
      "\tr2_score: -0.0078\n",
      "Epoch [5]:\n",
      "\tlast_lr: 0.00132\n",
      "\ttrain_loss: 1.0089\n",
      "\tval_loss: 0.8474\n",
      "\tr2_score: -0.0080\n",
      "Epoch [6]:\n",
      "\tlast_lr: 0.00163\n",
      "\ttrain_loss: 1.0095\n",
      "\tval_loss: 0.8475\n",
      "\tr2_score: -0.0080\n",
      "Epoch [7]:\n",
      "\tlast_lr: 0.00199\n",
      "\ttrain_loss: 1.0110\n",
      "\tval_loss: 0.8470\n",
      "\tr2_score: -0.0078\n",
      "Epoch [8]:\n",
      "\tlast_lr: 0.00238\n",
      "\ttrain_loss: 1.0091\n",
      "\tval_loss: 0.8475\n",
      "\tr2_score: -0.0080\n",
      "Epoch [9]:\n",
      "\tlast_lr: 0.00280\n",
      "\ttrain_loss: 1.0098\n",
      "\tval_loss: 0.8471\n",
      "\tr2_score: -0.0078\n",
      "Epoch [10]:\n",
      "\tlast_lr: 0.00325\n",
      "\ttrain_loss: 1.0082\n",
      "\tval_loss: 0.8474\n",
      "\tr2_score: -0.0079\n",
      "Epoch [11]:\n",
      "\tlast_lr: 0.00372\n",
      "\ttrain_loss: 1.0093\n",
      "\tval_loss: 0.8487\n",
      "\tr2_score: -0.0091\n",
      "Epoch [12]:\n",
      "\tlast_lr: 0.00420\n",
      "\ttrain_loss: 1.0100\n",
      "\tval_loss: 0.8476\n",
      "\tr2_score: -0.0081\n",
      "Epoch [13]:\n",
      "\tlast_lr: 0.00470\n",
      "\ttrain_loss: 1.0096\n",
      "\tval_loss: 0.8470\n",
      "\tr2_score: -0.0079\n",
      "Epoch [14]:\n",
      "\tlast_lr: 0.00520\n",
      "\ttrain_loss: 1.0103\n",
      "\tval_loss: 0.8482\n",
      "\tr2_score: -0.0086\n",
      "Epoch [15]:\n",
      "\tlast_lr: 0.00570\n",
      "\ttrain_loss: 1.0122\n",
      "\tval_loss: 0.8496\n",
      "\tr2_score: -0.0100\n",
      "Epoch [16]:\n",
      "\tlast_lr: 0.00620\n",
      "\ttrain_loss: 1.0095\n",
      "\tval_loss: 0.8475\n",
      "\tr2_score: -0.0080\n",
      "Epoch [17]:\n",
      "\tlast_lr: 0.00668\n",
      "\ttrain_loss: 1.0092\n",
      "\tval_loss: 0.8477\n",
      "\tr2_score: -0.0082\n",
      "Epoch [18]:\n",
      "\tlast_lr: 0.00715\n",
      "\ttrain_loss: 1.0080\n",
      "\tval_loss: 0.8471\n",
      "\tr2_score: -0.0078\n",
      "Epoch [19]:\n",
      "\tlast_lr: 0.00760\n",
      "\ttrain_loss: 1.0089\n",
      "\tval_loss: 0.8485\n",
      "\tr2_score: -0.0089\n",
      "Epoch [20]:\n",
      "\tlast_lr: 0.00802\n",
      "\ttrain_loss: 1.0116\n",
      "\tval_loss: 0.8471\n",
      "\tr2_score: -0.0078\n",
      "Epoch [21]:\n",
      "\tlast_lr: 0.00841\n",
      "\ttrain_loss: 1.0104\n",
      "\tval_loss: 0.8473\n",
      "\tr2_score: -0.0078\n",
      "Epoch [22]:\n",
      "\tlast_lr: 0.00877\n",
      "\ttrain_loss: 1.0113\n",
      "\tval_loss: 0.8488\n",
      "\tr2_score: -0.0092\n",
      "Epoch [23]:\n",
      "\tlast_lr: 0.00908\n",
      "\ttrain_loss: 1.0085\n",
      "\tval_loss: 0.8470\n",
      "\tr2_score: -0.0078\n",
      "Epoch [24]:\n",
      "\tlast_lr: 0.00936\n",
      "\ttrain_loss: 1.0091\n",
      "\tval_loss: 0.8471\n",
      "\tr2_score: -0.0078\n",
      "Epoch [25]:\n",
      "\tlast_lr: 0.00958\n",
      "\ttrain_loss: 1.0107\n",
      "\tval_loss: 0.8471\n",
      "\tr2_score: -0.0078\n",
      "Epoch [26]:\n",
      "\tlast_lr: 0.00976\n",
      "\ttrain_loss: 1.0087\n",
      "\tval_loss: 0.8475\n",
      "\tr2_score: -0.0080\n",
      "Epoch [27]:\n",
      "\tlast_lr: 0.00990\n",
      "\ttrain_loss: 1.0095\n",
      "\tval_loss: 0.8470\n",
      "\tr2_score: -0.0077\n",
      "Epoch [28]:\n",
      "\tlast_lr: 0.00997\n",
      "\ttrain_loss: 1.0095\n",
      "\tval_loss: 0.8485\n",
      "\tr2_score: -0.0089\n",
      "Epoch [29]:\n",
      "\tlast_lr: 0.01000\n",
      "\ttrain_loss: 1.0117\n",
      "\tval_loss: 0.8470\n",
      "\tr2_score: -0.0078\n",
      "Epoch [30]:\n",
      "\tlast_lr: 0.00999\n",
      "\ttrain_loss: 1.0092\n",
      "\tval_loss: 0.8483\n",
      "\tr2_score: -0.0087\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF\\SMFGF-SpaceApps\\mult2multatt.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Desktop/SMFGF/SMFGF-SpaceApps/mult2multatt.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(epochs, max_lr, train_hour_kp_dl, test_hour_kp_dl, weigth_decay, grad_clip, opt_func, lr_sched, start_factor, end_factor, steps, gamma, weights, encoder_forcing)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\Desktop\\SMFGF\\SMFGF-SpaceApps\\models\\base.py:119\u001b[0m, in \u001b[0;36mGeoBase.fit\u001b[1;34m(self, epochs, lr, train_loader, val_loader, weight_decay, grad_clip, opt_func, lr_sched, start_factor, end_factor, steps, gamma, weights, encoder_forcing)\u001b[0m\n\u001b[0;32m    117\u001b[0m train_losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m    118\u001b[0m \u001b[39m#Calcular las derivadas parciales\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    121\u001b[0m \u001b[39m# Gradient clipping, para que no ocurra el exploding gradient\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39mif\u001b[39;00m grad_clip:\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history += model.fit(epochs, max_lr, train_hour_kp_dl, test_hour_kp_dl, weigth_decay, grad_clip, opt_func, lr_sched, start_factor, end_factor, steps, gamma, weights, encoder_forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jorge\\Documents\\SMFGF-SpaceApps\\mult2multatt.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jorge/Documents/SMFGF-SpaceApps/mult2multatt.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jorge/Documents/SMFGF-SpaceApps/mult2multatt.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmult2mult/\u001b[39m\u001b[39m{\u001b[39;00mhidden_size_fc\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mhidden_size_mg\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mnum_layers\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mencoder_forcing\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtime_steps\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00march\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jorge/Documents/SMFGF-SpaceApps/mult2multatt.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     file\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m,\u001b[39mlist\u001b[39m(history[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mvalues()))))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('mult2mult', exist_ok=True)\n",
    "torch.save(model, f'mult2mult/{hidden_size_fc}_{hidden_size_mg}_{rnn_num_layers}_{encoder_forcing}_{time_steps}_{arch}.pt')\n",
    "try:     \n",
    "    os.remove(f'mult2mult/{hidden_size_fc}_{hidden_size_mg}_{rnn_num_layers}_{encoder_forcing}_{time_steps}_{arch}.csv')\n",
    "except FileNotFoundError:   \n",
    "    pass\n",
    "with open(f'mult2mult/{hidden_size_fc}_{hidden_size_mg}_{rnn_num_layers}_{encoder_forcing}_{time_steps}_{arch}.csv', 'w') as file:\n",
    "    file.write(','.join(map(str,list(history[-1].values()))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
